2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:   name = 'Grandeur Peak'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:   author = 'Erin Young'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:   homePage = 'https://github.com/UPHL-BioNGS/Grandeur'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:   mainScript = 'grandeur.nf'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //########## Setting the Profile ##########
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     docker.enabled = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     docker.runOptions = "-u \$(id -u):\$(id -g)"
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     includeConfig './configs/grandeur_template.config'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     singularity.enabled = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     singularity.autoMounts = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     includeConfig './configs/grandeur_template.config'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     includeConfig './configs/UPHL.config'
2022-03-14 09:22:59 [INFO] ENTERING_PARAMS_ENCLOSURE:     params {
2022-03-14 09:22:59 [INFO] OTHER_LINE:     params {
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:     params { PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       prokka = true
2022-03-14 09:22:59 [INFO] ADDING_LINE:       prokka = true
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       prokka = true PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       roary = true
2022-03-14 09:22:59 [INFO] ADDING_LINE:       roary = true
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       roary = true PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] OTHER_LINE:       }
2022-03-14 09:22:59 [INFO] IGNORE_PARAM_LINE:       }
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       } PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] EXITED_PARAMS_ENCLOSURE:     }
2022-03-14 09:22:59 [INFO] ENTERING_PARAMS_ENCLOSURE:     params {
2022-03-14 09:22:59 [INFO] OTHER_LINE:     params {
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:     params { PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       prokka = true
2022-03-14 09:22:59 [INFO] ADDING_LINE:       prokka = true
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       prokka = true PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       roary = true
2022-03-14 09:22:59 [INFO] ADDING_LINE:       roary = true
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       roary = true PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       fastqc = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:       fastqc = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       fastqc = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       seqyclean = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:       seqyclean = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       seqyclean = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       spades = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:       spades = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       spades = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] OTHER_LINE:       }
2022-03-14 09:22:59 [INFO] IGNORE_PARAM_LINE:       }
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       } PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] EXITED_PARAMS_ENCLOSURE:     }
2022-03-14 09:22:59 [INFO] ENTERING_PARAMS_ENCLOSURE:     params {
2022-03-14 09:22:59 [INFO] OTHER_LINE:     params {
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:     params { PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       roary = true
2022-03-14 09:22:59 [INFO] ADDING_LINE:       roary = true
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       roary = true PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       spades = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:       spades = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       spades = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       mash = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:       mash = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       mash = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       fastqc = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:       fastqc = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       fastqc = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       seqyclean = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:       seqyclean = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       seqyclean = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       spades = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:       spades = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       spades = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       multiqc = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:       multiqc = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       multiqc = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] OTHER_LINE:       }
2022-03-14 09:22:59 [INFO] IGNORE_PARAM_LINE:       }
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       } PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] EXITED_PARAMS_ENCLOSURE:     }
2022-03-14 09:22:59 [INFO] ENTERING_PARAMS_ENCLOSURE:     params {
2022-03-14 09:22:59 [INFO] OTHER_LINE:     params {
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:     params { PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       prokka = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:       prokka = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       prokka = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       roary = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:       roary = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       roary = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] OTHER_LINE:       }
2022-03-14 09:22:59 [INFO] IGNORE_PARAM_LINE:       }
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       } PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] EXITED_PARAMS_ENCLOSURE:     }
2022-03-14 09:22:59 [INFO] ENTERING_PARAMS_ENCLOSURE:     params {
2022-03-14 09:22:59 [INFO] OTHER_LINE:     params {
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:     params { PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       blobtools = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:       blobtools = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       blobtools = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       kraken2 = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:       kraken2 = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       kraken2 = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       fastqc = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:       fastqc = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       fastqc = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       quast = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:       quast = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       quast = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       cg_pipeline = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:       cg_pipeline = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       cg_pipeline = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       seqsero2 = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:       seqsero2 = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       seqsero2 = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       shigatyper = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:       shigatyper = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       shigatyper = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       kleborate = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:       kleborate = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       kleborate = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       serotypefinder = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:       serotypefinder = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       serotypefinder = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       amrfinderplus = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:       amrfinderplus = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       amrfinderplus = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       mlst = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:       mlst = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       mlst = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       summary = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:       summary = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       summary = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:       multiqc = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:       multiqc = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       multiqc = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] OTHER_LINE:       }
2022-03-14 09:22:59 [INFO] IGNORE_PARAM_LINE:       }
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:       } PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] EXITED_PARAMS_ENCLOSURE:     }
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:   }
2022-03-14 09:22:59 [INFO] DONE_PARSING


2022-03-14 09:22:59 [INFO] Reading in /Users/keng/codes/Grandeur/./configs/grandeur_template.config
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# Docker Params -------------------------------------------
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //docker.enabled = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //docker.runOptions = '-u \$(id -u):\$(id -g)'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //docker.sudo = false
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //docker.temp = /tmp
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //docker.remove = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //docker.registry = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //docker.fixOwnership = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //docker.engineOptions = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //docker.mountFlags = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# Singularity Params --------------------------------------
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //singularity.enabled = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //singularity.autoMounts = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //singularity.runOptions = 
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //process.stageInMode = link
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //singularity.engineOptions = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //singularity.cacheDir = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# AWS Batch Params ----------------------------------------
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //process.executor = 'awsbatch'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //process.queue = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //aws.batch.cliPath = '/home/ec2-user/miniconda/bin/aws'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //aws.region = 'us-east-1'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //workDir = 's3://'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# Google Cloud Params -------------------------------------
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //process.executor = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //google.project = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //google.location = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //google.region = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //workDir = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //google.lifeSciences.bootDiskSize = 50.GB
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# Nextflow Tower ------------------------------------------
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //tower.accessToken = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //tower.enabled = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# Adjustable Workflow parameters ---------------------------
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.reads = 'reads'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.gff = 'gff'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.fastas = 'fastas'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.outdir = 'grandeur'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# Basic CPU usage grouping
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: params.maxcpus = 8
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS: maxcpus = 8
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: params.medcpus = 4
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS: medcpus = 4
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for cg_pipeline processes
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.cg_pipeline = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.cg_pipeline_options = '--qual_offset 33 --minLength 1'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# json with genome sizes
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.genome_sizes = 'genome_sizes.json'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for blobtools processes
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.blobtools = false
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.blast_db = 'blast_db'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.local_db_type = 'nt'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.bwa_options = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.samtools_sort_options=''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.blobtools_create_options=''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.blobtools_view_options=''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.blobtools_plot_options = '--format png -r species'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for kraken2 process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.kraken2 = false
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.kraken2_db = 'kraken2_db'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.kraken2_options = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for seqyclean process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# contaminant file needs to be in the container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.seqyclean_contaminant_file = /Adapters_plus_PhiX_174.fasta
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.seqyclean_options = '-minlen 25 -qual'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for spades process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.spades = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.spades_options = '--isolate'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for fastqc process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.fastqc = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.fastqc_options = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for mash processes
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.mash = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.mash_reference = '/db/RefSeqSketchesDefaults.msh'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.mash_options = '-v 0 -d 0.5'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for prokka process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.prokka = false
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.prokka_options = '--mincontiglen 500 --compliant --locustag locus_tag'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.center = 'STAPHB'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for quast process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.quast = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.quast_options = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for seqsero2 process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.seqsero2 = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.seqsero2_options_fasta = '-t 4 -m k'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# default is to use paired-end fastq reads
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.seqsero2_options_fastq = '-t 2 -m a -b mem'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for sigatyper process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.shigatyper = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.shigatyper_options = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for kleborate process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.kleborate = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.kleborate_options = '-all'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for serotypefinder process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.serotypefinder = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.serotypefinder_options = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for amrfinder plus process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.amrfinderplus = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.amrfinderplus_options = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for mlst process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.mlst = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for summary process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: params.summary = true
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS: summary = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for multiqc process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.multiqc_options = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.multiqc = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for roary process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.roary = false
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for iqtree2 process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.iqtree2 = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.iqtree2_options = '-t RANDOM -m GTR+F+I -bb 1000 -alrt 1000'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.outgroup = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for snp-dists process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.snp_dists = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.snp_dists_options = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# Docker Images -------------------------------------------
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: seqyclean_container = 'staphb/seqyclean:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: spades_container = 'staphb/spades:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: fastqc_container = 'staphb/fastqc:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: mash_container = 'staphb/mash:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: prokka_container = 'staphb/prokka:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: quast_container = 'staphb/quast:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: lyveset_container = 'staphb/lyveset:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: seqsero2_container = 'staphb/seqsero2:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: shigatyper_container = 'andrewlangvt/shigatyper:1'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: kleborate_container = 'staphb/kleborate:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: serotypefinder_container = 'staphb/serotypefinder:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: amrfinderplus_container = 'staphb/ncbi-amrfinderplus:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: kraken2_container = 'staphb/kraken2:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: blastn_container = 'ncbi/blast:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: bwa_container = 'staphb/bwa:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: samtools_container = 'staphb/samtools:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: blobtools_container = 'chrishah/blobtools:v1.1.1'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: mlst_container = 'staphb/mlst:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: summary_container = 'staphb/parallel-perl:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: multiqc_container = 'ewels/multiqc:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: roary_container = 'staphb/roary:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: iqtree_container = 'staphb/iqtree2:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: snpdists_container = 'staphb/snp-dists:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:   cpus = 2
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:   memory = '4 GB'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = seqyclean_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.maxcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = maxcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = spades_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = fastqc_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.medcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = medcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = mash_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = mash_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.maxcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = maxcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = prokka_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = quast_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = lyveset_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.medcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = medcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = lyveset_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.medcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = medcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = seqsero2_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.medcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = medcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = shigatyper_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.medcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = medcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = kleborate_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.medcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = medcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = serotypefinder_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.medcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = medcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = amrfinderplus_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.maxcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = maxcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = kraken2_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.medcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = medcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = blastn_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.medcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = medcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = bwa_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.medcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = medcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = samtools_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = blobtools_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = blobtools_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = blobtools_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = mlst_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = summary_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = multiqc_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.maxcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = maxcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = roary_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.maxcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = maxcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = iqtree_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = snpdists_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: }
2022-03-14 09:22:59 [INFO] DONE_PARSING


2022-03-14 09:22:59 [INFO] Reading in /Users/keng/codes/Grandeur/./configs/grandeur_template.config
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# Docker Params -------------------------------------------
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //docker.enabled = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //docker.runOptions = '-u \$(id -u):\$(id -g)'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //docker.sudo = false
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //docker.temp = /tmp
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //docker.remove = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //docker.registry = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //docker.fixOwnership = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //docker.engineOptions = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //docker.mountFlags = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# Singularity Params --------------------------------------
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //singularity.enabled = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //singularity.autoMounts = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //singularity.runOptions = 
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //process.stageInMode = link
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //singularity.engineOptions = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //singularity.cacheDir = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# AWS Batch Params ----------------------------------------
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //process.executor = 'awsbatch'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //process.queue = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //aws.batch.cliPath = '/home/ec2-user/miniconda/bin/aws'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //aws.region = 'us-east-1'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //workDir = 's3://'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# Google Cloud Params -------------------------------------
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //process.executor = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //google.project = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //google.location = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //google.region = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //workDir = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //google.lifeSciences.bootDiskSize = 50.GB
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# Nextflow Tower ------------------------------------------
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //tower.accessToken = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //tower.enabled = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# Adjustable Workflow parameters ---------------------------
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.reads = 'reads'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.gff = 'gff'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.fastas = 'fastas'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.outdir = 'grandeur'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# Basic CPU usage grouping
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: params.maxcpus = 8
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS: maxcpus = 8
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: params.medcpus = 4
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS: medcpus = 4
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for cg_pipeline processes
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.cg_pipeline = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.cg_pipeline_options = '--qual_offset 33 --minLength 1'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# json with genome sizes
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.genome_sizes = 'genome_sizes.json'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for blobtools processes
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.blobtools = false
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.blast_db = 'blast_db'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.local_db_type = 'nt'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.bwa_options = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.samtools_sort_options=''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.blobtools_create_options=''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.blobtools_view_options=''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.blobtools_plot_options = '--format png -r species'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for kraken2 process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.kraken2 = false
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.kraken2_db = 'kraken2_db'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.kraken2_options = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for seqyclean process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# contaminant file needs to be in the container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.seqyclean_contaminant_file = /Adapters_plus_PhiX_174.fasta
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.seqyclean_options = '-minlen 25 -qual'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for spades process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.spades = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.spades_options = '--isolate'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for fastqc process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.fastqc = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.fastqc_options = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for mash processes
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.mash = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.mash_reference = '/db/RefSeqSketchesDefaults.msh'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.mash_options = '-v 0 -d 0.5'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for prokka process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.prokka = false
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.prokka_options = '--mincontiglen 500 --compliant --locustag locus_tag'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.center = 'STAPHB'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for quast process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.quast = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.quast_options = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for seqsero2 process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.seqsero2 = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.seqsero2_options_fasta = '-t 4 -m k'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# default is to use paired-end fastq reads
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.seqsero2_options_fastq = '-t 2 -m a -b mem'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for sigatyper process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.shigatyper = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.shigatyper_options = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for kleborate process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.kleborate = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.kleborate_options = '-all'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for serotypefinder process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.serotypefinder = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.serotypefinder_options = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for amrfinder plus process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.amrfinderplus = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.amrfinderplus_options = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for mlst process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.mlst = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for summary process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: params.summary = true
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS: summary = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for multiqc process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.multiqc_options = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.multiqc = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for roary process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.roary = false
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for iqtree2 process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.iqtree2 = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.iqtree2_options = '-t RANDOM -m GTR+F+I -bb 1000 -alrt 1000'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.outgroup = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# for snp-dists process
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.snp_dists = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //params.snp_dists_options = ''
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: //# Docker Images -------------------------------------------
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: seqyclean_container = 'staphb/seqyclean:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: spades_container = 'staphb/spades:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: fastqc_container = 'staphb/fastqc:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: mash_container = 'staphb/mash:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: prokka_container = 'staphb/prokka:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: quast_container = 'staphb/quast:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: lyveset_container = 'staphb/lyveset:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: seqsero2_container = 'staphb/seqsero2:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: shigatyper_container = 'andrewlangvt/shigatyper:1'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: kleborate_container = 'staphb/kleborate:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: serotypefinder_container = 'staphb/serotypefinder:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: amrfinderplus_container = 'staphb/ncbi-amrfinderplus:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: kraken2_container = 'staphb/kraken2:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: blastn_container = 'ncbi/blast:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: bwa_container = 'staphb/bwa:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: samtools_container = 'staphb/samtools:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: blobtools_container = 'chrishah/blobtools:v1.1.1'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: mlst_container = 'staphb/mlst:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: summary_container = 'staphb/parallel-perl:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: multiqc_container = 'ewels/multiqc:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: roary_container = 'staphb/roary:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: iqtree_container = 'staphb/iqtree2:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: snpdists_container = 'staphb/snp-dists:latest'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:   cpus = 2
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:   memory = '4 GB'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = seqyclean_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.maxcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = maxcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = spades_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = fastqc_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.medcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = medcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = mash_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = mash_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.maxcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = maxcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = prokka_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = quast_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = lyveset_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.medcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = medcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = lyveset_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.medcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = medcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = seqsero2_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.medcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = medcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = shigatyper_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.medcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = medcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = kleborate_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.medcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = medcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = serotypefinder_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.medcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = medcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = amrfinderplus_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.maxcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = maxcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = kraken2_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.medcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = medcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = blastn_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.medcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = medcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = bwa_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.medcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = medcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = samtools_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = blobtools_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = blobtools_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = blobtools_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = mlst_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = summary_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = multiqc_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.maxcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = maxcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = roary_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     cpus = params.maxcpus
2022-03-14 09:22:59 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = maxcpus
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = iqtree_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = snpdists_container
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: }
2022-03-14 09:22:59 [INFO] DONE_PARSING


2022-03-14 09:22:59 [INFO] Reading in /Users/keng/codes/Grandeur/./configs/UPHL.config
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:   enabled = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:   autoMounts = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:   cacheDir = '/Volumes/IDGenomics_NAS/singularity'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: // nextflow run /home/eriny/sandbox/Grandeur/grandeur.nf -profile uphl -with-dag grandeur_$(date +%y-%m-%d-%H%M%S).png
2022-03-14 09:22:59 [INFO] ENTERING_PARAMS_ENCLOSURE: params {
2022-03-14 09:22:59 [INFO] OTHER_LINE: params {
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST: params { PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:   maxcpus = 16
2022-03-14 09:22:59 [INFO] ADDING_LINE:   maxcpus = 16
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:   maxcpus = 16 PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:   medcpus = 4
2022-03-14 09:22:59 [INFO] ADDING_LINE:   medcpus = 4
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:   medcpus = 4 PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:   // For Grandeur
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:   center = 'UPHL'
2022-03-14 09:22:59 [INFO] ADDING_LINE:   center = 'UPHL'
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:   center = 'UPHL' PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:   prokka = true
2022-03-14 09:22:59 [INFO] ADDING_LINE:   prokka = true
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:   prokka = true PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:   blobtools = true
2022-03-14 09:22:59 [INFO] ADDING_LINE:   blobtools = true
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:   blobtools = true PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:   blast_db = '/Volumes/IDGenomics_NAS/Data/blast_db_refseq'
2022-03-14 09:22:59 [INFO] ADDING_LINE:   blast_db = '/Volumes/IDGenomics_NAS/Data/blast_db_refseq'
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:   blast_db = '/Volumes/IDGenomics_NAS/Data/blast_db_refseq' PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:   local_db_type = 'ref_prok_rep_genomes'
2022-03-14 09:22:59 [INFO] ADDING_LINE:   local_db_type = 'ref_prok_rep_genomes'
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:   local_db_type = 'ref_prok_rep_genomes' PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:   reads = 'Sequencing_reads/Raw'
2022-03-14 09:22:59 [INFO] ADDING_LINE:   reads = 'Sequencing_reads/Raw'
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:   reads = 'Sequencing_reads/Raw' PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:   // kraken2 = true
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:   kraken2_db = '/Volumes/IDGenomics_NAS/Data/kraken2_db/MiniKraken2/minikraken2_v2_8GB_201904_UPDATE'
2022-03-14 09:22:59 [INFO] ADDING_LINE:   kraken2_db = '/Volumes/IDGenomics_NAS/Data/kraken2_db/MiniKraken2/minikraken2_v2_8GB_201904_UPDATE'
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:   kraken2_db = '/Volumes/IDGenomics_NAS/Data/kraken2_db/MiniKraken2/minikraken2_v2_8GB_201904_UPDATE' PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:   shigatyper = false
2022-03-14 09:22:59 [INFO] ADDING_LINE:   shigatyper = false
2022-03-14 09:22:59 [INFO] LINE_OF_INTEREST:   shigatyper = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:22:59 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:22:59 [INFO] EXITED_PARAMS_ENCLOSURE: }
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = 'staphb/seqyclean:1.10.09'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = 'staphb/mash:2.3'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = 'staphb/mash:2.3'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = 'staphb/spades:3.15.3'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = 'staphb/seqsero2:1.2.1'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = 'staphb/serotypefinder:2.0.1'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = 'andrewlangvt/shigatyper:1'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     container = 'staphb/ncbi-amrfinderplus:3.10.16'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS:     errorStrategy = 'ignore'
2022-03-14 09:22:59 [INFO] NOT_CHANGING_STATUS: }
2022-03-14 09:22:59 [INFO] DONE_PARSING


2022-03-14 09:22:59 [INFO] Adding params params.maxcpus, params.medcpus, params.cpus
2022-03-14 09:22:59 [INFO] Adding params params.maxcpus, params.medcpus, params.center, params.blast_db, params.local_db_type, params.reads, params.kraken2_db
2022-03-14 09:22:59 [INFO] Added 10 params
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.outdir = workflow.launchDir + '/grandeur'
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: println("The files and directory for results is " + params.outdir)
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.maxcpus = Runtime.runtime.availableProcessors()
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE:   params.medcpus = params.maxcpus
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE:   params.medcpus = 5
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.reads = workflow.launchDir + '/reads'
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.fastas = workflow.launchDir + '/fastas'
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.gff = workflow.launchDir + '/gff'
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE:     println("Set 'params.reads' to directory with paired-end reads" )
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE:     println("Set 'params.fastas' to directory with fastas" )
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE:     println("Set 'params.gff' to directory with gff files" )
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.genome_sizes = workflow.projectDir + "/configs/genome_sizes.json"
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.blobtools = false // right now this isn't currently working
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.blast_db = 'blast_db'
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: local_blastdb = params.blobtools
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE:                     println("Set 'params.blast_db' to directory with blast database")
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.kraken2 = false
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.kraken2_db = 'kraken2_db'
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: local_kraken2 = params.kraken2
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE:                     println("Set 'params.kraken2_db' to directory with kraken2 database")
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.seqyclean_contaminant_file = "/Adapters_plus_PhiX_174.fasta"
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.seqyclean_options = '-minlen 25 -qual'
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.spades = true
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.spades_options = '--isolate'
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.fastqc = true
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.fastqc_options = ''
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.mash = true
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.mash_reference = '/db/RefSeqSketchesDefaults.msh'
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.mash_options = '-v 0 -d 0.5'
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.prokka = false
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE:   params.prokka_options = '--mincontiglen 500 --compliant --locustag locus_tag'
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE:   params.center = 'STAPHB'
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.quast = true
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.quast_options = ''
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.cg_pipeline = true
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.cg_pipeline_options = '--qual_offset 33 --minLength 1'
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.seqsero2 = true
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.seqsero2_options_fasta = '-t 4 -m k'
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.seqsero2_options_fastq = '-t 2 -m a -b mem'
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.shigatyper = true
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.shigatyper_options = ''
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.kleborate = true
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.kleborate_options = '-all'
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.serotypefinder = true
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.serotypefinder_options = ''
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.amrfinderplus = true
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.amrfinderplus_options = ''
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE:   params.kraken2_options = ''
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE:   params.local_db_type = 'nt'
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE:   params.bwa_options = ''
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE:   params.samtools_sort_options=''
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE:   params.blobtools_create_options=''
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE:   params.blobtools_view_options=''
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE:   params.blobtools_plot_options = '--format png -r species'
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.mlst = true
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.summary = true
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.multiqc_options = ''
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.multiqc = true
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE: params.roary = false
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE:   params.roary_options = ''
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE:   params.iqtree2 = true
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE:   params.iqtree2_options = '-t RANDOM -m GTR+F+I -bb 1000 -alrt 1000'
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE:   params.outgroup = ''
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE:   params.snp_dists = true
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE:   params.snp_dists_options = ''
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE:     println("MultiQC report can be found at $params.outdir/multiqc/multiqc_report.html")
2022-03-14 09:22:59 [INFO] ADDING_NF_SCRIPT_LINE:     println("Summary can be found at $params.outdir/grandeur_results.tsv")
2022-03-14 09:22:59 [INFO] Parameters to check: params.prokka
 2022-03-14 09:22:59 [INFO] Parameters to check: params.roary
 2022-03-14 09:22:59 [INFO] Parameters to check: params.fastqc
 2022-03-14 09:22:59 [INFO] Parameters to check: params.seqyclean
 2022-03-14 09:22:59 [INFO] Parameters to check: params.spades
 2022-03-14 09:22:59 [INFO] Parameters to check: params.mash
 2022-03-14 09:22:59 [INFO] Parameters to check: params.multiqc
 2022-03-14 09:22:59 [INFO] Parameters to check: params.blobtools
 2022-03-14 09:22:59 [INFO] Parameters to check: params.kraken2
 2022-03-14 09:22:59 [INFO] Parameters to check: params.quast
 2022-03-14 09:22:59 [INFO] Parameters to check: params.cg_pipeline
 2022-03-14 09:22:59 [INFO] Parameters to check: params.seqsero2
 2022-03-14 09:22:59 [INFO] Parameters to check: params.shigatyper
 2022-03-14 09:22:59 [INFO] Parameters to check: params.kleborate
 2022-03-14 09:22:59 [INFO] Parameters to check: params.serotypefinder
 2022-03-14 09:22:59 [INFO] Parameters to check: params.amrfinderplus
 2022-03-14 09:22:59 [INFO] Parameters to check: params.mlst
 2022-03-14 09:22:59 [INFO] Parameters to check: params.summary
 2022-03-14 09:22:59 [INFO] Parameters to check: params.maxcpus
 2022-03-14 09:22:59 [INFO] Parameters to check: params.medcpus
 2022-03-14 09:22:59 [INFO] Parameters to check: params.cpus
 2022-03-14 09:22:59 [INFO] Parameters to check: params.center
 2022-03-14 09:22:59 [INFO] Parameters to check: params.blast_db
 2022-03-14 09:22:59 [INFO] Parameters to check: params.local_db_type
 2022-03-14 09:22:59 [INFO] Parameters to check: params.reads
 2022-03-14 09:22:59 [INFO] Parameters to check: params.kraken2_db
2022-03-14 09:22:59 [INFO] Parameters to add: params.seqyclean
 2022-03-14 09:22:59 [INFO] Parameters to add: params.medcpus
 2022-03-14 09:22:59 [INFO] Parameters to add: params.cpus
 2022-03-14 09:22:59 [INFO] Parameters to add: params.center
 2022-03-14 09:22:59 [INFO] Parameters to add: params.local_db_type
2022-03-14 09:22:59 [INFO] NO need to check param: params.prokka
2022-03-14 09:22:59 [INFO] NO need to check param: params.roary
2022-03-14 09:22:59 [INFO] NO need to check param: params.fastqc
2022-03-14 09:22:59 [INFO] NO need to check param: params.seqyclean
2022-03-14 09:22:59 [INFO] NO need to check param: params.spades
2022-03-14 09:22:59 [INFO] NO need to check param: params.mash
2022-03-14 09:22:59 [INFO] NO need to check param: params.multiqc
2022-03-14 09:22:59 [INFO] NO need to check param: params.blobtools
2022-03-14 09:22:59 [INFO] NO need to check param: params.kraken2
2022-03-14 09:22:59 [INFO] NO need to check param: params.quast
2022-03-14 09:22:59 [INFO] NO need to check param: params.cg_pipeline
2022-03-14 09:22:59 [INFO] NO need to check param: params.seqsero2
2022-03-14 09:22:59 [INFO] NO need to check param: params.shigatyper
2022-03-14 09:22:59 [INFO] NO need to check param: params.kleborate
2022-03-14 09:22:59 [INFO] NO need to check param: params.serotypefinder
2022-03-14 09:22:59 [INFO] NO need to check param: params.amrfinderplus
2022-03-14 09:22:59 [INFO] NO need to check param: params.mlst
2022-03-14 09:22:59 [INFO] NO need to check param: params.summary
2022-03-14 09:22:59 [INFO] NO need to check param: params.maxcpus
2022-03-14 09:22:59 [INFO] NO need to check param: params.medcpus
2022-03-14 09:22:59 [INFO] NO need to check param: params.cpus
2022-03-14 09:22:59 [INFO] NO need to check param: params.center
2022-03-14 09:22:59 [INFO] NO need to check param: params.blast_db
2022-03-14 09:22:59 [INFO] NO need to check param: params.local_db_type
2022-03-14 09:22:59 [INFO] NO need to check param: params.reads
2022-03-14 09:22:59 [INFO] NO need to check param: params.kraken2_db
2022-03-14 09:23:00 [INFO] Initializing key: 17
2022-03-14 09:23:00 [INFO] Appending to key: 17 parameter: seqyclean
2022-03-14 09:23:00 [INFO] Appending to key: 17 parameter: medcpus
2022-03-14 09:23:00 [INFO] Appending to key: 17 parameter: cpus
2022-03-14 09:23:00 [INFO] Appending to key: 17 parameter: center
2022-03-14 09:23:00 [INFO] Appending to key: 17 parameter: local_db_type
2022-03-14 09:23:00 [INFO] ADDING UPDATED PARAMS to /Users/keng/codes/Grandeur/grandeur.ica.nf
2022-03-14 09:23:00 [INFO] parameters found: params.prokka
 2022-03-14 09:23:00 [INFO] parameters found: params.roary
 2022-03-14 09:23:00 [INFO] parameters found: params.fastqc
 2022-03-14 09:23:00 [INFO] parameters found: params.seqyclean
 2022-03-14 09:23:00 [INFO] parameters found: params.spades
 2022-03-14 09:23:00 [INFO] parameters found: params.mash
 2022-03-14 09:23:00 [INFO] parameters found: params.multiqc
 2022-03-14 09:23:00 [INFO] parameters found: params.blobtools
 2022-03-14 09:23:00 [INFO] parameters found: params.kraken2
 2022-03-14 09:23:00 [INFO] parameters found: params.quast
 2022-03-14 09:23:00 [INFO] parameters found: params.cg_pipeline
 2022-03-14 09:23:00 [INFO] parameters found: params.seqsero2
 2022-03-14 09:23:00 [INFO] parameters found: params.shigatyper
 2022-03-14 09:23:00 [INFO] parameters found: params.kleborate
 2022-03-14 09:23:00 [INFO] parameters found: params.serotypefinder
 2022-03-14 09:23:00 [INFO] parameters found: params.amrfinderplus
 2022-03-14 09:23:00 [INFO] parameters found: params.mlst
 2022-03-14 09:23:00 [INFO] parameters found: params.summary
 2022-03-14 09:23:00 [INFO] parameters found: params.maxcpus
 2022-03-14 09:23:00 [INFO] parameters found: params.medcpus
 2022-03-14 09:23:00 [INFO] parameters found: params.cpus
 2022-03-14 09:23:00 [INFO] parameters found: params.center
 2022-03-14 09:23:00 [INFO] parameters found: params.blast_db
 2022-03-14 09:23:00 [INFO] parameters found: params.local_db_type
 2022-03-14 09:23:00 [INFO] parameters found: params.reads
 2022-03-14 09:23:00 [INFO] parameters found: params.kraken2_db
2022-03-14 09:23:00 [INFO] LOOKING into params.prokka
2022-03-14 09:23:00 [INFO] LOOKING into params.roary
2022-03-14 09:23:00 [INFO] LOOKING into params.fastqc
2022-03-14 09:23:00 [INFO] LOOKING into params.seqyclean
2022-03-14 09:23:00 [INFO] LOOKING into params.spades
2022-03-14 09:23:00 [INFO] LOOKING into params.mash
2022-03-14 09:23:00 [INFO] LOOKING into params.multiqc
2022-03-14 09:23:00 [INFO] LOOKING into params.blobtools
2022-03-14 09:23:00 [INFO] LOOKING into params.kraken2
2022-03-14 09:23:00 [INFO] LOOKING into params.quast
2022-03-14 09:23:00 [INFO] LOOKING into params.cg_pipeline
2022-03-14 09:23:00 [INFO] LOOKING into params.seqsero2
2022-03-14 09:23:00 [INFO] LOOKING into params.shigatyper
2022-03-14 09:23:00 [INFO] LOOKING into params.kleborate
2022-03-14 09:23:00 [INFO] LOOKING into params.serotypefinder
2022-03-14 09:23:00 [INFO] LOOKING into params.amrfinderplus
2022-03-14 09:23:00 [INFO] LOOKING into params.mlst
2022-03-14 09:23:00 [INFO] LOOKING into params.summary
2022-03-14 09:23:00 [INFO] LOOKING into params.maxcpus
2022-03-14 09:23:00 [INFO] LOOKING into params.medcpus
2022-03-14 09:23:00 [INFO] LOOKING into params.cpus
2022-03-14 09:23:00 [INFO] LOOKING into params.center
2022-03-14 09:23:00 [INFO] LOOKING into params.blast_db
2022-03-14 09:23:00 [INFO] CHECKING if params.blast_db is file or folder. value: '/Volumes/IDGenomics_NAS/Data/blast_db_refseq'
2022-03-14 09:23:00 [INFO] ADDING params.blast_db to dataInputs
2022-03-14 09:23:00 [INFO] LOOKING into params.local_db_type
2022-03-14 09:23:00 [INFO] LOOKING into params.reads
2022-03-14 09:23:00 [INFO] CHECKING if params.reads is file or folder. value: 'Sequencing_reads/Raw'
2022-03-14 09:23:00 [INFO] LOOKING into params.kraken2_db
2022-03-14 09:23:00 [INFO] CHECKING if params.kraken2_db is file or folder. value: '/Volumes/IDGenomics_NAS/Data/kraken2_db/MiniKraken2/minikraken2_v2_8GB_201904_UPDATE'
2022-03-14 09:23:00 [INFO] ADDING params.kraken2_db to dataInputs
2022-03-14 09:23:00 [INFO] STEP3:Generating ICA XML based off of /Users/keng/codes/Grandeur/grandeur.nf
2022-03-14 09:23:00 [INFO] STEP3a: Adding dataInputs
2022-03-14 09:23:00 [INFO] STEP3b: Adding parameter options
2022-03-14 09:23:00 [INFO] STEP4: Generating parameters XML to /Users/keng/codes/Grandeur/Grandeur.pipeline.xml
[1] "/Users/keng/codes/Grandeur/Grandeur.pipeline.xml"
2022-03-14 09:23:00 [INFO] READING IN: /Users/keng/codes/Grandeur/./configs/grandeur_template.config
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE: process {
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   cpus = 2
2022-03-14 09:23:00 [INFO] CPUS_PARSED: 2
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   memory = '4 GB'
2022-03-14 09:23:00 [INFO] MEM_PARSED: 4 GB
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:seqyclean{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 141
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: seqyclean
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME seqyclean
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME seqyclean
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = seqyclean_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:spades{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 144
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: spades
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME spades
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME spades
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.maxcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 16
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 16
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME spades
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = spades_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:fastqc{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 148
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: fastqc
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME fastqc
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME fastqc
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = fastqc_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:mash_dist{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 151
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: mash_dist
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME mash_dist
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME mash_dist
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.medcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME mash_dist
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = mash_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:mash_sketch{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 155
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: mash_sketch
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME mash_sketch
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME mash_sketch
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = mash_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:prokka{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 158
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: prokka
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME prokka
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME prokka
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.maxcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 16
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 16
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME prokka
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = prokka_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:quast{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 162
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: quast
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME quast
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME quast
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = quast_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:shuffle{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 165
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: shuffle
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME shuffle
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME shuffle
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = lyveset_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:cg_pipeline{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 168
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: cg_pipeline
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME cg_pipeline
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME cg_pipeline
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.medcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME cg_pipeline
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = lyveset_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:seqsero2{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 172
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: seqsero2
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME seqsero2
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME seqsero2
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.medcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME seqsero2
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = seqsero2_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:shigatyper{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 176
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: shigatyper
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME shigatyper
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME shigatyper
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.medcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME shigatyper
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = shigatyper_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:kleborate{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 180
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: kleborate
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME kleborate
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME kleborate
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.medcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME kleborate
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = kleborate_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:serotypefinder{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 184
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: serotypefinder
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME serotypefinder
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME serotypefinder
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.medcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME serotypefinder
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = serotypefinder_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:amrfinderplus{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 188
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: amrfinderplus
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME amrfinderplus
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME amrfinderplus
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.medcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME amrfinderplus
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = amrfinderplus_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:kraken2{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 192
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: kraken2
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME kraken2
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME kraken2
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.maxcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 16
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 16
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME kraken2
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = kraken2_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:blastn{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 196
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: blastn
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME blastn
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME blastn
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.medcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME blastn
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = blastn_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:bwa{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 200
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: bwa
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME bwa
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME bwa
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.medcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME bwa
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = bwa_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:sort{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 204
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: sort
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME sort
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME sort
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.medcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME sort
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = samtools_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:create{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 208
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: create
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME create
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME create
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = blobtools_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:view{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 211
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: view
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME view
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME view
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = blobtools_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:blobtools{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 214
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: blobtools
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME blobtools
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME blobtools
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = blobtools_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:mlst{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 217
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: mlst
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME mlst
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME mlst
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = mlst_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:summary{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 220
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: summary
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME summary
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME summary
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = summary_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:multiqc{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 223
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: multiqc
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME multiqc
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME multiqc
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = multiqc_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:roary{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 226
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: roary
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME roary
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME roary
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.maxcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 16
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 16
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME roary
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = roary_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:iqtree2{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 230
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: iqtree2
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME iqtree2
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME iqtree2
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.maxcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 16
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 16
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME iqtree2
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = iqtree_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:snp_dists{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 234
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME snp_dists
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME snp_dists
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = snpdists_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_CLOSURE: }
2022-03-14 09:23:00 [INFO] READING IN: /Users/keng/codes/Grandeur/./configs/grandeur_template.config
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE: process {
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   cpus = 2
2022-03-14 09:23:00 [INFO] CPUS_PARSED: 2
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   memory = '4 GB'
2022-03-14 09:23:00 [INFO] MEM_PARSED: 4 GB
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:seqyclean{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 141
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: seqyclean
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME seqyclean
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME seqyclean
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = seqyclean_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:spades{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 144
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: spades
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME spades
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME spades
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.maxcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 16
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 16
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME spades
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = spades_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:fastqc{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 148
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: fastqc
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME fastqc
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME fastqc
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = fastqc_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:mash_dist{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 151
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: mash_dist
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME mash_dist
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME mash_dist
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.medcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME mash_dist
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = mash_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:mash_sketch{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 155
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: mash_sketch
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME mash_sketch
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME mash_sketch
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = mash_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:prokka{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 158
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: prokka
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME prokka
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME prokka
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.maxcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 16
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 16
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME prokka
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = prokka_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:quast{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 162
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: quast
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME quast
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME quast
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = quast_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:shuffle{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 165
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: shuffle
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME shuffle
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME shuffle
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = lyveset_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:cg_pipeline{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 168
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: cg_pipeline
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME cg_pipeline
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME cg_pipeline
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.medcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME cg_pipeline
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = lyveset_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:seqsero2{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 172
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: seqsero2
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME seqsero2
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME seqsero2
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.medcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME seqsero2
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = seqsero2_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:shigatyper{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 176
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: shigatyper
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME shigatyper
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME shigatyper
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.medcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME shigatyper
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = shigatyper_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:kleborate{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 180
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: kleborate
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME kleborate
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME kleborate
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.medcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME kleborate
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = kleborate_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:serotypefinder{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 184
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: serotypefinder
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME serotypefinder
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME serotypefinder
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.medcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME serotypefinder
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = serotypefinder_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:amrfinderplus{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 188
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: amrfinderplus
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME amrfinderplus
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME amrfinderplus
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.medcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME amrfinderplus
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = amrfinderplus_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:kraken2{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 192
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: kraken2
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME kraken2
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME kraken2
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.maxcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 16
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 16
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME kraken2
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = kraken2_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:blastn{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 196
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: blastn
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME blastn
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME blastn
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.medcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME blastn
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = blastn_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:bwa{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 200
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: bwa
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME bwa
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME bwa
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.medcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME bwa
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = bwa_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:sort{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 204
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: sort
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME sort
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME sort
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.medcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 4
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME sort
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = samtools_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:create{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 208
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: create
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME create
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME create
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = blobtools_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:view{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 211
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: view
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME view
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME view
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = blobtools_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:blobtools{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 214
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: blobtools
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME blobtools
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME blobtools
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = blobtools_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:mlst{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 217
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: mlst
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME mlst
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME mlst
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = mlst_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:summary{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 220
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: summary
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME summary
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME summary
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = summary_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:multiqc{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 223
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: multiqc
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME multiqc
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME multiqc
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = multiqc_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:roary{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 226
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: roary
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME roary
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME roary
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.maxcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 16
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 16
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME roary
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = roary_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:iqtree2{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 230
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: iqtree2
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME iqtree2
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME iqtree2
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] INITIAL_LINE:     cpus = params.maxcpus
2022-03-14 09:23:00 [INFO] TRANSLATED_LINE:     cpus = 16
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CPUS_PARSED: 16
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME iqtree2
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = iqtree_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:snp_dists{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 234
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME snp_dists
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME snp_dists
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = snpdists_container
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_CLOSURE: }
2022-03-14 09:23:00 [INFO] READING IN: /Users/keng/codes/Grandeur/./configs/UPHL.config
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE: process {
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:seqyclean{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 22
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: seqyclean
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME seqyclean
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME seqyclean
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = 'staphb/seqyclean:1.10.09'
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:mash_dist{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 25
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: mash_dist
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME mash_dist
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME mash_dist
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = 'staphb/mash:2.3'
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:mash_sketch{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 28
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: mash_sketch
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME mash_sketch
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME mash_sketch
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = 'staphb/mash:2.3'
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:spades{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 31
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: spades
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME spades
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME spades
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = 'staphb/spades:3.15.3'
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:seqsero2{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 34
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: seqsero2
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME seqsero2
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME seqsero2
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = 'staphb/seqsero2:1.2.1'
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:serotypefinder{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 37
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: serotypefinder
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME serotypefinder
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME serotypefinder
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = 'staphb/serotypefinder:2.0.1'
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:shigatyper{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 40
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: shigatyper
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME shigatyper
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME shigatyper
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = 'andrewlangvt/shigatyper:1'
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_FOUND:   withName:amrfinderplus{
2022-03-14 09:23:00 [INFO] LINE_NUMBER: 43
2022-03-14 09:23:00 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: amrfinderplus
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME amrfinderplus
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME amrfinderplus
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = 'staphb/ncbi-amrfinderplus:3.10.16'
2022-03-14 09:23:00 [INFO] PROCESS_LABEL_NAME amrfinderplus
[1] TRUE
2022-03-14 09:23:00 [INFO] NAMES: default, seqyclean, spades, fastqc, mash_dist, mash_sketch, prokka, quast, shuffle, cg_pipeline, seqsero2, shigatyper, kleborate, serotypefinder, amrfinderplus, kraken2, blastn, bwa, sort, create, view, blobtools, mlst, summary, multiqc, roary, iqtree2, snp_dists
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:00 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:00 [INFO] EXITING_PROCESS_CLOSURE: }
$default
$default$errorStrategy
[1] "ignore"

$default$cpus
[1] "2"

$default$mem
[1] "4 GB"


$seqyclean
$seqyclean$errorStrategy
[1] "ignore"

$seqyclean$container
[1] "    container = 'staphb/seqyclean:1.10.09'"


$spades
$spades$errorStrategy
[1] "ignore"

$spades$container
[1] "    container = 'staphb/spades:3.15.3'"


$fastqc
$fastqc$errorStrategy
[1] "ignore"

$fastqc$container
[1] "    container = fastqc_container"


$mash_dist
$mash_dist$errorStrategy
[1] "ignore"

$mash_dist$container
[1] "    container = 'staphb/mash:2.3'"


$mash_sketch
$mash_sketch$errorStrategy
[1] "ignore"

$mash_sketch$container
[1] "    container = 'staphb/mash:2.3'"


$prokka
$prokka$errorStrategy
[1] "ignore"

$prokka$cpus
[1] "16"

$prokka$container
[1] "    container = prokka_container"


$quast
$quast$errorStrategy
[1] "ignore"

$quast$container
[1] "    container = quast_container"


$shuffle
$shuffle$errorStrategy
[1] "ignore"

$shuffle$container
[1] "    container = lyveset_container"


$cg_pipeline
$cg_pipeline$errorStrategy
[1] "ignore"

$cg_pipeline$cpus
[1] "4"

$cg_pipeline$container
[1] "    container = lyveset_container"


$seqsero2
$seqsero2$errorStrategy
[1] "ignore"

$seqsero2$container
[1] "    container = 'staphb/seqsero2:1.2.1'"


$shigatyper
$shigatyper$errorStrategy
[1] "ignore"

$shigatyper$container
[1] "    container = 'andrewlangvt/shigatyper:1'"


$kleborate
$kleborate$errorStrategy
[1] "ignore"

$kleborate$cpus
[1] "4"

$kleborate$container
[1] "    container = kleborate_container"


$serotypefinder
$serotypefinder$errorStrategy
[1] "ignore"

$serotypefinder$container
[1] "    container = 'staphb/serotypefinder:2.0.1'"


$amrfinderplus
$amrfinderplus$errorStrategy
[1] "ignore"

$amrfinderplus$container
[1] "    container = 'staphb/ncbi-amrfinderplus:3.10.16'"


$kraken2
$kraken2$errorStrategy
[1] "ignore"

$kraken2$cpus
[1] "16"

$kraken2$container
[1] "    container = kraken2_container"


$blastn
$blastn$errorStrategy
[1] "ignore"

$blastn$cpus
[1] "4"

$blastn$container
[1] "    container = blastn_container"


$bwa
$bwa$errorStrategy
[1] "ignore"

$bwa$cpus
[1] "4"

$bwa$container
[1] "    container = bwa_container"


$sort
$sort$errorStrategy
[1] "ignore"

$sort$cpus
[1] "4"

$sort$container
[1] "    container = samtools_container"


$create
$create$errorStrategy
[1] "ignore"

$create$container
[1] "    container = blobtools_container"


$view
$view$errorStrategy
[1] "ignore"

$view$container
[1] "    container = blobtools_container"


$blobtools
$blobtools$errorStrategy
[1] "ignore"

$blobtools$container
[1] "    container = blobtools_container"


$mlst
$mlst$errorStrategy
[1] "ignore"

$mlst$container
[1] "    container = mlst_container"


$summary
$summary$errorStrategy
[1] "ignore"

$summary$container
[1] "    container = summary_container"


$multiqc
$multiqc$errorStrategy
[1] "ignore"

$multiqc$container
[1] "    container = multiqc_container"


$roary
$roary$errorStrategy
[1] "ignore"

$roary$cpus
[1] "16"

$roary$container
[1] "    container = roary_container"


$iqtree2
$iqtree2$errorStrategy
[1] "ignore"

$iqtree2$cpus
[1] "16"

$iqtree2$container
[1] "    container = iqtree_container"


$snp_dists
$snp_dists$errorStrategy
[1] "ignore"

$snp_dists$container
[1] "    container = snpdists_container"


2022-03-14 09:23:02 [INFO] script /Users/keng/codes/Grandeur/grandeur.ica.nf is DSL2 enabled: FALSE
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_NAME: seqyclean
2022-03-14 09:23:02 [INFO] PROCESS_LINE: process seqyclean {
2022-03-14 09:23:02 [INFO] ADDING_LINE: process seqyclean {
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   cpus 1
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   container 'staphb/seqyclean:latest'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   container 'staphb/seqyclean:latest'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: seqyclean
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 1 MEM  CONTAINER 'staphb/seqyclean:latest'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   sample != null
2022-03-14 09:23:02 [INFO] ADDING_LINE:   sample != null
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: seqyclean
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 1 MEM  CONTAINER 'staphb/seqyclean:latest'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple val(sample), file(reads) from reads_seqyclean
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple val(sample), file(reads) from reads_seqyclean
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:02 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, file("seqyclean/${sample}_clean_PE{1,2}.fastq.gz") into clean_reads_mash, clean_reads_cg, clean_reads_seqsero2, clean_reads_bwa, clean_reads_shigatyper, clean_reads_kraken2, clean_reads_spades
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, file("seqyclean/${sample}_clean_PE{1,2}.fastq.gz") into clean_reads_mash, clean_reads_cg, clean_reads_seqsero2, clean_reads_bwa, clean_reads_shigatyper, clean_reads_kraken2, clean_reads_spades
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("seqyclean/${sample}_clean_SE.fastq.gz")
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("seqyclean/${sample}_clean_SE.fastq.gz")
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("seqyclean/${sample}_clean_SummaryStatistics.tsv") into seqyclean_files, seqyclean_files_combine
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("seqyclean/${sample}_clean_SummaryStatistics.tsv") into seqyclean_files, seqyclean_files_combine
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("seqyclean/${sample}_clean_SummaryStatistics.txt")
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("seqyclean/${sample}_clean_SummaryStatistics.txt")
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(perc_kept) into seqyclean_perc_kept_results
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(perc_kept) into seqyclean_perc_kept_results
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(kept) into seqyclean_pairskept_results
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(kept) into seqyclean_pairskept_results
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:02 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:02 [INFO] ADDING_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] ADDING_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "seqyclean version: $(seqyclean -h | grep Version | head -n 1)" >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "seqyclean version: $(seqyclean -h | grep Version | head -n 1)" >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     seqyclean !{params.seqyclean_options} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:     seqyclean !{params.seqyclean_options} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       -c !{params.seqyclean_contaminant_file} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       -c !{params.seqyclean_contaminant_file} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       -1 !{reads[0]} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       -1 !{reads[0]} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       -2 !{reads[1]} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       -2 !{reads[1]} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       -o seqyclean/!{sample}_clean \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       -o seqyclean/!{sample}_clean \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       -gz \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       -gz \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       2>> $err_file >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:       2>> $err_file >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     kept=$(cut -f 58 seqyclean/!{sample}_clean_SummaryStatistics.tsv | grep -v "Kept" | head -n 1)
2022-03-14 09:23:02 [INFO] ADDING_LINE:     kept=$(cut -f 58 seqyclean/!{sample}_clean_SummaryStatistics.tsv | grep -v "Kept" | head -n 1)
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     perc_kept=$(cut -f 59 seqyclean/!{sample}_clean_SummaryStatistics.tsv | grep -v "Kept" | head -n 1)
2022-03-14 09:23:02 [INFO] ADDING_LINE:     perc_kept=$(cut -f 59 seqyclean/!{sample}_clean_SummaryStatistics.tsv | grep -v "Kept" | head -n 1)
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -z "$kept" ] ; then kept="0" ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -z "$kept" ] ; then kept="0" ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -z "$kept" ] ; then kept="0" ; fi
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -z "$perc_kept" ] ; then perc_kept="0" ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -z "$perc_kept" ] ; then perc_kept="0" ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -z "$perc_kept" ] ; then perc_kept="0" ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE: }
2022-03-14 09:23:02 [INFO] UPDATING_PROCESS seqyclean
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_NAME: spades
2022-03-14 09:23:02 [INFO] PROCESS_LINE: process spades {
2022-03-14 09:23:02 [INFO] ADDING_LINE: process spades {
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   cpus params.maxcpus
2022-03-14 09:23:02 [INFO] INITIAL_LINE:   cpus params.maxcpus
2022-03-14 09:23:02 [INFO] TRANSLATED_LINE:   cpus 16
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   container 'staphb/spades:latest'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   container 'staphb/spades:latest'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: spades
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 16 MEM  CONTAINER 'staphb/spades:latest'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   params.spades
2022-03-14 09:23:02 [INFO] ADDING_LINE:   params.spades
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: spades
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 16 MEM  CONTAINER 'staphb/spades:latest'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple val(sample), file(reads) from clean_reads_spades
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple val(sample), file(reads) from clean_reads_spades
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:02 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   path("${task.process}/${sample}")
2022-03-14 09:23:02 [INFO] ADDING_LINE:   path("${task.process}/${sample}")
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, file("contigs/${sample}_contigs.fa") into contigs_prokka, contigs_quast, contigs_blastn, contigs_mlst, contigs_bwa, contigs_create, contigs_kleborate, contigs_amrfinder, contigs_serotypefinder
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, file("contigs/${sample}_contigs.fa") into contigs_prokka, contigs_quast, contigs_blastn, contigs_mlst, contigs_bwa, contigs_create, contigs_kleborate, contigs_amrfinder, contigs_serotypefinder
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:02 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     mkdir -p !{task.process} contigs logs/!{task.process}
2022-03-14 09:23:02 [INFO] ADDING_LINE:     mkdir -p !{task.process} contigs logs/!{task.process}
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] ADDING_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     spades.py --version >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     spades.py --version >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     spades.py !{params.spades_options} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:     spades.py !{params.spades_options} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       -1 !{reads[0]} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       -1 !{reads[0]} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       -2 !{reads[1]} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       -2 !{reads[1]} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       --threads !{task.cpus} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       --threads !{task.cpus} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       -o !{task.process}/!{sample} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       -o !{task.process}/!{sample} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       2>> $err_file >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:       2>> $err_file >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     cp !{task.process}/!{sample}/contigs.fasta contigs/!{sample}_contigs.fa
2022-03-14 09:23:02 [INFO] ADDING_LINE:     cp !{task.process}/!{sample}/contigs.fasta contigs/!{sample}_contigs.fa
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE: }
2022-03-14 09:23:02 [INFO] UPDATING_PROCESS spades
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_NAME: fastqc
2022-03-14 09:23:02 [INFO] PROCESS_LINE: process fastqc {
2022-03-14 09:23:02 [INFO] ADDING_LINE: process fastqc {
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   cpus 1
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   container 'staphb/fastqc:latest'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   container 'staphb/fastqc:latest'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: fastqc
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 1 MEM  CONTAINER 'staphb/fastqc:latest'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   params.fastqc && sample != null
2022-03-14 09:23:02 [INFO] ADDING_LINE:   params.fastqc && sample != null
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: fastqc
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 1 MEM  CONTAINER 'staphb/fastqc:latest'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple val(sample), file(raw) from reads_fastqc
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple val(sample), file(raw) from reads_fastqc
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:02 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("${task.process}/*.html")
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("${task.process}/*.html")
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("${task.process}/*_fastqc.zip") into fastqc_files
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("${task.process}/*_fastqc.zip") into fastqc_files
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(raw_1) into fastqc_1_results
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(raw_1) into fastqc_1_results
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(raw_2) into fastqc_2_results
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(raw_2) into fastqc_2_results
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:02 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:02 [INFO] ADDING_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] ADDING_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     fastqc --version >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     fastqc --version >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     fastqc !{params.fastqc_options} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:     fastqc !{params.fastqc_options} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       --outdir fastqc \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       --outdir fastqc \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       --threads !{task.cpus} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       --threads !{task.cpus} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       !{raw} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       !{raw} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       2>> $err_file >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:       2>> $err_file >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     zipped_fastq=($(ls fastqc/*fastqc.zip) "")
2022-03-14 09:23:02 [INFO] ADDING_LINE:     zipped_fastq=($(ls fastqc/*fastqc.zip) "")
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     raw_1=$(unzip -p ${zipped_fastq[0]} */fastqc_data.txt | grep "Total Sequences" | awk '{ print $3 }' )
2022-03-14 09:23:02 [INFO] ADDING_LINE:     raw_1=$(unzip -p ${zipped_fastq[0]} */fastqc_data.txt | grep "Total Sequences" | awk '{ print $3 }' )
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     raw_2=$(unzip -p fastqc/*fastqc.zip */fastqc_data.txt | grep "Total Sequences" | awk '{ print $3 }' )
2022-03-14 09:23:02 [INFO] ADDING_LINE:     raw_2=$(unzip -p fastqc/*fastqc.zip */fastqc_data.txt | grep "Total Sequences" | awk '{ print $3 }' )
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -z "$raw_1" ] ; then raw_1="0" ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -z "$raw_1" ] ; then raw_1="0" ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -z "$raw_1" ] ; then raw_1="0" ; fi
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -z "$raw_2" ] ; then raw_2="0" ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -z "$raw_2" ] ; then raw_2="0" ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -z "$raw_2" ] ; then raw_2="0" ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE: }
2022-03-14 09:23:02 [INFO] UPDATING_PROCESS fastqc
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_NAME: mash_sketch
2022-03-14 09:23:02 [INFO] PROCESS_LINE: process mash_sketch {
2022-03-14 09:23:02 [INFO] ADDING_LINE: process mash_sketch {
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   cpus 1
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   container 'staphb/mash:latest'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   container 'staphb/mash:latest'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: mash_sketch
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 1 MEM  CONTAINER 'staphb/mash:latest'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   params.mash
2022-03-14 09:23:02 [INFO] ADDING_LINE:   params.mash
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: mash_sketch
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 1 MEM  CONTAINER 'staphb/mash:latest'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple val(sample), file(reads) from clean_reads_mash
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple val(sample), file(reads) from clean_reads_mash
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:02 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, file("mash/${sample}.msh") into mash_sketch_files optional true
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, file("mash/${sample}.msh") into mash_sketch_files optional true
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(genome_size) into mash_genome_size_results, mash_genome_size_gc
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(genome_size) into mash_genome_size_results, mash_genome_size_gc
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(coverage) into mash_coverage_results
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(coverage) into mash_coverage_results
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:02 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     mkdir -p mash logs/!{task.process}
2022-03-14 09:23:02 [INFO] ADDING_LINE:     mkdir -p mash logs/!{task.process}
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] ADDING_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "mash version: $(mash --version | head -n 1 )" >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "mash version: $(mash --version | head -n 1 )" >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     cat !{reads} | mash sketch -m 2 -o mash/!{sample} - 2>> $err_file | tee $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     cat !{reads} | mash sketch -m 2 -o mash/!{sample} - 2>> $err_file | tee $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     genome_size=$(grep "Estimated genome size" $err_file | awk '{print $4}' )
2022-03-14 09:23:02 [INFO] ADDING_LINE:     genome_size=$(grep "Estimated genome size" $err_file | awk '{print $4}' )
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     coverage=$(grep "Estimated coverage" $err_file | awk '{print $3}' )
2022-03-14 09:23:02 [INFO] ADDING_LINE:     coverage=$(grep "Estimated coverage" $err_file | awk '{print $3}' )
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE: }
2022-03-14 09:23:02 [INFO] UPDATING_PROCESS mash_sketch
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_NAME: mash_dist
2022-03-14 09:23:02 [INFO] PROCESS_LINE: process mash_dist {
2022-03-14 09:23:02 [INFO] ADDING_LINE: process mash_dist {
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   cpus params.medcpus
2022-03-14 09:23:02 [INFO] INITIAL_LINE:   cpus params.medcpus
2022-03-14 09:23:02 [INFO] TRANSLATED_LINE:   cpus 4
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   container 'staphb/mash:latest'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   container 'staphb/mash:latest'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: mash_dist
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 4 MEM  CONTAINER 'staphb/mash:latest'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   params.mash
2022-03-14 09:23:02 [INFO] ADDING_LINE:   params.mash
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: mash_dist
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 4 MEM  CONTAINER 'staphb/mash:latest'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple val(sample), file(msh) from mash_sketch_files.concat(fastas_mash)
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple val(sample), file(msh) from mash_sketch_files.concat(fastas_mash)
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:02 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, file("mash/${sample}_mashdist.txt") optional true
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, file("mash/${sample}_mashdist.txt") optional true
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(genus) into mash_genus_results, mash_genus_prokka, mash_genus_gc, mash_genus_amrfinder
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(genus) into mash_genus_results, mash_genus_prokka, mash_genus_gc, mash_genus_amrfinder
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(species) into mash_species_results, mash_species_prokka, mash_species_gc, mash_species_amrfinder
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(species) into mash_species_results, mash_species_prokka, mash_species_gc, mash_species_amrfinder
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(full_mash) into mash_full_results
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(full_mash) into mash_full_results
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(pvalue) into mash_pvalue_results
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(pvalue) into mash_pvalue_results
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(distance) into mash_distance_results
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(distance) into mash_distance_results
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(salmonella_flag) into salmonella_flag
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(salmonella_flag) into salmonella_flag
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(ecoli_flag) into ecoli_flag, shigella_flag
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(ecoli_flag) into ecoli_flag, shigella_flag
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(klebsiella_flag) into klebsiella_flag
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(klebsiella_flag) into klebsiella_flag
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:02 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     mkdir -p mash logs/!{task.process}
2022-03-14 09:23:02 [INFO] ADDING_LINE:     mkdir -p mash logs/!{task.process}
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] ADDING_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "mash version: $(mash --version | head -n 1 )" >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "mash version: $(mash --version | head -n 1 )" >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     mash dist -p !{task.cpus} !{params.mash_options} !{params.mash_reference} !{msh} | sort -gk3 > mash/!{sample}_mashdist.txt 2>> $err_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     mash dist -p !{task.cpus} !{params.mash_options} !{params.mash_reference} !{msh} | sort -gk3 > mash/!{sample}_mashdist.txt 2>> $err_file
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ ! -s "mash/!{sample}_mashdist.txt" ]
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ ! -s "mash/!{sample}_mashdist.txt" ]
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ ! -s "mash/!{sample}_mashdist.txt" ]
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:02 [INFO] ADDING_LINE:     then
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       echo "!{sample} had no mash results with '!{params.mash_options}'. Trying again without those parameters." 2>> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:       echo "!{sample} had no mash results with '!{params.mash_options}'. Trying again without those parameters." 2>> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       mash dist -p !{task.cpus} !{params.mash_reference} !{msh} | sort -gk3 > mash/!{sample}_mashdist.txt 2>> $err_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:       mash dist -p !{task.cpus} !{params.mash_reference} !{msh} | sort -gk3 > mash/!{sample}_mashdist.txt 2>> $err_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     mash_result=($(head -n 1 mash/!{sample}_mashdist.txt | head -n 1 | cut -f 1 | cut -f 8 -d "-" | cut -f 1,2 -d "_" | cut -f 1 -d "." | tr "_" " " ) 'missing' 'missing')
2022-03-14 09:23:02 [INFO] ADDING_LINE:     mash_result=($(head -n 1 mash/!{sample}_mashdist.txt | head -n 1 | cut -f 1 | cut -f 8 -d "-" | cut -f 1,2 -d "_" | cut -f 1 -d "." | tr "_" " " ) 'missing' 'missing')
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     genus=${mash_result[0]}
2022-03-14 09:23:02 [INFO] ADDING_LINE:     genus=${mash_result[0]}
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     species=${mash_result[1]}
2022-03-14 09:23:02 [INFO] ADDING_LINE:     species=${mash_result[1]}
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     full_mash=$(head -n 1 mash/!{sample}_mashdist.txt | cut -f 1 )
2022-03-14 09:23:02 [INFO] ADDING_LINE:     full_mash=$(head -n 1 mash/!{sample}_mashdist.txt | cut -f 1 )
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     pvalue=$(head -n 1 mash/!{sample}_mashdist.txt | cut -f 4 )
2022-03-14 09:23:02 [INFO] ADDING_LINE:     pvalue=$(head -n 1 mash/!{sample}_mashdist.txt | cut -f 4 )
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     distance=$(head -n 1 mash/!{sample}_mashdist.txt | cut -f 3 )
2022-03-14 09:23:02 [INFO] ADDING_LINE:     distance=$(head -n 1 mash/!{sample}_mashdist.txt | cut -f 3 )
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -z "$full_mash" ] ; then full_mash='missing' ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -z "$full_mash" ] ; then full_mash='missing' ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -z "$full_mash" ] ; then full_mash='missing' ; fi
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -z "$pvalue" ] ; then pvalue='NA' ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -z "$pvalue" ] ; then pvalue='NA' ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -z "$pvalue" ] ; then pvalue='NA' ; fi
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -z "$distance" ] ; then distance='NA' ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -z "$distance" ] ; then distance='NA' ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -z "$distance" ] ; then distance='NA' ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     salmonella_flag=''
2022-03-14 09:23:02 [INFO] ADDING_LINE:     salmonella_flag=''
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     find_salmonella=$(head mash/!{sample}_mashdist.txt | grep "Salmonella" | head -n 1 )
2022-03-14 09:23:02 [INFO] ADDING_LINE:     find_salmonella=$(head mash/!{sample}_mashdist.txt | grep "Salmonella" | head -n 1 )
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -n "$find_salmonella" ] ; then salmonella_flag="found" ; else salmonella_flag="not" ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -n "$find_salmonella" ] ; then salmonella_flag="found" ; else salmonella_flag="not" ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -n "$find_salmonella" ] ; then salmonella_flag="found" ; else salmonella_flag="not" ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     ecoli_flag=''
2022-03-14 09:23:02 [INFO] ADDING_LINE:     ecoli_flag=''
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     find_ecoli=$(head mash/!{sample}_mashdist.txt | grep -e "Escherichia" -e "Shigella" | head -n 1 )
2022-03-14 09:23:02 [INFO] ADDING_LINE:     find_ecoli=$(head mash/!{sample}_mashdist.txt | grep -e "Escherichia" -e "Shigella" | head -n 1 )
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -n "$find_ecoli" ] ; then ecoli_flag="found" ; else ecoli_flag="not" ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -n "$find_ecoli" ] ; then ecoli_flag="found" ; else ecoli_flag="not" ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -n "$find_ecoli" ] ; then ecoli_flag="found" ; else ecoli_flag="not" ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     klebsiella_flag=''
2022-03-14 09:23:02 [INFO] ADDING_LINE:     klebsiella_flag=''
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     find_klebsiella=$(head mash/!{sample}_mashdist.txt | grep -e "Klebsiella" -e "Enterobacter" -e "Serratia" | head -n 1 )
2022-03-14 09:23:02 [INFO] ADDING_LINE:     find_klebsiella=$(head mash/!{sample}_mashdist.txt | grep -e "Klebsiella" -e "Enterobacter" -e "Serratia" | head -n 1 )
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -n "$find_klebsiella" ] ; then klebsiella_flag="found" ; else klebsiella_flag="not" ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -n "$find_klebsiella" ] ; then klebsiella_flag="found" ; else klebsiella_flag="not" ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -n "$find_klebsiella" ] ; then klebsiella_flag="found" ; else klebsiella_flag="not" ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE: }
2022-03-14 09:23:02 [INFO] UPDATING_PROCESS mash_dist
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_NAME: prokka
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   process prokka {
2022-03-14 09:23:02 [INFO] ADDING_LINE:   process prokka {
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     tag "${sample}"
2022-03-14 09:23:02 [INFO] ADDING_LINE:     tag "${sample}"
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     cpus params.maxcpus
2022-03-14 09:23:02 [INFO] INITIAL_LINE:     cpus params.maxcpus
2022-03-14 09:23:02 [INFO] TRANSLATED_LINE:     cpus 16
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     container 'staphb/prokka:latest'
2022-03-14 09:23:02 [INFO] ADDING_LINE:     container 'staphb/prokka:latest'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     when:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:     
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: prokka
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 16 MEM  CONTAINER 'staphb/prokka:latest'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:     when:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     params.prokka
2022-03-14 09:23:02 [INFO] ADDING_LINE:     params.prokka
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     input:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:     input:
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: prokka
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 16 MEM  CONTAINER 'staphb/prokka:latest'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:     input:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     tuple val(sample), file(contigs), val(genus), val(species) from contigs_prokka.concat(fastas_prokka).join(mash_genus_prokka, remainder: true, by:0).join(mash_species_prokka, remainder: true, by:0)
2022-03-14 09:23:02 [INFO] ADDING_LINE:     tuple val(sample), file(contigs), val(genus), val(species) from contigs_prokka.concat(fastas_prokka).join(mash_genus_prokka, remainder: true, by:0).join(mash_species_prokka, remainder: true, by:0)
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     output:
2022-03-14 09:23:02 [INFO] ADDING_LINE:     output:
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     file("prokka/${sample}/${sample}.{err,faa,ffn,fna,fsa,gbk,gff,log,sqn,tbl,tsv}")
2022-03-14 09:23:02 [INFO] ADDING_LINE:     file("prokka/${sample}/${sample}.{err,faa,ffn,fna,fsa,gbk,gff,log,sqn,tbl,tsv}")
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     file("prokka/${sample}/${sample}.txt") into prokka_files
2022-03-14 09:23:02 [INFO] ADDING_LINE:     file("prokka/${sample}/${sample}.txt") into prokka_files
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     file("gff/${sample}.gff") into gffs
2022-03-14 09:23:02 [INFO] ADDING_LINE:     file("gff/${sample}.gff") into gffs
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] ADDING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     shell:
2022-03-14 09:23:02 [INFO] ADDING_LINE:     shell:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       mkdir -p prokka gff logs/!{task.process}
2022-03-14 09:23:02 [INFO] ADDING_LINE:       mkdir -p prokka gff logs/!{task.process}
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] ADDING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] ADDING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] ADDING_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] ADDING_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:       echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       prokka -v >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:       prokka -v >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:       echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:       cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       prokka !{params.prokka_options} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       prokka !{params.prokka_options} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:         --cpu !{task.cpus} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:         --cpu !{task.cpus} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:         --centre !{params.center} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:         --centre !{params.center} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:         --outdir prokka/!{sample} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:         --outdir prokka/!{sample} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:         --prefix !{sample} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:         --prefix !{sample} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:         --genus !{genus} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:         --genus !{genus} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:         --species !{species} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:         --species !{species} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:         --force !{contigs} 2>> $err_file | tee -a $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:         --force !{contigs} 2>> $err_file | tee -a $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       cp prokka/!{sample}/!{sample}.gff gff/!{sample}.gff
2022-03-14 09:23:02 [INFO] ADDING_LINE:       cp prokka/!{sample}/!{sample}.gff gff/!{sample}.gff
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   }
2022-03-14 09:23:02 [INFO] UPDATING_PROCESS prokka
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_NAME: quast
2022-03-14 09:23:02 [INFO] PROCESS_LINE: process quast {
2022-03-14 09:23:02 [INFO] ADDING_LINE: process quast {
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   cpus 1
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   container 'staphb/quast:latest'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   container 'staphb/quast:latest'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: quast
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 1 MEM  CONTAINER 'staphb/quast:latest'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   params.quast
2022-03-14 09:23:02 [INFO] ADDING_LINE:   params.quast
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: quast
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 1 MEM  CONTAINER 'staphb/quast:latest'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple val(sample), file(contigs) from contigs_quast.concat(fastas_quast)
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple val(sample), file(contigs) from contigs_quast.concat(fastas_quast)
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:02 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   path("quast/${sample}")
2022-03-14 09:23:02 [INFO] ADDING_LINE:   path("quast/${sample}")
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("quast/${sample}_quast_report.tsv") into quast_files optional true
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("quast/${sample}_quast_report.tsv") into quast_files optional true
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("quast/${sample}/transposed_report.tsv") into quast_files_combine optional true
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("quast/${sample}/transposed_report.tsv") into quast_files_combine optional true
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(gc) into quast_gc_results
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(gc) into quast_gc_results
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(num_contigs) into quast_contigs_results
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(num_contigs) into quast_contigs_results
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(n50) into quast_N50_contigs_results
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(n50) into quast_N50_contigs_results
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(length) into quast_length_results
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(length) into quast_length_results
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:02 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:02 [INFO] ADDING_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] ADDING_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     quast.py --version >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     quast.py --version >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     quast.py !{params.quast_options} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:     quast.py !{params.quast_options} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       !{contigs} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       !{contigs} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       --output-dir quast/!{sample} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       --output-dir quast/!{sample} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       --threads !{task.cpus} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       --threads !{task.cpus} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       2>> $err_file | tee -a $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:       2>> $err_file | tee -a $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     gc=$(grep "GC (" quast/!{sample}/report.txt | awk '{print $3}' )
2022-03-14 09:23:02 [INFO] ADDING_LINE:     gc=$(grep "GC (" quast/!{sample}/report.txt | awk '{print $3}' )
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     num_contigs=$(grep "contigs" quast/!{sample}/report.txt | grep -v "(" | awk '{print $3}' )
2022-03-14 09:23:02 [INFO] ADDING_LINE:     num_contigs=$(grep "contigs" quast/!{sample}/report.txt | grep -v "(" | awk '{print $3}' )
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     n50=$(grep "N50" quast/!{sample}/report.txt | awk '{print $2}' )
2022-03-14 09:23:02 [INFO] ADDING_LINE:     n50=$(grep "N50" quast/!{sample}/report.txt | awk '{print $2}' )
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     length=$(grep "Total length" quast/!{sample}/report.txt | grep -v "(" | awk '{print $3}' )
2022-03-14 09:23:02 [INFO] ADDING_LINE:     length=$(grep "Total length" quast/!{sample}/report.txt | grep -v "(" | awk '{print $3}' )
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -z "$gc" ] ; then gc='NA' ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -z "$gc" ] ; then gc='NA' ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -z "$gc" ] ; then gc='NA' ; fi
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -z "$num_contigs" ] ; then num_contigs='NA' ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -z "$num_contigs" ] ; then num_contigs='NA' ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -z "$num_contigs" ] ; then num_contigs='NA' ; fi
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -z "$n50" ] ; then n50='NA' ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -z "$n50" ] ; then n50='NA' ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -z "$n50" ] ; then n50='NA' ; fi
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -z "$length" ] ; then length='NA' ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -z "$length" ] ; then length='NA' ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -z "$length" ] ; then length='NA' ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     cp quast/!{sample}/report.tsv quast/!{sample}_quast_report.tsv
2022-03-14 09:23:02 [INFO] ADDING_LINE:     cp quast/!{sample}/report.tsv quast/!{sample}_quast_report.tsv
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE: }
2022-03-14 09:23:02 [INFO] UPDATING_PROCESS quast
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_NAME: shuffle
2022-03-14 09:23:02 [INFO] PROCESS_LINE: process shuffle {
2022-03-14 09:23:02 [INFO] ADDING_LINE: process shuffle {
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   cpus 1
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   container 'staphb/lyveset:latest'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   container 'staphb/lyveset:latest'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: shuffle
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 1 MEM  CONTAINER 'staphb/lyveset:latest'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   params.cg_pipeline
2022-03-14 09:23:02 [INFO] ADDING_LINE:   params.cg_pipeline
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: shuffle
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 1 MEM  CONTAINER 'staphb/lyveset:latest'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple val(sample), file(reads) from clean_reads_cg
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple val(sample), file(reads) from clean_reads_cg
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:02 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, file("shuffled/${sample}_shuffled.fastq.gz") into shuffled_files
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, file("shuffled/${sample}_shuffled.fastq.gz") into shuffled_files
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:02 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     mkdir -p shuffled logs/!{task.process}
2022-03-14 09:23:02 [INFO] ADDING_LINE:     mkdir -p shuffled logs/!{task.process}
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] ADDING_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     run_assembly_shuffleReads.pl -gz !{reads} 2>> $err_file > shuffled/!{sample}_shuffled.fastq.gz
2022-03-14 09:23:02 [INFO] ADDING_LINE:     run_assembly_shuffleReads.pl -gz !{reads} 2>> $err_file > shuffled/!{sample}_shuffled.fastq.gz
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE: }
2022-03-14 09:23:02 [INFO] UPDATING_PROCESS shuffle
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_NAME: cg_pipeline
2022-03-14 09:23:02 [INFO] PROCESS_LINE: process cg_pipeline {
2022-03-14 09:23:02 [INFO] ADDING_LINE: process cg_pipeline {
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   cpus params.medcpus
2022-03-14 09:23:02 [INFO] INITIAL_LINE:   cpus params.medcpus
2022-03-14 09:23:02 [INFO] TRANSLATED_LINE:   cpus 4
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   container 'staphb/lyveset:latest'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   container 'staphb/lyveset:latest'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: cg_pipeline
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 4 MEM  CONTAINER 'staphb/lyveset:latest'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   params.cg_pipeline
2022-03-14 09:23:02 [INFO] ADDING_LINE:   params.cg_pipeline
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: cg_pipeline
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 4 MEM  CONTAINER 'staphb/lyveset:latest'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple val(sample), file(fastq), val(mash), val(genus), val(species), file(genome_file) from for_gc
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple val(sample), file(fastq), val(mash), val(genus), val(species), file(genome_file) from for_gc
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:02 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("cg_pipeline/${sample}_cg_pipeline_report.txt") optional true into cg_pipeline_files
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("cg_pipeline/${sample}_cg_pipeline_report.txt") optional true into cg_pipeline_files
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(read_length) into cg_avrl_results
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(read_length) into cg_avrl_results
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(quality) into cg_quality_results
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(quality) into cg_quality_results
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(coverage) into cg_cov_results
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(coverage) into cg_cov_results
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(reference_genome_length) into ref_genome_length
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(reference_genome_length) into ref_genome_length
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:02 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:02 [INFO] ADDING_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] ADDING_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     genome_length=''
2022-03-14 09:23:02 [INFO] ADDING_LINE:     genome_length=''
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ "!{genus}" != "null" ] && [ "!{species}" != "null" ] ; then genome_length=$(grep !{genus} !{genome_file} | grep !{species} | grep -v "#" | head -n 1 | cut -f 2 -d ":" | cut -f 1 -d "," | awk '{ print $0 "e+06" }') ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ "!{genus}" != "null" ] && [ "!{species}" != "null" ] ; then genome_length=$(grep !{genus} !{genome_file} | grep !{species} | grep -v "#" | head -n 1 | cut -f 2 -d ":" | cut -f 1 -d "," | awk '{ print $0 "e+06" }') ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ "!{genus}" != "null" ] && [ "!{species}" != "null" ] ; then genome_length=$(grep !{genus} !{genome_file} | grep !{species} | grep -v "#" | head -n 1 | cut -f 2 -d ":" | cut -f 1 -d "," | awk '{ print $0 "e+06" }') ; fi
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -z "$genome_length" ] && [ "!{mash}" != "null" ] ; then genome_length=$(echo !{mash} | xargs printf "%.0f" ) ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -z "$genome_length" ] && [ "!{mash}" != "null" ] ; then genome_length=$(echo !{mash} | xargs printf "%.0f" ) ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -z "$genome_length" ] && [ "!{mash}" != "null" ] ; then genome_length=$(echo !{mash} | xargs printf "%.0f" ) ; fi
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -n "$genome_length" ]
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -n "$genome_length" ]
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -n "$genome_length" ]
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:02 [INFO] ADDING_LINE:     then
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       run_assembly_readMetrics.pl !{fastq} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       run_assembly_readMetrics.pl !{fastq} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:         !{params.cg_pipeline_options} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:         !{params.cg_pipeline_options} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:         --fast \
2022-03-14 09:23:02 [INFO] ADDING_LINE:         --fast \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:         --numcpus !{task.cpus} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:         --numcpus !{task.cpus} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:         -e $genome_length \
2022-03-14 09:23:02 [INFO] ADDING_LINE:         -e $genome_length \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:         2>> $err_file > cg_pipeline/!{sample}_cg_pipeline_report.txt
2022-03-14 09:23:02 [INFO] ADDING_LINE:         2>> $err_file > cg_pipeline/!{sample}_cg_pipeline_report.txt
2022-03-14 09:23:02 [INFO] PROCESS_LINE:         read_length=$(cut -f 2 cg_pipeline/!{sample}_cg_pipeline_report.txt | tail -n 1 )
2022-03-14 09:23:02 [INFO] ADDING_LINE:         read_length=$(cut -f 2 cg_pipeline/!{sample}_cg_pipeline_report.txt | tail -n 1 )
2022-03-14 09:23:02 [INFO] PROCESS_LINE:         quality=$(cut -f 6 cg_pipeline/!{sample}_cg_pipeline_report.txt | tail -n 1 )
2022-03-14 09:23:02 [INFO] ADDING_LINE:         quality=$(cut -f 6 cg_pipeline/!{sample}_cg_pipeline_report.txt | tail -n 1 )
2022-03-14 09:23:02 [INFO] PROCESS_LINE:         coverage=$(cut -f 9 cg_pipeline/!{sample}_cg_pipeline_report.txt | tail -n 1 )
2022-03-14 09:23:02 [INFO] ADDING_LINE:         coverage=$(cut -f 9 cg_pipeline/!{sample}_cg_pipeline_report.txt | tail -n 1 )
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     else
2022-03-14 09:23:02 [INFO] ADDING_LINE:     else
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       genome_length='0'
2022-03-14 09:23:02 [INFO] ADDING_LINE:       genome_length='0'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       read_length='NA'
2022-03-14 09:23:02 [INFO] ADDING_LINE:       read_length='NA'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       quality='NA'
2022-03-14 09:23:02 [INFO] ADDING_LINE:       quality='NA'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       coverage='NA'
2022-03-14 09:23:02 [INFO] ADDING_LINE:       coverage='NA'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       echo "Could not determine genome length of isolate, so could not run GC pipeline" | tee $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:       echo "Could not determine genome length of isolate, so could not run GC pipeline" | tee $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -z "$read_length" ] ; then read_length='NA' ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -z "$read_length" ] ; then read_length='NA' ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -z "$read_length" ] ; then read_length='NA' ; fi
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -z "$quality" ] ; then quality='NA' ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -z "$quality" ] ; then quality='NA' ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -z "$quality" ] ; then quality='NA' ; fi
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -z "$coverage" ] ; then coverage='NA' ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -z "$coverage" ] ; then coverage='NA' ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -z "$coverage" ] ; then coverage='NA' ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     reference_genome_length=$genome_length
2022-03-14 09:23:02 [INFO] ADDING_LINE:     reference_genome_length=$genome_length
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE: }
2022-03-14 09:23:02 [INFO] UPDATING_PROCESS cg_pipeline
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_NAME: seqsero2
2022-03-14 09:23:02 [INFO] PROCESS_LINE: process seqsero2 {
2022-03-14 09:23:02 [INFO] ADDING_LINE: process seqsero2 {
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   cpus params.medcpus
2022-03-14 09:23:02 [INFO] INITIAL_LINE:   cpus params.medcpus
2022-03-14 09:23:02 [INFO] TRANSLATED_LINE:   cpus 4
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   container 'staphb/seqsero2:latest'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   container 'staphb/seqsero2:latest'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: seqsero2
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 4 MEM  CONTAINER 'staphb/seqsero2:latest'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   params.seqsero2 && flag =~ 'found'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   params.seqsero2 && flag =~ 'found'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: seqsero2
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 4 MEM  CONTAINER 'staphb/seqsero2:latest'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple val(sample), file(fastq_or_fasta), val(flag) from clean_reads_seqsero2.concat(fastas_seqsero2).join(salmonella_flag, by:0)
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple val(sample), file(fastq_or_fasta), val(flag) from clean_reads_seqsero2.concat(fastas_seqsero2).join(salmonella_flag, by:0)
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:02 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(antigenic_profile) into seqsero2_profile_results
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(antigenic_profile) into seqsero2_profile_results
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(serotype) into seqsero2_serotype_results
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(serotype) into seqsero2_serotype_results
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(contamination) into seqsero2_contamination_results
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(contamination) into seqsero2_contamination_results
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("seqsero2/${sample}/*")
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("seqsero2/${sample}/*")
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("seqsero2/${sample}/SeqSero_result.tsv") into seqsero2_files
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("seqsero2/${sample}/SeqSero_result.tsv") into seqsero2_files
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:02 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:02 [INFO] ADDING_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] ADDING_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     SeqSero2_package.py --version >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     SeqSero2_package.py --version >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     fastq_check=$(echo "!{fastq_or_fasta}" | grep "fastq" | head -n 1 )
2022-03-14 09:23:02 [INFO] ADDING_LINE:     fastq_check=$(echo "!{fastq_or_fasta}" | grep "fastq" | head -n 1 )
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -n "$fastq_check" ] ; then seqsero_options="!{params.seqsero2_options_fastq}" ; else seqsero_options="!{params.seqsero2_options_fasta}" ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -n "$fastq_check" ] ; then seqsero_options="!{params.seqsero2_options_fastq}" ; else seqsero_options="!{params.seqsero2_options_fasta}" ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -n "$fastq_check" ] ; then seqsero_options="!{params.seqsero2_options_fastq}" ; else seqsero_options="!{params.seqsero2_options_fasta}" ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     SeqSero2_package.py $seqsero_options \
2022-03-14 09:23:02 [INFO] ADDING_LINE:     SeqSero2_package.py $seqsero_options \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       -i !{fastq_or_fasta} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       -i !{fastq_or_fasta} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       -p !{task.cpus} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       -p !{task.cpus} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       -d seqsero2/!{sample} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       -d seqsero2/!{sample} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       -n !{sample} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       -n !{sample} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       2>> $err_file >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:       2>> $err_file >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     serotype=$(cut -f 9 seqsero2/!{sample}/SeqSero_result.tsv | tail -n 1)
2022-03-14 09:23:02 [INFO] ADDING_LINE:     serotype=$(cut -f 9 seqsero2/!{sample}/SeqSero_result.tsv | tail -n 1)
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     contamination=$(cut -f 10 seqsero2/!{sample}/SeqSero_result.tsv | tail -n 1)
2022-03-14 09:23:02 [INFO] ADDING_LINE:     contamination=$(cut -f 10 seqsero2/!{sample}/SeqSero_result.tsv | tail -n 1)
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     antigenic_profile=$(cut -f 8 seqsero2/!{sample}/SeqSero_result.tsv | tail -n 1)
2022-03-14 09:23:02 [INFO] ADDING_LINE:     antigenic_profile=$(cut -f 8 seqsero2/!{sample}/SeqSero_result.tsv | tail -n 1)
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     enteritidis_check=$(grep "Enteritidis" seqsero2/!{sample}/SeqSero_result.tsv | head -n 1 )
2022-03-14 09:23:02 [INFO] ADDING_LINE:     enteritidis_check=$(grep "Enteritidis" seqsero2/!{sample}/SeqSero_result.tsv | head -n 1 )
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     sdf_check=$(grep "Detected Sdf" seqsero2/!{sample}/SeqSero_result.tsv | head -n 1 )
2022-03-14 09:23:02 [INFO] ADDING_LINE:     sdf_check=$(grep "Detected Sdf" seqsero2/!{sample}/SeqSero_result.tsv | head -n 1 )
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -n "$sdf_check" ] && [ -n "$enteritidis_check" ]
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -n "$sdf_check" ] && [ -n "$enteritidis_check" ]
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -n "$sdf_check" ] && [ -n "$enteritidis_check" ]
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:02 [INFO] ADDING_LINE:     then
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       serotype="$serotype (Sdf+)"
2022-03-14 09:23:02 [INFO] ADDING_LINE:       serotype="$serotype (Sdf+)"
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     elif [ -z "$sdf_check" ] && [ -n "$enteritidis_check" ]
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     elif [ -z "$sdf_check" ] && [ -n "$enteritidis_check" ]
2022-03-14 09:23:02 [INFO] ADDING_LINE:     elif [ -z "$sdf_check" ] && [ -n "$enteritidis_check" ]
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:02 [INFO] ADDING_LINE:     then
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       serotype="$serotype (Sdf-)"
2022-03-14 09:23:02 [INFO] ADDING_LINE:       serotype="$serotype (Sdf-)"
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -z "$serotype" ] ; then serotype='NA' ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -z "$serotype" ] ; then serotype='NA' ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -z "$serotype" ] ; then serotype='NA' ; fi
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -z "$contamination" ] ; then contamination='NA' ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -z "$contamination" ] ; then contamination='NA' ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -z "$contamination" ] ; then contamination='NA' ; fi
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -z "$antigenic_profile" ] ; then antigenic_profile='NA' ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -z "$antigenic_profile" ] ; then antigenic_profile='NA' ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -z "$antigenic_profile" ] ; then antigenic_profile='NA' ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE: }
2022-03-14 09:23:02 [INFO] UPDATING_PROCESS seqsero2
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_NAME: shigatyper
2022-03-14 09:23:02 [INFO] PROCESS_LINE: process shigatyper {
2022-03-14 09:23:02 [INFO] ADDING_LINE: process shigatyper {
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   cpus params.medcpus
2022-03-14 09:23:02 [INFO] INITIAL_LINE:   cpus params.medcpus
2022-03-14 09:23:02 [INFO] TRANSLATED_LINE:   cpus 4
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   container 'andrewlangvt/shigatyper:1'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   container 'andrewlangvt/shigatyper:1'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: shigatyper
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 4 MEM  CONTAINER 'andrewlangvt/shigatyper:1'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   params.shigatyper && flag =~ 'found'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   params.shigatyper && flag =~ 'found'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: shigatyper
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 4 MEM  CONTAINER 'andrewlangvt/shigatyper:1'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple val(sample), file(fastq), val(flag) from clean_reads_shigatyper.join(shigella_flag, by:0)
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple val(sample), file(fastq), val(flag) from clean_reads_shigatyper.join(shigella_flag, by:0)
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:02 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("${task.process}/${sample}_shigatyper.tsv")
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("${task.process}/${sample}_shigatyper.tsv")
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(predictions) into shigatyper_predictions
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(predictions) into shigatyper_predictions
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(lacy_cada) into shigatyper_cadA
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(lacy_cada) into shigatyper_cadA
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:02 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:02 [INFO] ADDING_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] ADDING_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     shigatyper --version >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     shigatyper --version >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     shigatyper !{params.shigatyper_options} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:     shigatyper !{params.shigatyper_options} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       --name !{sample} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       --name !{sample} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       !{fastq} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       !{fastq} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       2>> $err_file \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       2>> $err_file \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       > !{task.process}/!{sample}_shigatyper.tsv
2022-03-14 09:23:02 [INFO] ADDING_LINE:       > !{task.process}/!{sample}_shigatyper.tsv
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     predictions=$(grep -v "prediction" !{task.process}/!{sample}_shigatyper.tsv | cut -f 2 | tr '\\n' ',' | sed 's/,$//g' )
2022-03-14 09:23:02 [INFO] ADDING_LINE:     predictions=$(grep -v "prediction" !{task.process}/!{sample}_shigatyper.tsv | cut -f 2 | tr '\\n' ',' | sed 's/,$//g' )
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     lacy_cada="$(grep -ie "lac" -ie "cad" $err_file | head -n 1)"
2022-03-14 09:23:02 [INFO] ADDING_LINE:     lacy_cada="$(grep -ie "lac" -ie "cad" $err_file | head -n 1)"
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -z "$predictions" ] ; then predictions='none' ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -z "$predictions" ] ; then predictions='none' ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -z "$predictions" ] ; then predictions='none' ; fi
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -z "$lacy_cada" ] ; then lacy_cada='none' ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -z "$lacy_cada" ] ; then lacy_cada='none' ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -z "$lacy_cada" ] ; then lacy_cada='none' ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE: }
2022-03-14 09:23:02 [INFO] UPDATING_PROCESS shigatyper
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_NAME: kleborate
2022-03-14 09:23:02 [INFO] PROCESS_LINE: process kleborate {
2022-03-14 09:23:02 [INFO] ADDING_LINE: process kleborate {
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   cpus params.medcpus
2022-03-14 09:23:02 [INFO] INITIAL_LINE:   cpus params.medcpus
2022-03-14 09:23:02 [INFO] TRANSLATED_LINE:   cpus 4
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   container 'staphb/kleborate:latest'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   container 'staphb/kleborate:latest'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: kleborate
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 4 MEM  CONTAINER 'staphb/kleborate:latest'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   params.kleborate && flag =~ 'found'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   params.kleborate && flag =~ 'found'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: kleborate
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 4 MEM  CONTAINER 'staphb/kleborate:latest'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple val(sample), file(contig), val(flag) from contigs_kleborate.concat(fastas_kleborate).join(klebsiella_flag, by:0)
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple val(sample), file(contig), val(flag) from contigs_kleborate.concat(fastas_kleborate).join(klebsiella_flag, by:0)
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:02 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(kleborate_score) into kleborate_score
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(kleborate_score) into kleborate_score
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(kleborate_mlst) into kleborate_mlst
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(kleborate_mlst) into kleborate_mlst
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("${task.process}/${sample}_results.txt") into kleborate_files
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("${task.process}/${sample}_results.txt") into kleborate_files
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:02 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:02 [INFO] ADDING_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] ADDING_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     kleborate --version >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     kleborate --version >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     kleborate !{params.kleborate_options} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:     kleborate !{params.kleborate_options} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       -o !{task.process}/!{sample}_results.txt \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       -o !{task.process}/!{sample}_results.txt \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       -a !{contig} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       -a !{contig} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       2>> $err_file >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:       2>> $err_file >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     virulence_column=$(head -n 1 !{task.process}/!{sample}_results.txt | tr '\\t' '\\n' | grep -n virulence_score | cut -f 1 -d ":" )
2022-03-14 09:23:02 [INFO] ADDING_LINE:     virulence_column=$(head -n 1 !{task.process}/!{sample}_results.txt | tr '\\t' '\\n' | grep -n virulence_score | cut -f 1 -d ":" )
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     mlst_column=$(head -n 1 !{task.process}/!{sample}_results.txt | tr '\\t' '\\n' | grep -n ST | cut -f 1 -d ":" )
2022-03-14 09:23:02 [INFO] ADDING_LINE:     mlst_column=$(head -n 1 !{task.process}/!{sample}_results.txt | tr '\\t' '\\n' | grep -n ST | cut -f 1 -d ":" )
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -n "$virulence_column" ] ; then kleborate_score=$(cut -f $virulence_column !{task.process}/!{sample}_results.txt | tail -n 1 ) ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -n "$virulence_column" ] ; then kleborate_score=$(cut -f $virulence_column !{task.process}/!{sample}_results.txt | tail -n 1 ) ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -n "$virulence_column" ] ; then kleborate_score=$(cut -f $virulence_column !{task.process}/!{sample}_results.txt | tail -n 1 ) ; fi
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -n "$mlst_column" ] ; then kleborate_mlst=$(cut -f $mlst_column !{task.process}/!{sample}_results.txt | tail -n 1 ) ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -n "$mlst_column" ] ; then kleborate_mlst=$(cut -f $mlst_column !{task.process}/!{sample}_results.txt | tail -n 1 ) ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -n "$mlst_column" ] ; then kleborate_mlst=$(cut -f $mlst_column !{task.process}/!{sample}_results.txt | tail -n 1 ) ; fi
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -z "$kleborate_score" ] ; then kleborate_score='NA' ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -z "$kleborate_score" ] ; then kleborate_score='NA' ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -z "$kleborate_score" ] ; then kleborate_score='NA' ; fi
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -z "$kleborate_mlst" ] ; then kleborate_mlst='NA' ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -z "$kleborate_mlst" ] ; then kleborate_mlst='NA' ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -z "$kleborate_mlst" ] ; then kleborate_mlst='NA' ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE: }
2022-03-14 09:23:02 [INFO] UPDATING_PROCESS kleborate
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_NAME: serotypefinder
2022-03-14 09:23:02 [INFO] PROCESS_LINE: process serotypefinder {
2022-03-14 09:23:02 [INFO] ADDING_LINE: process serotypefinder {
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   cpus params.medcpus
2022-03-14 09:23:02 [INFO] INITIAL_LINE:   cpus params.medcpus
2022-03-14 09:23:02 [INFO] TRANSLATED_LINE:   cpus 4
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   container 'staphb/serotypefinder:latest'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   container 'staphb/serotypefinder:latest'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: serotypefinder
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 4 MEM  CONTAINER 'staphb/serotypefinder:latest'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   params.serotypefinder && flag =~ 'found'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   params.serotypefinder && flag =~ 'found'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:02 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:02 [WARN] NO_PROCESS_LABEL: For process name: serotypefinder
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:02 [INFO] CPUS 4 MEM  CONTAINER 'staphb/serotypefinder:latest'
2022-03-14 09:23:02 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:02 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:02 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:02 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple val(sample), file(fasta), val(flag) from contigs_serotypefinder.concat(fastas_serotypefinder).join(ecoli_flag, by:0)
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple val(sample), file(fasta), val(flag) from contigs_serotypefinder.concat(fastas_serotypefinder).join(ecoli_flag, by:0)
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:02 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("${task.process}/${sample}/*")
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("${task.process}/${sample}/*")
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(o_type) into serotypefinder_results_o
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(o_type) into serotypefinder_results_o
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tuple sample, env(h_type) into serotypefinder_results_h
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tuple sample, env(h_type) into serotypefinder_results_h
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:02 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     mkdir -p !{task.process}/!{sample} logs/!{task.process}
2022-03-14 09:23:02 [INFO] ADDING_LINE:     mkdir -p !{task.process}/!{sample} logs/!{task.process}
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:02 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] ADDING_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     serotypefinder.py !{params.serotypefinder_options} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:     serotypefinder.py !{params.serotypefinder_options} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       -i !{fasta} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       -i !{fasta} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       -o !{task.process}/!{sample} \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       -o !{task.process}/!{sample} \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       -x \
2022-03-14 09:23:02 [INFO] ADDING_LINE:       -x \
2022-03-14 09:23:02 [INFO] PROCESS_LINE:       2>> $err_file >> $log_file
2022-03-14 09:23:02 [INFO] ADDING_LINE:       2>> $err_file >> $log_file
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     h_type=$(cut -f 3 !{task.process}/!{sample}/results_tab.tsv | grep ^H | sort | uniq | tr '\\n' ',' | sed 's/,$//g' )
2022-03-14 09:23:02 [INFO] ADDING_LINE:     h_type=$(cut -f 3 !{task.process}/!{sample}/results_tab.tsv | grep ^H | sort | uniq | tr '\\n' ',' | sed 's/,$//g' )
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     o_type=$(cut -f 3 !{task.process}/!{sample}/results_tab.tsv | grep ^O | sort | uniq | tr '\\n' ',' | sed 's/,$//g' )
2022-03-14 09:23:02 [INFO] ADDING_LINE:     o_type=$(cut -f 3 !{task.process}/!{sample}/results_tab.tsv | grep ^O | sort | uniq | tr '\\n' ',' | sed 's/,$//g' )
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -z "$h_type" ] ; then h_type="none" ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -z "$h_type" ] ; then h_type="none" ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -z "$h_type" ] ; then h_type="none" ; fi
2022-03-14 09:23:02 [INFO] EXPRESSION_LINE:     if [ -z "$o_type" ] ; then o_type="none" ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:     if [ -z "$o_type" ] ; then o_type="none" ; fi
2022-03-14 09:23:02 [INFO] ADDING_LINE:     if [ -z "$o_type" ] ; then o_type="none" ; fi
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:02 [INFO] ADDING_LINE: }
2022-03-14 09:23:02 [INFO] UPDATING_PROCESS serotypefinder
2022-03-14 09:23:02 [INFO] FOUND_PROCESS_NAME: amrfinderplus
2022-03-14 09:23:02 [INFO] PROCESS_LINE: process amrfinderplus {
2022-03-14 09:23:02 [INFO] ADDING_LINE: process amrfinderplus {
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   cpus params.medcpus
2022-03-14 09:23:02 [INFO] INITIAL_LINE:   cpus params.medcpus
2022-03-14 09:23:02 [INFO] TRANSLATED_LINE:   cpus 4
2022-03-14 09:23:02 [INFO] PROCESS_LINE:   container 'staphb/ncbi-amrfinderplus:latest'
2022-03-14 09:23:03 [INFO] ADDING_LINE:   container 'staphb/ncbi-amrfinderplus:latest'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:03 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:03 [WARN] NO_PROCESS_LABEL: For process name: amrfinderplus
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:03 [INFO] CPUS 4 MEM  CONTAINER 'staphb/ncbi-amrfinderplus:latest'
2022-03-14 09:23:03 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:03 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   params.amrfinderplus
2022-03-14 09:23:03 [INFO] ADDING_LINE:   params.amrfinderplus
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:03 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:03 [WARN] NO_PROCESS_LABEL: For process name: amrfinderplus
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:03 [INFO] CPUS 4 MEM  CONTAINER 'staphb/ncbi-amrfinderplus:latest'
2022-03-14 09:23:03 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:03 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   tuple val(sample), file(contigs), val(genus), val(species) from contigs_amrfinder.concat(fastas_amrfinder).join(mash_genus_amrfinder, by: 0).join(mash_species_amrfinder, by: 0)
2022-03-14 09:23:03 [INFO] ADDING_LINE:   tuple val(sample), file(contigs), val(genus), val(species) from contigs_amrfinder.concat(fastas_amrfinder).join(mash_genus_amrfinder, by: 0).join(mash_species_amrfinder, by: 0)
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:03 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:   file("ncbi-AMRFinderplus/${sample}_amrfinder_plus.txt") into amrfinder_files
2022-03-14 09:23:03 [INFO] ADDING_LINE:   file("ncbi-AMRFinderplus/${sample}_amrfinder_plus.txt") into amrfinder_files
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   tuple sample, env(amr_genes) into amr_genes
2022-03-14 09:23:03 [INFO] ADDING_LINE:   tuple sample, env(amr_genes) into amr_genes
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   tuple sample, env(virulence_genes) into virulence_genes
2022-03-14 09:23:03 [INFO] ADDING_LINE:   tuple sample, env(virulence_genes) into virulence_genes
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:03 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     mkdir -p ncbi-AMRFinderplus logs/!{task.process}
2022-03-14 09:23:03 [INFO] ADDING_LINE:     mkdir -p ncbi-AMRFinderplus logs/!{task.process}
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] ADDING_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     organism_options=(Acinetobacter_baumannii
2022-03-14 09:23:03 [INFO] ADDING_LINE:     organism_options=(Acinetobacter_baumannii
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     Campylobacter
2022-03-14 09:23:03 [INFO] ADDING_LINE:     Campylobacter
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     Enterococcus_faecalis
2022-03-14 09:23:03 [INFO] ADDING_LINE:     Enterococcus_faecalis
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     Enterococcus_faecium
2022-03-14 09:23:03 [INFO] ADDING_LINE:     Enterococcus_faecium
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     Escherichia:Shigella
2022-03-14 09:23:03 [INFO] ADDING_LINE:     Escherichia:Shigella
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     Klebsiella
2022-03-14 09:23:03 [INFO] ADDING_LINE:     Klebsiella
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     Salmonella
2022-03-14 09:23:03 [INFO] ADDING_LINE:     Salmonella
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     Staphylococcus_aureus
2022-03-14 09:23:03 [INFO] ADDING_LINE:     Staphylococcus_aureus
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     Staphylococcus_pseudintermedius
2022-03-14 09:23:03 [INFO] ADDING_LINE:     Staphylococcus_pseudintermedius
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     Streptococcus_agalactiae
2022-03-14 09:23:03 [INFO] ADDING_LINE:     Streptococcus_agalactiae
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     Streptococcus_pneumoniae
2022-03-14 09:23:03 [INFO] ADDING_LINE:     Streptococcus_pneumoniae
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     Streptococcus_pyogenes
2022-03-14 09:23:03 [INFO] ADDING_LINE:     Streptococcus_pyogenes
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     Vibrio_cholerae)
2022-03-14 09:23:03 [INFO] ADDING_LINE:     Vibrio_cholerae)
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     organism=$(history -p ${organism_options[@]} | grep -i !{genus} | grep -i !{species} | head -n 1 )
2022-03-14 09:23:03 [INFO] ADDING_LINE:     organism=$(history -p ${organism_options[@]} | grep -i !{genus} | grep -i !{species} | head -n 1 )
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:     if [ -z "$organism" ] ; then organism=$(history -p ${organism_options[@]} | grep -i !{genus} | head -n 1 | cut -f 1 -d ":" ) ; fi
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     if [ -z "$organism" ] ; then organism=$(history -p ${organism_options[@]} | grep -i !{genus} | head -n 1 | cut -f 1 -d ":" ) ; fi
2022-03-14 09:23:03 [INFO] ADDING_LINE:     if [ -z "$organism" ] ; then organism=$(history -p ${organism_options[@]} | grep -i !{genus} | head -n 1 | cut -f 1 -d ":" ) ; fi
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:     if [ -n "$organism" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     if [ -n "$organism" ]
2022-03-14 09:23:03 [INFO] ADDING_LINE:     if [ -n "$organism" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:03 [INFO] ADDING_LINE:     then
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       organism_check="--organism $organism"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       organism_check="--organism $organism"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       echo "Mash result of !{genus} !{species} matched with $organism" >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       echo "Mash result of !{genus} !{species} matched with $organism" >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     else
2022-03-14 09:23:03 [INFO] ADDING_LINE:     else
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       organism_check=''
2022-03-14 09:23:03 [INFO] ADDING_LINE:       organism_check=''
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       echo "Mash result of !{genus} !{species} did not match any of the organisms" >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       echo "Mash result of !{genus} !{species} did not match any of the organisms" >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:03 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     amrfinder !{params.amrfinderplus_options} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:     amrfinder !{params.amrfinderplus_options} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       --nucleotide !{contigs} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:       --nucleotide !{contigs} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       --threads !{task.cpus} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:       --threads !{task.cpus} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       --name !{sample} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:       --name !{sample} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       --output ncbi-AMRFinderplus/!{sample}_amrfinder_plus.txt \
2022-03-14 09:23:03 [INFO] ADDING_LINE:       --output ncbi-AMRFinderplus/!{sample}_amrfinder_plus.txt \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       $organism_check \
2022-03-14 09:23:03 [INFO] ADDING_LINE:       $organism_check \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       --plus \
2022-03-14 09:23:03 [INFO] ADDING_LINE:       --plus \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       2>> $err_file >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       2>> $err_file >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     amr_genes=$(cut -f 7 ncbi-AMRFinderplus/!{sample}_amrfinder_plus.txt | tail +2 | sort | uniq | tr '\\n' ',' | sed 's/,$//g' )
2022-03-14 09:23:03 [INFO] ADDING_LINE:     amr_genes=$(cut -f 7 ncbi-AMRFinderplus/!{sample}_amrfinder_plus.txt | tail +2 | sort | uniq | tr '\\n' ',' | sed 's/,$//g' )
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     virulence_genes=$(grep "VIRULENCE" ncbi-AMRFinderplus/!{sample}_amrfinder_plus.txt | cut -f 7 | sort | uniq | tr '\\n' ',' | sed 's/,$//g' )
2022-03-14 09:23:03 [INFO] ADDING_LINE:     virulence_genes=$(grep "VIRULENCE" ncbi-AMRFinderplus/!{sample}_amrfinder_plus.txt | cut -f 7 | sort | uniq | tr '\\n' ',' | sed 's/,$//g' )
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:     if [ -z "$amr_genes" ] ; then amr_genes="none" ; fi
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     if [ -z "$amr_genes" ] ; then amr_genes="none" ; fi
2022-03-14 09:23:03 [INFO] ADDING_LINE:     if [ -z "$amr_genes" ] ; then amr_genes="none" ; fi
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:     if [ -z "$virulence_genes" ] ; then virulence_genes="none" ; fi
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     if [ -z "$virulence_genes" ] ; then virulence_genes="none" ; fi
2022-03-14 09:23:03 [INFO] ADDING_LINE:     if [ -z "$virulence_genes" ] ; then virulence_genes="none" ; fi
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:03 [INFO] ADDING_LINE: }
2022-03-14 09:23:03 [INFO] UPDATING_PROCESS amrfinderplus
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_NAME: kraken2
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   process kraken2 {
2022-03-14 09:23:03 [INFO] ADDING_LINE:   process kraken2 {
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tag "${sample}"
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tag "${sample}"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     cpus params.maxcpus
2022-03-14 09:23:03 [INFO] INITIAL_LINE:     cpus params.maxcpus
2022-03-14 09:23:03 [INFO] TRANSLATED_LINE:     cpus 16
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     container 'staphb/kraken2:latest'
2022-03-14 09:23:03 [INFO] ADDING_LINE:     container 'staphb/kraken2:latest'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     input:
2022-03-14 09:23:03 [INFO] LINE_INDENT_FIRST_TOKEN:     input:
2022-03-14 09:23:03 [WARN] NO_PROCESS_LABEL: For process name: kraken2
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:03 [INFO] CPUS 16 MEM  CONTAINER 'staphb/kraken2:latest'
2022-03-14 09:23:03 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:03 [INFO] ADDING_LINE:     input:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tuple val(sample), file(clean), path(kraken2_db) from clean_reads_kraken2.concat(fastas_kraken2).combine(local_kraken2)
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tuple val(sample), file(clean), path(kraken2_db) from clean_reads_kraken2.concat(fastas_kraken2).combine(local_kraken2)
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     output:
2022-03-14 09:23:03 [INFO] ADDING_LINE:     output:
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     file("${task.process}/${sample}_kraken2_report.txt") into kraken2_files
2022-03-14 09:23:03 [INFO] ADDING_LINE:     file("${task.process}/${sample}_kraken2_report.txt") into kraken2_files
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] ADDING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tuple sample, env(top_hit) into kraken2_top_hit
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tuple sample, env(top_hit) into kraken2_top_hit
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tuple sample, env(top_perc) into kraken2_top_perc
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tuple sample, env(top_perc) into kraken2_top_perc
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tuple sample, env(top_reads) into kraken2_top_reads
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tuple sample, env(top_reads) into kraken2_top_reads
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     shell:
2022-03-14 09:23:03 [INFO] ADDING_LINE:     shell:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:03 [INFO] ADDING_LINE:       mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] ADDING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] ADDING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] ADDING_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       kraken2 --version >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       kraken2 --version >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       fastq_check=$(echo "!{clean}" | grep "fastq" | head -n 1 )
2022-03-14 09:23:03 [INFO] ADDING_LINE:       fastq_check=$(echo "!{clean}" | grep "fastq" | head -n 1 )
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:       if [ -n "$fastq_check" ] ; then kraken2_parameter="--paired --classified-out cseqs#.fq" ; else kraken2_parameter="" ; fi
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       if [ -n "$fastq_check" ] ; then kraken2_parameter="--paired --classified-out cseqs#.fq" ; else kraken2_parameter="" ; fi
2022-03-14 09:23:03 [INFO] ADDING_LINE:       if [ -n "$fastq_check" ] ; then kraken2_parameter="--paired --classified-out cseqs#.fq" ; else kraken2_parameter="" ; fi
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       kraken2 !{params.kraken2_options} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:       kraken2 !{params.kraken2_options} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         $kraken2_parameter \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         $kraken2_parameter \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         --threads !{task.cpus} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         --threads !{task.cpus} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         --db !{kraken2_db} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         --db !{kraken2_db} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         !{clean} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         !{clean} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         --report !{task.process}/!{sample}_kraken2_report.txt \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         --report !{task.process}/!{sample}_kraken2_report.txt \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         2>> $err_file >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:         2>> $err_file >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       top_hit=$(cat !{task.process}/!{sample}_kraken2_report.txt   | grep -w S | sort | tail -n 1 | awk '{print $6 " " $7}')
2022-03-14 09:23:03 [INFO] ADDING_LINE:       top_hit=$(cat !{task.process}/!{sample}_kraken2_report.txt   | grep -w S | sort | tail -n 1 | awk '{print $6 " " $7}')
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       top_perc=$(cat !{task.process}/!{sample}_kraken2_report.txt  | grep -w S | sort | tail -n 1 | awk '{print $1}')
2022-03-14 09:23:03 [INFO] ADDING_LINE:       top_perc=$(cat !{task.process}/!{sample}_kraken2_report.txt  | grep -w S | sort | tail -n 1 | awk '{print $1}')
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       top_reads=$(cat !{task.process}/!{sample}_kraken2_report.txt | grep -w S | sort | tail -n 1 | awk '{print $3}')
2022-03-14 09:23:03 [INFO] ADDING_LINE:       top_reads=$(cat !{task.process}/!{sample}_kraken2_report.txt | grep -w S | sort | tail -n 1 | awk '{print $3}')
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:       if [ -z "$top_hit" ] ; then top_hit="NA" ; fi
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       if [ -z "$top_hit" ] ; then top_hit="NA" ; fi
2022-03-14 09:23:03 [INFO] ADDING_LINE:       if [ -z "$top_hit" ] ; then top_hit="NA" ; fi
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:       if [ -z "$top_perc" ] ; then top_perc="0" ; fi
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       if [ -z "$top_perc" ] ; then top_perc="0" ; fi
2022-03-14 09:23:03 [INFO] ADDING_LINE:       if [ -z "$top_perc" ] ; then top_perc="0" ; fi
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:       if [ -z "$top_reads" ] ; then top_reads="0" ; fi
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       if [ -z "$top_reads" ] ; then top_reads="0" ; fi
2022-03-14 09:23:03 [INFO] ADDING_LINE:       if [ -z "$top_reads" ] ; then top_reads="0" ; fi
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:   }
2022-03-14 09:23:03 [INFO] UPDATING_PROCESS kraken2
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_NAME: blastn
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   process blastn {
2022-03-14 09:23:03 [INFO] ADDING_LINE:   process blastn {
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tag "${sample}"
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tag "${sample}"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     cpus params.medcpus
2022-03-14 09:23:03 [INFO] INITIAL_LINE:     cpus params.medcpus
2022-03-14 09:23:03 [INFO] TRANSLATED_LINE:     cpus 4
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     container 'ncbi/blast:latest'
2022-03-14 09:23:03 [INFO] ADDING_LINE:     container 'ncbi/blast:latest'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     input:
2022-03-14 09:23:03 [INFO] LINE_INDENT_FIRST_TOKEN:     input:
2022-03-14 09:23:03 [WARN] NO_PROCESS_LABEL: For process name: blastn
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:03 [INFO] CPUS 4 MEM  CONTAINER 'ncbi/blast:latest'
2022-03-14 09:23:03 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:03 [INFO] ADDING_LINE:     input:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tuple val(sample), file(contig), path(blastdb) from contigs_blastn.combine(local_blastdb)
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tuple val(sample), file(contig), path(blastdb) from contigs_blastn.combine(local_blastdb)
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     output:
2022-03-14 09:23:03 [INFO] ADDING_LINE:     output:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tuple sample, file("blastn/${sample}.tsv") into blastn_files
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tuple sample, file("blastn/${sample}.tsv") into blastn_files
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] ADDING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     shell:
2022-03-14 09:23:03 [INFO] ADDING_LINE:     shell:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:03 [INFO] ADDING_LINE:       mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] ADDING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] ADDING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] ADDING_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] ADDING_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       blastn -version >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       blastn -version >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       blastn -query !{contig} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:       blastn -query !{contig} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         -out blastn/!{sample}.tsv \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         -out blastn/!{sample}.tsv \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         -num_threads !{task.cpus} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         -num_threads !{task.cpus} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         -db !{blastdb}/!{params.local_db_type} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         -db !{blastdb}/!{params.local_db_type} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         -outfmt '6 qseqid staxids bitscore std' \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         -outfmt '6 qseqid staxids bitscore std' \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         -max_target_seqs 10 \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         -max_target_seqs 10 \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         -max_hsps 1 \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         -max_hsps 1 \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         -evalue 1e-25 \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         -evalue 1e-25 \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         2>> $err_file >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:         2>> $err_file >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:   }
2022-03-14 09:23:03 [INFO] UPDATING_PROCESS blastn
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_NAME: bwa
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   process bwa {
2022-03-14 09:23:03 [INFO] ADDING_LINE:   process bwa {
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     publishDir "${params.outdir}", mode: 'copy', pattern: "logs/${task.process}/*.{log,err}"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tag "${sample}"
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tag "${sample}"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     cpus params.medcpus
2022-03-14 09:23:03 [INFO] INITIAL_LINE:     cpus params.medcpus
2022-03-14 09:23:03 [INFO] TRANSLATED_LINE:     cpus 4
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     container 'staphb/bwa:latest'
2022-03-14 09:23:03 [INFO] ADDING_LINE:     container 'staphb/bwa:latest'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     input:
2022-03-14 09:23:03 [INFO] LINE_INDENT_FIRST_TOKEN:     input:
2022-03-14 09:23:03 [WARN] NO_PROCESS_LABEL: For process name: bwa
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:03 [INFO] CPUS 4 MEM  CONTAINER 'staphb/bwa:latest'
2022-03-14 09:23:03 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:03 [INFO] ADDING_LINE:     input:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tuple val(sample), file(reads), file(contig) from clean_reads_bwa.join(contigs_bwa, by:0)
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tuple val(sample), file(reads), file(contig) from clean_reads_bwa.join(contigs_bwa, by:0)
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     output:
2022-03-14 09:23:03 [INFO] ADDING_LINE:     output:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tuple sample, file("${task.process}/${sample}.sam") into sam_files
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tuple sample, file("${task.process}/${sample}.sam") into sam_files
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] ADDING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     shell:
2022-03-14 09:23:03 [INFO] ADDING_LINE:     shell:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:03 [INFO] ADDING_LINE:       mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] ADDING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] ADDING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] ADDING_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] ADDING_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       echo "bwa $(bwa 2>&1 | grep Version )" >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       echo "bwa $(bwa 2>&1 | grep Version )" >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       bwa index !{contig} 2>> $err_file >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       bwa index !{contig} 2>> $err_file >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       bwa mem !{params.bwa_options} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:       bwa mem !{params.bwa_options} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         -t !{task.cpus} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         -t !{task.cpus} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         !{contig} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         !{contig} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         !{reads} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         !{reads} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         2>> $err_file \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         2>> $err_file \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         > !{task.process}/!{sample}.sam
2022-03-14 09:23:03 [INFO] ADDING_LINE:         > !{task.process}/!{sample}.sam
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:   }
2022-03-14 09:23:03 [INFO] UPDATING_PROCESS bwa
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_NAME: sort
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   process sort {
2022-03-14 09:23:03 [INFO] ADDING_LINE:   process sort {
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tag "${sample}"
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tag "${sample}"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     cpus params.medcpus
2022-03-14 09:23:03 [INFO] INITIAL_LINE:     cpus params.medcpus
2022-03-14 09:23:03 [INFO] TRANSLATED_LINE:     cpus 4
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     container 'staphb/samtools:latest'
2022-03-14 09:23:03 [INFO] ADDING_LINE:     container 'staphb/samtools:latest'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     input:
2022-03-14 09:23:03 [INFO] LINE_INDENT_FIRST_TOKEN:     input:
2022-03-14 09:23:03 [WARN] NO_PROCESS_LABEL: For process name: sort
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:03 [INFO] CPUS 4 MEM  CONTAINER 'staphb/samtools:latest'
2022-03-14 09:23:03 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:03 [INFO] ADDING_LINE:     input:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tuple val(sample), file(sam) from sam_files
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tuple val(sample), file(sam) from sam_files
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     output:
2022-03-14 09:23:03 [INFO] ADDING_LINE:     output:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tuple sample, file("aligned/${sample}.sorted.bam*") into bam_files
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tuple sample, file("aligned/${sample}.sorted.bam*") into bam_files
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] ADDING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     shell:
2022-03-14 09:23:03 [INFO] ADDING_LINE:     shell:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       mkdir -p aligned logs/!{task.process}
2022-03-14 09:23:03 [INFO] ADDING_LINE:       mkdir -p aligned logs/!{task.process}
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] ADDING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] ADDING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] ADDING_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] ADDING_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       samtools --version >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       samtools --version >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       samtools sort !{params.samtools_sort_options} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:       samtools sort !{params.samtools_sort_options} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         --threads !{task.cpus} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         --threads !{task.cpus} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         !{sam} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         !{sam} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         -o aligned/!{sample}.sorted.bam \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         -o aligned/!{sample}.sorted.bam \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         --write-index \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         --write-index \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         2>> $err_file >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:         2>> $err_file >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:   }
2022-03-14 09:23:03 [INFO] UPDATING_PROCESS sort
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_NAME: create
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   process create {
2022-03-14 09:23:03 [INFO] ADDING_LINE:   process create {
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tag "${sample}"
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tag "${sample}"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     cpus 1
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     container 'chrishah/blobtools:v1.1.1'
2022-03-14 09:23:03 [INFO] ADDING_LINE:     container 'chrishah/blobtools:v1.1.1'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     input:
2022-03-14 09:23:03 [INFO] LINE_INDENT_FIRST_TOKEN:     input:
2022-03-14 09:23:03 [WARN] NO_PROCESS_LABEL: For process name: create
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:03 [INFO] CPUS 1 MEM  CONTAINER 'chrishah/blobtools:v1.1.1'
2022-03-14 09:23:03 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:03 [INFO] ADDING_LINE:     input:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tuple val(sample), file(contig), file(blastn), file(bam) from contigs_create.join(blastn_files, by:0).join(bam_files, by:0)
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tuple val(sample), file(contig), file(blastn), file(bam) from contigs_create.join(blastn_files, by:0).join(bam_files, by:0)
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     output:
2022-03-14 09:23:03 [INFO] ADDING_LINE:     output:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tuple sample, file("blobtools/${sample}.blobDB.json") into create_files_view, create_files_plot
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tuple sample, file("blobtools/${sample}.blobDB.json") into create_files_view, create_files_plot
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     file("blobtools/${sample}.${sample}.sorted.bam.cov")
2022-03-14 09:23:03 [INFO] ADDING_LINE:     file("blobtools/${sample}.${sample}.sorted.bam.cov")
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] ADDING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     shell:
2022-03-14 09:23:03 [INFO] ADDING_LINE:     shell:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       mkdir -p blobtools logs/!{task.process}
2022-03-14 09:23:03 [INFO] ADDING_LINE:       mkdir -p blobtools logs/!{task.process}
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] ADDING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] ADDING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] ADDING_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] ADDING_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       echo "blobtools version $(blobtools -v)" >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       echo "blobtools version $(blobtools -v)" >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       blobtools create !{params.blobtools_create_options} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:       blobtools create !{params.blobtools_create_options} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         -o blobtools/!{sample} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         -o blobtools/!{sample} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         -i !{contig} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         -i !{contig} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         -b !{sample}.sorted.bam \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         -b !{sample}.sorted.bam \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         -t !{blastn} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         -t !{blastn} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         2>> $err_file >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:         2>> $err_file >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:   }
2022-03-14 09:23:03 [INFO] UPDATING_PROCESS create
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_NAME: view
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   process view {
2022-03-14 09:23:03 [INFO] ADDING_LINE:   process view {
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tag "${sample}"
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tag "${sample}"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     cpus 1
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     container 'chrishah/blobtools:v1.1.1'
2022-03-14 09:23:03 [INFO] ADDING_LINE:     container 'chrishah/blobtools:v1.1.1'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     input:
2022-03-14 09:23:03 [INFO] LINE_INDENT_FIRST_TOKEN:     input:
2022-03-14 09:23:03 [WARN] NO_PROCESS_LABEL: For process name: view
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:03 [INFO] CPUS 1 MEM  CONTAINER 'chrishah/blobtools:v1.1.1'
2022-03-14 09:23:03 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:03 [INFO] ADDING_LINE:     input:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tuple val(sample), file(json) from create_files_view
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tuple val(sample), file(json) from create_files_view
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     output:
2022-03-14 09:23:03 [INFO] ADDING_LINE:     output:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tuple sample, file("blobtools/${sample}.blobDB.table.txt") into view_files
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tuple sample, file("blobtools/${sample}.blobDB.table.txt") into view_files
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] ADDING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     shell:
2022-03-14 09:23:03 [INFO] ADDING_LINE:     shell:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       mkdir -p blobtools logs/!{task.process}
2022-03-14 09:23:03 [INFO] ADDING_LINE:       mkdir -p blobtools logs/!{task.process}
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] ADDING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] ADDING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] ADDING_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] ADDING_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       echo "blobtools version $(blobtools -v)" >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       echo "blobtools version $(blobtools -v)" >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       blobtools view !{params.blobtools_view_options} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:       blobtools view !{params.blobtools_view_options} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         -i !{json} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         -i !{json} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         -o blobtools/ \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         -o blobtools/ \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         2>> $err_file >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:         2>> $err_file >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:   }
2022-03-14 09:23:03 [INFO] UPDATING_PROCESS view
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_NAME: blobtools
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   process blobtools {
2022-03-14 09:23:03 [INFO] ADDING_LINE:   process blobtools {
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tag "${sample}"
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tag "${sample}"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     cpus 1
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     container 'chrishah/blobtools:v1.1.1'
2022-03-14 09:23:03 [INFO] ADDING_LINE:     container 'chrishah/blobtools:v1.1.1'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     input:
2022-03-14 09:23:03 [INFO] LINE_INDENT_FIRST_TOKEN:     input:
2022-03-14 09:23:03 [WARN] NO_PROCESS_LABEL: For process name: blobtools
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:03 [INFO] CPUS 1 MEM  CONTAINER 'chrishah/blobtools:v1.1.1'
2022-03-14 09:23:03 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:03 [INFO] ADDING_LINE:     input:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tuple val(sample), file(json) from create_files_plot
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tuple val(sample), file(json) from create_files_plot
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     output:
2022-03-14 09:23:03 [INFO] ADDING_LINE:     output:
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     file("blobtools/${sample}.*")
2022-03-14 09:23:03 [INFO] ADDING_LINE:     file("blobtools/${sample}.*")
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tuple sample, env(blobtools_species) into blobtools_species_results
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tuple sample, env(blobtools_species) into blobtools_species_results
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tuple sample, env(blobtools_perc) into blobtools_perc_results
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tuple sample, env(blobtools_perc) into blobtools_perc_results
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] ADDING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     shell:
2022-03-14 09:23:03 [INFO] ADDING_LINE:     shell:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       mkdir -p blobtools logs/!{task.process}
2022-03-14 09:23:03 [INFO] ADDING_LINE:       mkdir -p blobtools logs/!{task.process}
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] ADDING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] ADDING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] ADDING_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] ADDING_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       echo "blobtools version $(blobtools -v)" >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       echo "blobtools version $(blobtools -v)" >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       blobtools plot !{params.blobtools_plot_options} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:       blobtools plot !{params.blobtools_plot_options} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         -i !{json} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         -i !{json} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         -o blobtools/ \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         -o blobtools/ \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         2>> $err_file 2>> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:         2>> $err_file 2>> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       perc='0.0'
2022-03-14 09:23:03 [INFO] ADDING_LINE:       perc='0.0'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       blobtools_species='missing'
2022-03-14 09:23:03 [INFO] ADDING_LINE:       blobtools_species='missing'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       while read line
2022-03-14 09:23:03 [INFO] ADDING_LINE:       while read line
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       do
2022-03-14 09:23:03 [INFO] ADDING_LINE:       do
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         new_perc=$(echo $line | cut -f 13 -d " " | sed 's/%//g')
2022-03-14 09:23:03 [INFO] ADDING_LINE:         new_perc=$(echo $line | cut -f 13 -d " " | sed 's/%//g')
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         min=$(echo $perc $new_perc | awk '{if ($1 > $2) print $1; else print $2}')
2022-03-14 09:23:03 [INFO] ADDING_LINE:         min=$(echo $perc $new_perc | awk '{if ($1 > $2) print $1; else print $2}')
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:         if [ "$min" != "$perc" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         if [ "$min" != "$perc" ]
2022-03-14 09:23:03 [INFO] ADDING_LINE:         if [ "$min" != "$perc" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         then
2022-03-14 09:23:03 [INFO] ADDING_LINE:         then
2022-03-14 09:23:03 [INFO] PROCESS_LINE:           perc=$new_perc
2022-03-14 09:23:03 [INFO] ADDING_LINE:           perc=$new_perc
2022-03-14 09:23:03 [INFO] PROCESS_LINE:           blobtools_species=$(echo $line | cut -f 1 -d " " )
2022-03-14 09:23:03 [INFO] ADDING_LINE:           blobtools_species=$(echo $line | cut -f 1 -d " " )
2022-03-14 09:23:03 [INFO] PROCESS_LINE:           blobtools_perc=$(echo $line | cut -f 13 -d " " )
2022-03-14 09:23:03 [INFO] ADDING_LINE:           blobtools_perc=$(echo $line | cut -f 13 -d " " )
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         fi
2022-03-14 09:23:03 [INFO] ADDING_LINE:         fi
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       done < <(grep -vw all blobtools/!{sample}*.stats.txt | grep -v "# name" | tr ' ' '_' | grep '%')
2022-03-14 09:23:03 [INFO] ADDING_LINE:       done < <(grep -vw all blobtools/!{sample}*.stats.txt | grep -v "# name" | tr ' ' '_' | grep '%')
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:   }
2022-03-14 09:23:03 [INFO] UPDATING_PROCESS blobtools
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_NAME: mlst
2022-03-14 09:23:03 [INFO] PROCESS_LINE: process mlst {
2022-03-14 09:23:03 [INFO] ADDING_LINE: process mlst {
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:03 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   cpus 1
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   container 'staphb/mlst:latest'
2022-03-14 09:23:03 [INFO] ADDING_LINE:   container 'staphb/mlst:latest'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:03 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:03 [WARN] NO_PROCESS_LABEL: For process name: mlst
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:03 [INFO] CPUS 1 MEM  CONTAINER 'staphb/mlst:latest'
2022-03-14 09:23:03 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:03 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   params.mlst
2022-03-14 09:23:03 [INFO] ADDING_LINE:   params.mlst
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:03 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:03 [WARN] NO_PROCESS_LABEL: For process name: mlst
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:03 [INFO] CPUS 1 MEM  CONTAINER 'staphb/mlst:latest'
2022-03-14 09:23:03 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:03 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   tuple val(sample), file(contig) from contigs_mlst.concat(fastas_mlst)
2022-03-14 09:23:03 [INFO] ADDING_LINE:   tuple val(sample), file(contig) from contigs_mlst.concat(fastas_mlst)
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:03 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:   file("${task.process}/${sample}_mlst.txt") into mlst_files
2022-03-14 09:23:03 [INFO] ADDING_LINE:   file("${task.process}/${sample}_mlst.txt") into mlst_files
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   tuple sample, env(mlst) into mlst_results
2022-03-14 09:23:03 [INFO] ADDING_LINE:   tuple sample, env(mlst) into mlst_results
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:03 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:03 [INFO] ADDING_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] ADDING_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     mlst --version >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:     mlst --version >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     mlst !{contig} 2>> $err_file > mlst/!{sample}_mlst.txt
2022-03-14 09:23:03 [INFO] ADDING_LINE:     mlst !{contig} 2>> $err_file > mlst/!{sample}_mlst.txt
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     mlst=$(awk '{ print $2 ":" $3 }' mlst/!{sample}_mlst.txt)
2022-03-14 09:23:03 [INFO] ADDING_LINE:     mlst=$(awk '{ print $2 ":" $3 }' mlst/!{sample}_mlst.txt)
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:03 [INFO] ADDING_LINE: }
2022-03-14 09:23:03 [INFO] UPDATING_PROCESS mlst
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_NAME: summary
2022-03-14 09:23:03 [INFO] PROCESS_LINE: process summary {
2022-03-14 09:23:03 [INFO] ADDING_LINE: process summary {
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy', overwrite: true
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:03 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   cpus 1
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   container 'staphb/parallel-perl:latest'
2022-03-14 09:23:03 [INFO] ADDING_LINE:   container 'staphb/parallel-perl:latest'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:03 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:03 [WARN] NO_PROCESS_LABEL: For process name: summary
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:03 [INFO] CPUS 1 MEM  CONTAINER 'staphb/parallel-perl:latest'
2022-03-14 09:23:03 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:03 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   params.summary
2022-03-14 09:23:03 [INFO] ADDING_LINE:   params.summary
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:03 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:03 [WARN] NO_PROCESS_LABEL: For process name: summary
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:03 [INFO] CPUS 1 MEM  CONTAINER 'staphb/parallel-perl:latest'
2022-03-14 09:23:03 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:03 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   set val(sample), file(file),
2022-03-14 09:23:03 [INFO] ADDING_LINE:   set val(sample), file(file),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(seqyclean_perc_kept_results),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(seqyclean_perc_kept_results),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(seqyclean_pairskept_results),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(seqyclean_pairskept_results),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(fastqc_1_results),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(fastqc_1_results),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(fastqc_2_results),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(fastqc_2_results),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(mash_genome_size_results),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(mash_genome_size_results),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(mash_coverage_results),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(mash_coverage_results),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(mash_genus_results),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(mash_genus_results),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(mash_species_results),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(mash_species_results),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(mash_full_results),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(mash_full_results),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(mash_pvalue_results),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(mash_pvalue_results),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(mash_distance_results),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(mash_distance_results),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(quast_gc_results),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(quast_gc_results),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(quast_contigs_results),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(quast_contigs_results),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(quast_N50_contigs_results),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(quast_N50_contigs_results),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(quast_length_results),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(quast_length_results),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(cg_avrl_results),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(cg_avrl_results),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(cg_quality_results),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(cg_quality_results),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(cg_cov_results),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(cg_cov_results),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(ref_genome_length),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(ref_genome_length),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(seqsero2_profile_results),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(seqsero2_profile_results),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(seqsero2_serotype_results),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(seqsero2_serotype_results),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(seqsero2_contamination_results),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(seqsero2_contamination_results),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(serotypefinder_results_o),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(serotypefinder_results_o),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(serotypefinder_results_h),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(serotypefinder_results_h),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(shigatyper_predictions),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(shigatyper_predictions),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(shigatyper_cadA),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(shigatyper_cadA),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(kleborate_score),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(kleborate_score),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(kleborate_mlst),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(kleborate_mlst),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(blobtools_species_results),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(blobtools_species_results),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(blobtools_perc_results),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(blobtools_perc_results),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(kraken2_top_hit),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(kraken2_top_hit),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(kraken2_top_perc),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(kraken2_top_perc),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(kraken2_top_reads),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(kraken2_top_reads),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(amr_genes),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(amr_genes),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(virulence_genes),
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(virulence_genes),
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     val(mlst_results) from results
2022-03-14 09:23:03 [INFO] ADDING_LINE:     val(mlst_results) from results
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:03 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:   file("summary/${sample}.summary.txt") into summary_files_txt
2022-03-14 09:23:03 [INFO] ADDING_LINE:   file("summary/${sample}.summary.txt") into summary_files_txt
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:   file("summary/${sample}.summary.tsv") into summary_files_tsv
2022-03-14 09:23:03 [INFO] ADDING_LINE:   file("summary/${sample}.summary.tsv") into summary_files_tsv
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:03 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:03 [INFO] ADDING_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     sample_id_split=($(echo !{sample} | sed 's/-/ /g' | sed 's/_/ /g' ))
2022-03-14 09:23:03 [INFO] ADDING_LINE:     sample_id_split=($(echo !{sample} | sed 's/-/ /g' | sed 's/_/ /g' ))
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:     if [ "${#sample_id_split[@]}" -ge "5" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     if [ "${#sample_id_split[@]}" -ge "5" ]
2022-03-14 09:23:03 [INFO] ADDING_LINE:     if [ "${#sample_id_split[@]}" -ge "5" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:03 [INFO] ADDING_LINE:     then
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       sample_id="${sample_id_split[0]}-${sample_id_split[1]}"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       sample_id="${sample_id_split[0]}-${sample_id_split[1]}"
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:     elif [ "${#sample_id_split[@]}" -eq "4" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     elif [ "${#sample_id_split[@]}" -eq "4" ]
2022-03-14 09:23:03 [INFO] ADDING_LINE:     elif [ "${#sample_id_split[@]}" -eq "4" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:03 [INFO] ADDING_LINE:     then
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       sample_id=${sample_id_split[0]}
2022-03-14 09:23:03 [INFO] ADDING_LINE:       sample_id=${sample_id_split[0]}
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     else
2022-03-14 09:23:03 [INFO] ADDING_LINE:     else
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       sample_id=!{sample}
2022-03-14 09:23:03 [INFO] ADDING_LINE:       sample_id=!{sample}
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:03 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     header="sample_id;sample"
2022-03-14 09:23:03 [INFO] ADDING_LINE:     header="sample_id;sample"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     result="$sample_id;!{sample}"
2022-03-14 09:23:03 [INFO] ADDING_LINE:     result="$sample_id;!{sample}"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     header=$header";seqyclean_pairs_kept;seqyclean_percent_kept"
2022-03-14 09:23:03 [INFO] ADDING_LINE:     header=$header";seqyclean_pairs_kept;seqyclean_percent_kept"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     result=$result";!{seqyclean_pairskept_results};!{seqyclean_perc_kept_results}"
2022-03-14 09:23:03 [INFO] ADDING_LINE:     result=$result";!{seqyclean_pairskept_results};!{seqyclean_perc_kept_results}"
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:     if [ "!{params.fastqc}" != "false" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     if [ "!{params.fastqc}" != "false" ]
2022-03-14 09:23:03 [INFO] ADDING_LINE:     if [ "!{params.fastqc}" != "false" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:03 [INFO] ADDING_LINE:     then
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       header=$header";fastqc_1_reads;fastqc_2_reads"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       header=$header";fastqc_1_reads;fastqc_2_reads"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       result=$result";!{fastqc_1_results};!{fastqc_2_results}"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       result=$result";!{fastqc_1_results};!{fastqc_2_results}"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:03 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:     if [ "!{params.mash}" != "false" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     if [ "!{params.mash}" != "false" ]
2022-03-14 09:23:03 [INFO] ADDING_LINE:     if [ "!{params.mash}" != "false" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:03 [INFO] ADDING_LINE:     then
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       header=$header";mash_genome_size;mash_coverage;mash_genus;mash_species;mash_full;mash_pvalue;mash_distance"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       header=$header";mash_genome_size;mash_coverage;mash_genus;mash_species;mash_full;mash_pvalue;mash_distance"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       result=$result";!{mash_genome_size_results};!{mash_coverage_results};!{mash_genus_results};!{mash_species_results};!{mash_full_results};!{mash_pvalue_results};!{mash_distance_results}"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       result=$result";!{mash_genome_size_results};!{mash_coverage_results};!{mash_genus_results};!{mash_species_results};!{mash_full_results};!{mash_pvalue_results};!{mash_distance_results}"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:03 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:     if [ "!{params.quast}" != "false" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     if [ "!{params.quast}" != "false" ]
2022-03-14 09:23:03 [INFO] ADDING_LINE:     if [ "!{params.quast}" != "false" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:03 [INFO] ADDING_LINE:     then
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       header=$header";quast_gc_%;quast_contigs;quast_N50;quast_length"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       header=$header";quast_gc_%;quast_contigs;quast_N50;quast_length"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       result=$result";!{quast_gc_results};!{quast_contigs_results};!{quast_N50_contigs_results};!{quast_length_results}"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       result=$result";!{quast_gc_results};!{quast_contigs_results};!{quast_N50_contigs_results};!{quast_length_results}"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:03 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:     if [ "!{params.cg_pipeline}" != "false" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     if [ "!{params.cg_pipeline}" != "false" ]
2022-03-14 09:23:03 [INFO] ADDING_LINE:     if [ "!{params.cg_pipeline}" != "false" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:03 [INFO] ADDING_LINE:     then
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       header=$header";cg_average_read_length;cg_average_quality;cg_coverage;ref_genome_length"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       header=$header";cg_average_read_length;cg_average_quality;cg_coverage;ref_genome_length"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       result=$result";!{cg_avrl_results};!{cg_quality_results};!{cg_cov_results};!{ref_genome_length}"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       result=$result";!{cg_avrl_results};!{cg_quality_results};!{cg_cov_results};!{ref_genome_length}"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:03 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:     if [ "!{params.seqsero2}" != "false" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     if [ "!{params.seqsero2}" != "false" ]
2022-03-14 09:23:03 [INFO] ADDING_LINE:     if [ "!{params.seqsero2}" != "false" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:03 [INFO] ADDING_LINE:     then
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       header=$header";seqsero2_profile;seqsero2_serotype;seqsero2_contamination"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       header=$header";seqsero2_profile;seqsero2_serotype;seqsero2_contamination"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       result=$result";!{seqsero2_profile_results};!{seqsero2_serotype_results};!{seqsero2_contamination_results}"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       result=$result";!{seqsero2_profile_results};!{seqsero2_serotype_results};!{seqsero2_contamination_results}"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:03 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:     if [ "!{params.serotypefinder}" != "false" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     if [ "!{params.serotypefinder}" != "false" ]
2022-03-14 09:23:03 [INFO] ADDING_LINE:     if [ "!{params.serotypefinder}" != "false" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:03 [INFO] ADDING_LINE:     then
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       header=$header";serotypefinder_o_group;serotypefinder_h_group"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       header=$header";serotypefinder_o_group;serotypefinder_h_group"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       result=$result";!{serotypefinder_results_o};!{serotypefinder_results_h}"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       result=$result";!{serotypefinder_results_o};!{serotypefinder_results_h}"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:03 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:     if [ "!{params.kleborate}" != "false" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     if [ "!{params.kleborate}" != "false" ]
2022-03-14 09:23:03 [INFO] ADDING_LINE:     if [ "!{params.kleborate}" != "false" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:03 [INFO] ADDING_LINE:     then
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       header=$header";kleborate_score;kleborate_mlst"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       header=$header";kleborate_score;kleborate_mlst"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       result=$result";!{kleborate_score};!{kleborate_mlst}"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       result=$result";!{kleborate_score};!{kleborate_mlst}"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:03 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:     if [ "!{params.amrfinderplus}" != "false" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     if [ "!{params.amrfinderplus}" != "false" ]
2022-03-14 09:23:03 [INFO] ADDING_LINE:     if [ "!{params.amrfinderplus}" != "false" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:03 [INFO] ADDING_LINE:     then
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       header=$header";amr_genes;virulence_genes"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       header=$header";amr_genes;virulence_genes"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       result=$result";!{amr_genes};!{virulence_genes}"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       result=$result";!{amr_genes};!{virulence_genes}"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:03 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:     if [ "!{params.blobtools}" != "false" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     if [ "!{params.blobtools}" != "false" ]
2022-03-14 09:23:03 [INFO] ADDING_LINE:     if [ "!{params.blobtools}" != "false" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:03 [INFO] ADDING_LINE:     then
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       header=$header";blobtools_top_species;blobtools_percentage"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       header=$header";blobtools_top_species;blobtools_percentage"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       result=$result";!{blobtools_species_results};!{blobtools_perc_results}"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       result=$result";!{blobtools_species_results};!{blobtools_perc_results}"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:03 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:     if [ "!{params.kraken2}" != "false" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     if [ "!{params.kraken2}" != "false" ]
2022-03-14 09:23:03 [INFO] ADDING_LINE:     if [ "!{params.kraken2}" != "false" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:03 [INFO] ADDING_LINE:     then
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       header=$header";kraken2_top_species;kraken2_num_reads;kraken2_percentage"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       header=$header";kraken2_top_species;kraken2_num_reads;kraken2_percentage"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       result=$result";!{kraken2_top_hit};!{kraken2_top_reads};!{kraken2_top_perc}"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       result=$result";!{kraken2_top_hit};!{kraken2_top_reads};!{kraken2_top_perc}"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:03 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:     if [ "!{params.mlst}" != "false" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     if [ "!{params.mlst}" != "false" ]
2022-03-14 09:23:03 [INFO] ADDING_LINE:     if [ "!{params.mlst}" != "false" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:03 [INFO] ADDING_LINE:     then
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       header=$header";mlst"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       header=$header";mlst"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       result=$result";!{mlst_results}"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       result=$result";!{mlst_results}"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:03 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:     if [ "!{params.shigatyper}" != "false" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     if [ "!{params.shigatyper}" != "false" ]
2022-03-14 09:23:03 [INFO] ADDING_LINE:     if [ "!{params.shigatyper}" != "false" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:03 [INFO] ADDING_LINE:     then
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       header=$header";shigatyper_predictions;shigatyper_cadA"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       header=$header";shigatyper_predictions;shigatyper_cadA"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       result=$result";!{shigatyper_predictions};!{shigatyper_cadA}"
2022-03-14 09:23:03 [INFO] ADDING_LINE:       result=$result";!{shigatyper_predictions};!{shigatyper_cadA}"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:03 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     echo $header > summary/!{sample}.summary.txt
2022-03-14 09:23:03 [INFO] ADDING_LINE:     echo $header > summary/!{sample}.summary.txt
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     echo $result >> summary/!{sample}.summary.txt
2022-03-14 09:23:03 [INFO] ADDING_LINE:     echo $result >> summary/!{sample}.summary.txt
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     cat summary/!{sample}.summary.txt | tr ';' '\t' > summary/!{sample}.summary.tsv
2022-03-14 09:23:03 [INFO] ADDING_LINE:     cat summary/!{sample}.summary.txt | tr ';' '\t' > summary/!{sample}.summary.tsv
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:03 [INFO] ADDING_LINE: }
2022-03-14 09:23:03 [INFO] UPDATING_PROCESS summary
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_NAME: multiqc
2022-03-14 09:23:03 [INFO] PROCESS_LINE: process multiqc {
2022-03-14 09:23:03 [INFO] ADDING_LINE: process multiqc {
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   tag "multiqc"
2022-03-14 09:23:03 [INFO] ADDING_LINE:   tag "multiqc"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   cpus 1
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   container 'ewels/multiqc:latest'
2022-03-14 09:23:03 [INFO] ADDING_LINE:   container 'ewels/multiqc:latest'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:03 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:03 [WARN] NO_PROCESS_LABEL: For process name: multiqc
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:03 [INFO] CPUS 1 MEM  CONTAINER 'ewels/multiqc:latest'
2022-03-14 09:23:03 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:03 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   params.multiqc
2022-03-14 09:23:03 [INFO] ADDING_LINE:   params.multiqc
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:03 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:03 [WARN] NO_PROCESS_LABEL: For process name: multiqc
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:03 [INFO] CPUS 1 MEM  CONTAINER 'ewels/multiqc:latest'
2022-03-14 09:23:03 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:03 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   file(fastqc) from fastqc_files.collect().ifEmpty([])
2022-03-14 09:23:03 [INFO] ADDING_LINE:   file(fastqc) from fastqc_files.collect().ifEmpty([])
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   file(quast) from quast_files.collect().ifEmpty([])
2022-03-14 09:23:03 [INFO] ADDING_LINE:   file(quast) from quast_files.collect().ifEmpty([])
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   file(seqyclean) from seqyclean_files.collect().ifEmpty([])
2022-03-14 09:23:03 [INFO] ADDING_LINE:   file(seqyclean) from seqyclean_files.collect().ifEmpty([])
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   file(kraken2) from kraken2_files.collect().ifEmpty([])
2022-03-14 09:23:03 [INFO] ADDING_LINE:   file(kraken2) from kraken2_files.collect().ifEmpty([])
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   file(prokka) from prokka_files.collect().ifEmpty([])
2022-03-14 09:23:03 [INFO] ADDING_LINE:   file(prokka) from prokka_files.collect().ifEmpty([])
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:03 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:   file("${task.process}/multiqc_report.html") optional true
2022-03-14 09:23:03 [INFO] ADDING_LINE:   file("${task.process}/multiqc_report.html") optional true
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:   file("${task.process}/multiqc_data/*") optional true
2022-03-14 09:23:03 [INFO] ADDING_LINE:   file("${task.process}/multiqc_data/*") optional true
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] ADDING_LINE:   file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:03 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     mkdir -p !{task.process} quast fastqc kraken2 prokka seqyclean logs/!{task.process}
2022-03-14 09:23:03 [INFO] ADDING_LINE:     mkdir -p !{task.process} quast fastqc kraken2 prokka seqyclean logs/!{task.process}
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] ADDING_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     multiqc --version >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:     multiqc --version >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:     cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     for quast_file in !{quast}
2022-03-14 09:23:03 [INFO] ADDING_LINE:     for quast_file in !{quast}
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     do
2022-03-14 09:23:03 [INFO] ADDING_LINE:     do
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:       if [ -f "$quast_file" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       if [ -f "$quast_file" ]
2022-03-14 09:23:03 [INFO] ADDING_LINE:       if [ -f "$quast_file" ]
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       then
2022-03-14 09:23:03 [INFO] ADDING_LINE:       then
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         sample=$(echo $quast_file | sed 's/_quast_report.tsv//g' | head -n 1 )
2022-03-14 09:23:03 [INFO] ADDING_LINE:         sample=$(echo $quast_file | sed 's/_quast_report.tsv//g' | head -n 1 )
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         mkdir -p quast/$sample
2022-03-14 09:23:03 [INFO] ADDING_LINE:         mkdir -p quast/$sample
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         mv $quast_file quast/$sample/report.tsv
2022-03-14 09:23:03 [INFO] ADDING_LINE:         mv $quast_file quast/$sample/report.tsv
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       fi
2022-03-14 09:23:03 [INFO] ADDING_LINE:       fi
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     done
2022-03-14 09:23:03 [INFO] ADDING_LINE:     done
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     multiqc !{params.multiqc_options} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:     multiqc !{params.multiqc_options} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       --outdir !{task.process} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:       --outdir !{task.process} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       --cl_config "prokka_fn_snames: True"  \
2022-03-14 09:23:03 [INFO] ADDING_LINE:       --cl_config "prokka_fn_snames: True"  \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       . \
2022-03-14 09:23:03 [INFO] ADDING_LINE:       . \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       2>> $err_file >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       2>> $err_file >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:03 [INFO] ADDING_LINE: }
2022-03-14 09:23:03 [INFO] UPDATING_PROCESS multiqc
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_NAME: roary
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   process roary {
2022-03-14 09:23:03 [INFO] ADDING_LINE:   process roary {
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tag "Core Genome Alignment"
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tag "Core Genome Alignment"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     cpus params.maxcpus
2022-03-14 09:23:03 [INFO] INITIAL_LINE:     cpus params.maxcpus
2022-03-14 09:23:03 [INFO] TRANSLATED_LINE:     cpus 16
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     container 'staphb/roary:latest'
2022-03-14 09:23:03 [INFO] ADDING_LINE:     container 'staphb/roary:latest'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     input:
2022-03-14 09:23:03 [INFO] LINE_INDENT_FIRST_TOKEN:     input:
2022-03-14 09:23:03 [WARN] NO_PROCESS_LABEL: For process name: roary
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:03 [INFO] CPUS 16 MEM  CONTAINER 'staphb/roary:latest'
2022-03-14 09:23:03 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:03 [INFO] ADDING_LINE:     input:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     file(contigs) from gffs.concat(local_gffs).collect()
2022-03-14 09:23:03 [INFO] ADDING_LINE:     file(contigs) from gffs.concat(local_gffs).collect()
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     output:
2022-03-14 09:23:03 [INFO] ADDING_LINE:     output:
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     file("roary/*")
2022-03-14 09:23:03 [INFO] ADDING_LINE:     file("roary/*")
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     file("roary/fixed_input_files/*")
2022-03-14 09:23:03 [INFO] ADDING_LINE:     file("roary/fixed_input_files/*")
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     file("roary/core_gene_alignment.aln") into roary_core_genome_iqtree, roary_core_genome_snp_dists
2022-03-14 09:23:03 [INFO] ADDING_LINE:     file("roary/core_gene_alignment.aln") into roary_core_genome_iqtree, roary_core_genome_snp_dists
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] ADDING_LINE:     file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     shell:
2022-03-14 09:23:03 [INFO] ADDING_LINE:     shell:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       mkdir -p logs/!{task.process}
2022-03-14 09:23:03 [INFO] ADDING_LINE:       mkdir -p logs/!{task.process}
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:       log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] ADDING_LINE:       log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:       err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] ADDING_LINE:       err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] ADDING_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] ADDING_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       roary -a >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       roary -a >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       echo "There are $(ls *gff | wc -l) files for alignment" >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       echo "There are $(ls *gff | wc -l) files for alignment" >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       roary !{params.roary_options} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:       roary !{params.roary_options} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         -p !{task.cpus} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         -p !{task.cpus} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         -f roary \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         -f roary \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         -e -n \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         -e -n \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         *.gff \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         *.gff \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         2>> $err_file >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:         2>> $err_file >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:   }
2022-03-14 09:23:03 [INFO] UPDATING_PROCESS roary
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_NAME: iqtree2
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   process iqtree2 {
2022-03-14 09:23:03 [INFO] ADDING_LINE:   process iqtree2 {
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tag "Pylogenetic Tree"
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tag "Pylogenetic Tree"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     cpus params.maxcpus
2022-03-14 09:23:03 [INFO] INITIAL_LINE:     cpus params.maxcpus
2022-03-14 09:23:03 [INFO] TRANSLATED_LINE:     cpus 16
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     container 'staphb/iqtree2:latest'
2022-03-14 09:23:03 [INFO] ADDING_LINE:     container 'staphb/iqtree2:latest'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     when:
2022-03-14 09:23:03 [INFO] LINE_INDENT_FIRST_TOKEN:     
2022-03-14 09:23:03 [WARN] NO_PROCESS_LABEL: For process name: iqtree2
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:03 [INFO] CPUS 16 MEM  CONTAINER 'staphb/iqtree2:latest'
2022-03-14 09:23:03 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:03 [INFO] ADDING_LINE:     when:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     params.iqtree2
2022-03-14 09:23:03 [INFO] ADDING_LINE:     params.iqtree2
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     input:
2022-03-14 09:23:03 [INFO] LINE_INDENT_FIRST_TOKEN:     input:
2022-03-14 09:23:03 [WARN] NO_PROCESS_LABEL: For process name: iqtree2
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:03 [INFO] CPUS 16 MEM  CONTAINER 'staphb/iqtree2:latest'
2022-03-14 09:23:03 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:03 [INFO] ADDING_LINE:     input:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     file(msa) from roary_core_genome_iqtree
2022-03-14 09:23:03 [INFO] ADDING_LINE:     file(msa) from roary_core_genome_iqtree
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     output:
2022-03-14 09:23:03 [INFO] ADDING_LINE:     output:
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     file("${task.process}/iqtree{.ckp.gz,.treefile,.iqtree,.log,.splits.nex}")
2022-03-14 09:23:03 [INFO] ADDING_LINE:     file("${task.process}/iqtree{.ckp.gz,.treefile,.iqtree,.log,.splits.nex}")
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     file("${task.process}/iqtree.contree") into treefile
2022-03-14 09:23:03 [INFO] ADDING_LINE:     file("${task.process}/iqtree.contree") into treefile
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] ADDING_LINE:     file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     shell:
2022-03-14 09:23:03 [INFO] ADDING_LINE:     shell:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:03 [INFO] ADDING_LINE:       mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:       log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] ADDING_LINE:       log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:       err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] ADDING_LINE:       err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] ADDING_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] ADDING_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       iqtree2 -v >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       iqtree2 -v >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       outgroup=''
2022-03-14 09:23:03 [INFO] ADDING_LINE:       outgroup=''
2022-03-14 09:23:03 [INFO] EXPRESSION_LINE:       if [ -n "!{params.outgroup}" ] ; then outgroup="-o !{params.outgroup}" ; fi
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       if [ -n "!{params.outgroup}" ] ; then outgroup="-o !{params.outgroup}" ; fi
2022-03-14 09:23:03 [INFO] ADDING_LINE:       if [ -n "!{params.outgroup}" ] ; then outgroup="-o !{params.outgroup}" ; fi
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       iqtree2 !{params.iqtree2_options} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:       iqtree2 !{params.iqtree2_options} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         -s !{msa} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         -s !{msa} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         -pre !{task.process}/iqtree \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         -pre !{task.process}/iqtree \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         -nt AUTO \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         -nt AUTO \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         -ntmax !{task.cpus} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         -ntmax !{task.cpus} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         $outgroup \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         $outgroup \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         2>> $err_file >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:         2>> $err_file >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:   }
2022-03-14 09:23:03 [INFO] UPDATING_PROCESS iqtree2
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_NAME: snp_dists
2022-03-14 09:23:03 [INFO] PROCESS_LINE:   process snp_dists {
2022-03-14 09:23:03 [INFO] ADDING_LINE:   process snp_dists {
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     tag "SNP matrix"
2022-03-14 09:23:03 [INFO] ADDING_LINE:     tag "SNP matrix"
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     cpus 1
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     container 'staphb/snp-dists:latest'
2022-03-14 09:23:03 [INFO] ADDING_LINE:     container 'staphb/snp-dists:latest'
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     when:
2022-03-14 09:23:03 [INFO] LINE_INDENT_FIRST_TOKEN:     
2022-03-14 09:23:03 [WARN] NO_PROCESS_LABEL: For process name: snp_dists
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:03 [INFO] CPUS 1 MEM  CONTAINER 'staphb/snp-dists:latest'
2022-03-14 09:23:03 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:03 [INFO] ADDING_LINE:     when:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     params.snp_dists
2022-03-14 09:23:03 [INFO] ADDING_LINE:     params.snp_dists
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     input:
2022-03-14 09:23:03 [INFO] LINE_INDENT_FIRST_TOKEN:     input:
2022-03-14 09:23:03 [WARN] NO_PROCESS_LABEL: For process name: snp_dists
2022-03-14 09:23:03 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:03 [INFO] CPUS 1 MEM  CONTAINER 'staphb/snp-dists:latest'
2022-03-14 09:23:03 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:03 [INFO] ADDING_LINE:     input:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     file(contigs) from roary_core_genome_snp_dists
2022-03-14 09:23:03 [INFO] ADDING_LINE:     file(contigs) from roary_core_genome_snp_dists
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     output:
2022-03-14 09:23:03 [INFO] ADDING_LINE:     output:
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     file("${task.process}/snp_matrix.txt")
2022-03-14 09:23:03 [INFO] ADDING_LINE:     file("${task.process}/snp_matrix.txt")
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:     file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] ADDING_LINE:     file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     shell:
2022-03-14 09:23:03 [INFO] ADDING_LINE:     shell:
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:03 [INFO] ADDING_LINE:       mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:       log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] ADDING_LINE:       log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] NOT_PARSING_LINE:       err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] ADDING_LINE:       err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] ADDING_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] ADDING_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       snp-dists -v >> $log_file
2022-03-14 09:23:03 [INFO] ADDING_LINE:       snp-dists -v >> $log_file
2022-03-14 09:23:03 [INFO] PROCESS_LINE:       snp-dists !{params.snp_dists_options} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:       snp-dists !{params.snp_dists_options} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         !{contigs} \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         !{contigs} \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         2>> $err_file \
2022-03-14 09:23:03 [INFO] ADDING_LINE:         2>> $err_file \
2022-03-14 09:23:03 [INFO] PROCESS_LINE:         > !{task.process}/snp_matrix.txt
2022-03-14 09:23:03 [INFO] ADDING_LINE:         > !{task.process}/snp_matrix.txt
2022-03-14 09:23:03 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:03 [INFO] ADDING_LINE:   }
2022-03-14 09:23:03 [INFO] UPDATING_PROCESS snp_dists
$seqyclean
$seqyclean$process_lines
 [1] "process seqyclean {"                                                                                                                                                                                               
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                                                                                                                                   
 [3] "  tag \"${sample}\""                                                                                                                                                                                               
 [4] "  container 'staphb/seqyclean:latest'"                                                                                                                                                                             
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                                                                                     
 [6] "  errorStrategy 'ignore'"                                                                                                                                                                                          
 [7] "  time '1day'"                                                                                                                                                                                                     
 [8] "  when:"                                                                                                                                                                                                           
 [9] "  sample != null"                                                                                                                                                                                                  
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                                                                               
[11] "  input:errorStrategy 'ignore'"                                                                                                                                                                                    
[12] "  input:time '1day'"                                                                                                                                                                                               
[13] "  input:"                                                                                                                                                                                                          
[14] "  tuple val(sample), file(reads) from reads_seqyclean"                                                                                                                                                             
[15] "  output:"                                                                                                                                                                                                         
[16] "  tuple sample, file(\"seqyclean/${sample}_clean_PE{1,2}.fastq.gz\") into clean_reads_mash, clean_reads_cg, clean_reads_seqsero2, clean_reads_bwa, clean_reads_shigatyper, clean_reads_kraken2, clean_reads_spades"
[17] "  file(\"seqyclean/${sample}_clean_SE.fastq.gz\")"                                                                                                                                                                 
[18] "  file(\"seqyclean/${sample}_clean_SummaryStatistics.tsv\") into seqyclean_files, seqyclean_files_combine"                                                                                                         
[19] "  file(\"seqyclean/${sample}_clean_SummaryStatistics.txt\")"                                                                                                                                                       
[20] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                                                                                                        
[21] "  tuple sample, env(perc_kept) into seqyclean_perc_kept_results"                                                                                                                                                   
[22] "  tuple sample, env(kept) into seqyclean_pairskept_results"                                                                                                                                                        
[23] "  shell:"                                                                                                                                                                                                          
[24] "  '''"                                                                                                                                                                                                             
[25] "    mkdir -p !{task.process} logs/!{task.process}"                                                                                                                                                                 
[26] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                                                                                                             
[27] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                                                                                                             
[28] "    # time stamp + capturing tool versions"                                                                                                                                                                        
[29] "    date | tee -a $log_file $err_file > /dev/null"                                                                                                                                                                 
[30] "    echo \"container : !{task.container}\" >> $log_file"                                                                                                                                                           
[31] "    echo \"seqyclean version: $(seqyclean -h | grep Version | head -n 1)\" >> $log_file"                                                                                                                           
[32] "    echo \"Nextflow command : \" >> $log_file"                                                                                                                                                                     
[33] "    cat .command.sh >> $log_file"                                                                                                                                                                                  
[34] "    seqyclean !{params.seqyclean_options} \\"                                                                                                                                                                      
[35] "      -c !{params.seqyclean_contaminant_file} \\"                                                                                                                                                                  
[36] "      -1 !{reads[0]} \\"                                                                                                                                                                                           
[37] "      -2 !{reads[1]} \\"                                                                                                                                                                                           
[38] "      -o seqyclean/!{sample}_clean \\"                                                                                                                                                                             
[39] "      -gz \\"                                                                                                                                                                                                      
[40] "      2>> $err_file >> $log_file"                                                                                                                                                                                  
[41] "    kept=$(cut -f 58 seqyclean/!{sample}_clean_SummaryStatistics.tsv | grep -v \"Kept\" | head -n 1)"                                                                                                              
[42] "    perc_kept=$(cut -f 59 seqyclean/!{sample}_clean_SummaryStatistics.tsv | grep -v \"Kept\" | head -n 1)"                                                                                                         
[43] "    if [ -z \"$kept\" ] ; then kept=\"0\" ; fi"                                                                                                                                                                    
[44] "    if [ -z \"$perc_kept\" ] ; then perc_kept=\"0\" ; fi"                                                                                                                                                          
[45] "  '''"                                                                                                                                                                                                             
[46] "}"                                                                                                                                                                                                                 

$seqyclean$line_numbers
 [1]  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110
[20] 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129
[39] 130 131 132

$seqyclean$cpus_parsed
[1] 1


$spades
$spades$process_lines
 [1] "process spades {"                                                                                                                                                                                                  
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                                                                                                                                   
 [3] "  tag \"${sample}\""                                                                                                                                                                                               
 [4] "  container 'staphb/spades:latest'"                                                                                                                                                                                
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                                                                                     
 [6] "  errorStrategy 'ignore'"                                                                                                                                                                                          
 [7] "  time '1day'"                                                                                                                                                                                                     
 [8] "  when:"                                                                                                                                                                                                           
 [9] "  params.spades"                                                                                                                                                                                                   
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                                                                               
[11] "  input:errorStrategy 'ignore'"                                                                                                                                                                                    
[12] "  input:time '1day'"                                                                                                                                                                                               
[13] "  input:"                                                                                                                                                                                                          
[14] "  tuple val(sample), file(reads) from clean_reads_spades"                                                                                                                                                          
[15] "  output:"                                                                                                                                                                                                         
[16] "  path(\"${task.process}/${sample}\")"                                                                                                                                                                             
[17] "  tuple sample, file(\"contigs/${sample}_contigs.fa\") into contigs_prokka, contigs_quast, contigs_blastn, contigs_mlst, contigs_bwa, contigs_create, contigs_kleborate, contigs_amrfinder, contigs_serotypefinder"
[18] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                                                                                                        
[19] "  shell:"                                                                                                                                                                                                          
[20] "  '''"                                                                                                                                                                                                             
[21] "    mkdir -p !{task.process} contigs logs/!{task.process}"                                                                                                                                                         
[22] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                                                                                                             
[23] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                                                                                                             
[24] "    # time stamp + capturing tool versions"                                                                                                                                                                        
[25] "    date | tee -a $log_file $err_file > /dev/null"                                                                                                                                                                 
[26] "    echo \"container : !{task.container}\" >> $log_file"                                                                                                                                                           
[27] "    spades.py --version >> $log_file"                                                                                                                                                                              
[28] "    echo \"Nextflow command : \" >> $log_file"                                                                                                                                                                     
[29] "    cat .command.sh >> $log_file"                                                                                                                                                                                  
[30] "    spades.py !{params.spades_options} \\"                                                                                                                                                                         
[31] "      -1 !{reads[0]} \\"                                                                                                                                                                                           
[32] "      -2 !{reads[1]} \\"                                                                                                                                                                                           
[33] "      --threads !{task.cpus} \\"                                                                                                                                                                                   
[34] "      -o !{task.process}/!{sample} \\"                                                                                                                                                                             
[35] "      2>> $err_file >> $log_file"                                                                                                                                                                                  
[36] "    cp !{task.process}/!{sample}/contigs.fasta contigs/!{sample}_contigs.fa"                                                                                                                                       
[37] "  '''"                                                                                                                                                                                                             
[38] "}"                                                                                                                                                                                                                 

$spades$line_numbers
 [1] 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158
[20] 159 160 161 162 163 164 165 166 167 168 169 170 171 172

$spades$cpus_parsed
[1] 16


$fastqc
$fastqc$process_lines
 [1] "process fastqc {"                                                                                           
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                            
 [3] "  tag \"${sample}\""                                                                                        
 [4] "  container 'staphb/fastqc:latest'"                                                                         
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                              
 [6] "  errorStrategy 'ignore'"                                                                                   
 [7] "  time '1day'"                                                                                              
 [8] "  when:"                                                                                                    
 [9] "  params.fastqc && sample != null"                                                                          
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                        
[11] "  input:errorStrategy 'ignore'"                                                                             
[12] "  input:time '1day'"                                                                                        
[13] "  input:"                                                                                                   
[14] "  tuple val(sample), file(raw) from reads_fastqc"                                                           
[15] "  output:"                                                                                                  
[16] "  file(\"${task.process}/*.html\")"                                                                         
[17] "  file(\"${task.process}/*_fastqc.zip\") into fastqc_files"                                                 
[18] "  tuple sample, env(raw_1) into fastqc_1_results"                                                           
[19] "  tuple sample, env(raw_2) into fastqc_2_results"                                                           
[20] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                 
[21] "  shell:"                                                                                                   
[22] "  '''"                                                                                                      
[23] "    mkdir -p !{task.process} logs/!{task.process}"                                                          
[24] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                      
[25] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                      
[26] "    # time stamp + capturing tool versions"                                                                 
[27] "    date | tee -a $log_file $err_file > /dev/null"                                                          
[28] "    echo \"container : !{task.container}\" >> $log_file"                                                    
[29] "    fastqc --version >> $log_file"                                                                          
[30] "    echo \"Nextflow command : \" >> $log_file"                                                              
[31] "    cat .command.sh >> $log_file"                                                                           
[32] "    fastqc !{params.fastqc_options} \\"                                                                     
[33] "      --outdir fastqc \\"                                                                                   
[34] "      --threads !{task.cpus} \\"                                                                            
[35] "      !{raw} \\"                                                                                            
[36] "      2>> $err_file >> $log_file"                                                                           
[37] "    zipped_fastq=($(ls fastqc/*fastqc.zip) \"\")"                                                           
[38] "    raw_1=$(unzip -p ${zipped_fastq[0]} */fastqc_data.txt | grep \"Total Sequences\" | awk '{ print $3 }' )"
[39] "    raw_2=$(unzip -p fastqc/*fastqc.zip */fastqc_data.txt | grep \"Total Sequences\" | awk '{ print $3 }' )"
[40] "    if [ -z \"$raw_1\" ] ; then raw_1=\"0\" ; fi"                                                           
[41] "    if [ -z \"$raw_2\" ] ; then raw_2=\"0\" ; fi"                                                           
[42] "  '''"                                                                                                      
[43] "}"                                                                                                          

$fastqc$line_numbers
 [1] 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193
[20] 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212

$fastqc$cpus_parsed
[1] 1


$mash_sketch
$mash_sketch$process_lines
 [1] "process mash_sketch {"                                                                
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                      
 [3] "  tag \"${sample}\""                                                                  
 [4] "  container 'staphb/mash:latest'"                                                     
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"        
 [6] "  errorStrategy 'ignore'"                                                             
 [7] "  time '1day'"                                                                        
 [8] "  when:"                                                                              
 [9] "  params.mash"                                                                        
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"  
[11] "  input:errorStrategy 'ignore'"                                                       
[12] "  input:time '1day'"                                                                  
[13] "  input:"                                                                             
[14] "  tuple val(sample), file(reads) from clean_reads_mash"                               
[15] "  output:"                                                                            
[16] "  tuple sample, file(\"mash/${sample}.msh\") into mash_sketch_files optional true"    
[17] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"           
[18] "  tuple sample, env(genome_size) into mash_genome_size_results, mash_genome_size_gc"  
[19] "  tuple sample, env(coverage) into mash_coverage_results"                             
[20] "  shell:"                                                                             
[21] "  '''"                                                                                
[22] "    mkdir -p mash logs/!{task.process}"                                               
[23] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                
[24] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                
[25] "    # time stamp + capturing tool versions"                                           
[26] "    date | tee -a $log_file $err_file > /dev/null"                                    
[27] "    echo \"container : !{task.container}\" >> $log_file"                              
[28] "    echo \"mash version: $(mash --version | head -n 1 )\" >> $log_file"               
[29] "    echo \"Nextflow command : \" >> $log_file"                                        
[30] "    cat .command.sh >> $log_file"                                                     
[31] "    cat !{reads} | mash sketch -m 2 -o mash/!{sample} - 2>> $err_file | tee $log_file"
[32] "    genome_size=$(grep \"Estimated genome size\" $err_file | awk '{print $4}' )"      
[33] "    coverage=$(grep \"Estimated coverage\" $err_file | awk '{print $3}' )"            
[34] "  '''"                                                                                
[35] "}"                                                                                    

$mash_sketch$line_numbers
 [1] 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232
[20] 233 234 235 236 237 238 239 240 241 242 243

$mash_sketch$cpus_parsed
[1] 1


$mash_dist
$mash_dist$process_lines
 [1] "process mash_dist {"                                                                                                                                                                  
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                                                                                                      
 [3] "  tag \"${sample}\""                                                                                                                                                                  
 [4] "  container 'staphb/mash:latest'"                                                                                                                                                     
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                                                        
 [6] "  errorStrategy 'ignore'"                                                                                                                                                             
 [7] "  time '1day'"                                                                                                                                                                        
 [8] "  when:"                                                                                                                                                                              
 [9] "  params.mash"                                                                                                                                                                        
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                                                  
[11] "  input:errorStrategy 'ignore'"                                                                                                                                                       
[12] "  input:time '1day'"                                                                                                                                                                  
[13] "  input:"                                                                                                                                                                             
[14] "  tuple val(sample), file(msh) from mash_sketch_files.concat(fastas_mash)"                                                                                                            
[15] "  output:"                                                                                                                                                                            
[16] "  tuple sample, file(\"mash/${sample}_mashdist.txt\") optional true"                                                                                                                  
[17] "  tuple sample, env(genus) into mash_genus_results, mash_genus_prokka, mash_genus_gc, mash_genus_amrfinder"                                                                           
[18] "  tuple sample, env(species) into mash_species_results, mash_species_prokka, mash_species_gc, mash_species_amrfinder"                                                                 
[19] "  tuple sample, env(full_mash) into mash_full_results"                                                                                                                                
[20] "  tuple sample, env(pvalue) into mash_pvalue_results"                                                                                                                                 
[21] "  tuple sample, env(distance) into mash_distance_results"                                                                                                                             
[22] "  tuple sample, env(salmonella_flag) into salmonella_flag"                                                                                                                            
[23] "  tuple sample, env(ecoli_flag) into ecoli_flag, shigella_flag"                                                                                                                       
[24] "  tuple sample, env(klebsiella_flag) into klebsiella_flag"                                                                                                                            
[25] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                                                                           
[26] "  shell:"                                                                                                                                                                             
[27] "  '''"                                                                                                                                                                                
[28] "    mkdir -p mash logs/!{task.process}"                                                                                                                                               
[29] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                                                                                
[30] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                                                                                
[31] "    # time stamp + capturing tool versions"                                                                                                                                           
[32] "    date | tee -a $log_file $err_file > /dev/null"                                                                                                                                    
[33] "    echo \"container : !{task.container}\" >> $log_file"                                                                                                                              
[34] "    echo \"mash version: $(mash --version | head -n 1 )\" >> $log_file"                                                                                                               
[35] "    echo \"Nextflow command : \" >> $log_file"                                                                                                                                        
[36] "    cat .command.sh >> $log_file"                                                                                                                                                     
[37] "    mash dist -p !{task.cpus} !{params.mash_options} !{params.mash_reference} !{msh} | sort -gk3 > mash/!{sample}_mashdist.txt 2>> $err_file"                                         
[38] "    if [ ! -s \"mash/!{sample}_mashdist.txt\" ]"                                                                                                                                      
[39] "    then"                                                                                                                                                                             
[40] "      echo \"!{sample} had no mash results with '!{params.mash_options}'. Trying again without those parameters.\" 2>> $log_file"                                                     
[41] "      mash dist -p !{task.cpus} !{params.mash_reference} !{msh} | sort -gk3 > mash/!{sample}_mashdist.txt 2>> $err_file"                                                              
[42] "    fi"                                                                                                                                                                               
[43] "    mash_result=($(head -n 1 mash/!{sample}_mashdist.txt | head -n 1 | cut -f 1 | cut -f 8 -d \"-\" | cut -f 1,2 -d \"_\" | cut -f 1 -d \".\" | tr \"_\" \" \" ) 'missing' 'missing')"
[44] "    genus=${mash_result[0]}"                                                                                                                                                          
[45] "    species=${mash_result[1]}"                                                                                                                                                        
[46] "    full_mash=$(head -n 1 mash/!{sample}_mashdist.txt | cut -f 1 )"                                                                                                                   
[47] "    pvalue=$(head -n 1 mash/!{sample}_mashdist.txt | cut -f 4 )"                                                                                                                      
[48] "    distance=$(head -n 1 mash/!{sample}_mashdist.txt | cut -f 3 )"                                                                                                                    
[49] "    if [ -z \"$full_mash\" ] ; then full_mash='missing' ; fi"                                                                                                                         
[50] "    if [ -z \"$pvalue\" ] ; then pvalue='NA' ; fi"                                                                                                                                    
[51] "    if [ -z \"$distance\" ] ; then distance='NA' ; fi"                                                                                                                                
[52] "    salmonella_flag=''"                                                                                                                                                               
[53] "    find_salmonella=$(head mash/!{sample}_mashdist.txt | grep \"Salmonella\" | head -n 1 )"                                                                                           
[54] "    if [ -n \"$find_salmonella\" ] ; then salmonella_flag=\"found\" ; else salmonella_flag=\"not\" ; fi"                                                                              
[55] "    ecoli_flag=''"                                                                                                                                                                    
[56] "    find_ecoli=$(head mash/!{sample}_mashdist.txt | grep -e \"Escherichia\" -e \"Shigella\" | head -n 1 )"                                                                            
[57] "    if [ -n \"$find_ecoli\" ] ; then ecoli_flag=\"found\" ; else ecoli_flag=\"not\" ; fi"                                                                                             
[58] "    klebsiella_flag=''"                                                                                                                                                               
[59] "    find_klebsiella=$(head mash/!{sample}_mashdist.txt | grep -e \"Klebsiella\" -e \"Enterobacter\" -e \"Serratia\" | head -n 1 )"                                                    
[60] "    if [ -n \"$find_klebsiella\" ] ; then klebsiella_flag=\"found\" ; else klebsiella_flag=\"not\" ; fi"                                                                              
[61] "  '''"                                                                                                                                                                                
[62] "}"                                                                                                                                                                                    

$mash_dist$line_numbers
 [1] 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264
[20] 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283
[39] 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302

$mash_dist$cpus_parsed
[1] 4


$prokka
$prokka$process_lines
 [1] "  process prokka {"                                                                                                                                                                                      
 [2] "    publishDir \"${params.outdir}\", mode: 'copy'"                                                                                                                                                       
 [3] "    tag \"${sample}\""                                                                                                                                                                                   
 [4] "    container 'staphb/prokka:latest'"                                                                                                                                                                    
 [5] "    pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                                                                         
 [6] "    errorStrategy 'ignore'"                                                                                                                                                                              
 [7] "    time '1day'"                                                                                                                                                                                         
 [8] "    when:"                                                                                                                                                                                               
 [9] "    params.prokka"                                                                                                                                                                                       
[10] "    input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                                                                   
[11] "    input:errorStrategy 'ignore'"                                                                                                                                                                        
[12] "    input:time '1day'"                                                                                                                                                                                   
[13] "    input:"                                                                                                                                                                                              
[14] "    tuple val(sample), file(contigs), val(genus), val(species) from contigs_prokka.concat(fastas_prokka).join(mash_genus_prokka, remainder: true, by:0).join(mash_species_prokka, remainder: true, by:0)"
[15] "    output:"                                                                                                                                                                                             
[16] "    file(\"prokka/${sample}/${sample}.{err,faa,ffn,fna,fsa,gbk,gff,log,sqn,tbl,tsv}\")"                                                                                                                  
[17] "    file(\"prokka/${sample}/${sample}.txt\") into prokka_files"                                                                                                                                          
[18] "    file(\"gff/${sample}.gff\") into gffs"                                                                                                                                                               
[19] "    file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                                                                                            
[20] "    shell:"                                                                                                                                                                                              
[21] "    '''"                                                                                                                                                                                                 
[22] "      mkdir -p prokka gff logs/!{task.process}"                                                                                                                                                          
[23] "      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                                                                                                 
[24] "      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                                                                                                 
[25] "      # time stamp + capturing tool versions"                                                                                                                                                            
[26] "      date | tee -a $log_file $err_file > /dev/null"                                                                                                                                                     
[27] "      echo \"container : !{task.container}\" >> $log_file"                                                                                                                                               
[28] "      prokka -v >> $log_file"                                                                                                                                                                            
[29] "      echo \"Nextflow command : \" >> $log_file"                                                                                                                                                         
[30] "      cat .command.sh >> $log_file"                                                                                                                                                                      
[31] "      prokka !{params.prokka_options} \\"                                                                                                                                                                
[32] "        --cpu !{task.cpus} \\"                                                                                                                                                                           
[33] "        --centre !{params.center} \\"                                                                                                                                                                    
[34] "        --outdir prokka/!{sample} \\"                                                                                                                                                                    
[35] "        --prefix !{sample} \\"                                                                                                                                                                           
[36] "        --genus !{genus} \\"                                                                                                                                                                             
[37] "        --species !{species} \\"                                                                                                                                                                         
[38] "        --force !{contigs} 2>> $err_file | tee -a $log_file"                                                                                                                                             
[39] "      cp prokka/!{sample}/!{sample}.gff gff/!{sample}.gff"                                                                                                                                               
[40] "    '''"                                                                                                                                                                                                 
[41] "  }"                                                                                                                                                                                                     

$prokka$line_numbers
 [1] 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325
[20] 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342

$prokka$cpus_parsed
[1] 16


$quast
$quast$process_lines
 [1] "process quast {"                                                                                   
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                   
 [3] "  tag \"${sample}\""                                                                               
 [4] "  container 'staphb/quast:latest'"                                                                 
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                     
 [6] "  errorStrategy 'ignore'"                                                                          
 [7] "  time '1day'"                                                                                     
 [8] "  when:"                                                                                           
 [9] "  params.quast"                                                                                    
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"               
[11] "  input:errorStrategy 'ignore'"                                                                    
[12] "  input:time '1day'"                                                                               
[13] "  input:"                                                                                          
[14] "  tuple val(sample), file(contigs) from contigs_quast.concat(fastas_quast)"                        
[15] "  output:"                                                                                         
[16] "  path(\"quast/${sample}\")"                                                                       
[17] "  file(\"quast/${sample}_quast_report.tsv\") into quast_files optional true"                       
[18] "  file(\"quast/${sample}/transposed_report.tsv\") into quast_files_combine optional true"          
[19] "  tuple sample, env(gc) into quast_gc_results"                                                     
[20] "  tuple sample, env(num_contigs) into quast_contigs_results"                                       
[21] "  tuple sample, env(n50) into quast_N50_contigs_results"                                           
[22] "  tuple sample, env(length) into quast_length_results"                                             
[23] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                        
[24] "  shell:"                                                                                          
[25] "  '''"                                                                                             
[26] "    mkdir -p !{task.process} logs/!{task.process}"                                                 
[27] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                             
[28] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                             
[29] "    # time stamp + capturing tool versions"                                                        
[30] "    date | tee -a $log_file $err_file > /dev/null"                                                 
[31] "    echo \"container : !{task.container}\" >> $log_file"                                           
[32] "    quast.py --version >> $log_file"                                                               
[33] "    echo \"Nextflow command : \" >> $log_file"                                                     
[34] "    cat .command.sh >> $log_file"                                                                  
[35] "    quast.py !{params.quast_options} \\"                                                           
[36] "      !{contigs} \\"                                                                               
[37] "      --output-dir quast/!{sample} \\"                                                             
[38] "      --threads !{task.cpus} \\"                                                                   
[39] "      2>> $err_file | tee -a $log_file"                                                            
[40] "    gc=$(grep \"GC (\" quast/!{sample}/report.txt | awk '{print $3}' )"                            
[41] "    num_contigs=$(grep \"contigs\" quast/!{sample}/report.txt | grep -v \"(\" | awk '{print $3}' )"
[42] "    n50=$(grep \"N50\" quast/!{sample}/report.txt | awk '{print $2}' )"                            
[43] "    length=$(grep \"Total length\" quast/!{sample}/report.txt | grep -v \"(\" | awk '{print $3}' )"
[44] "    if [ -z \"$gc\" ] ; then gc='NA' ; fi"                                                         
[45] "    if [ -z \"$num_contigs\" ] ; then num_contigs='NA' ; fi"                                       
[46] "    if [ -z \"$n50\" ] ; then n50='NA' ; fi"                                                       
[47] "    if [ -z \"$length\" ] ; then length='NA' ; fi"                                                 
[48] "    cp quast/!{sample}/report.tsv quast/!{sample}_quast_report.tsv"                                
[49] "  '''"                                                                                             
[50] "}"                                                                                                 

$quast$line_numbers
 [1] 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367
[20] 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386
[39] 387 388 389 390 391 392 393

$quast$cpus_parsed
[1] 1


$shuffle
$shuffle$process_lines
 [1] "process shuffle {"                                                                                 
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                   
 [3] "  tag \"${sample}\""                                                                               
 [4] "  container 'staphb/lyveset:latest'"                                                               
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                     
 [6] "  errorStrategy 'ignore'"                                                                          
 [7] "  time '1day'"                                                                                     
 [8] "  when:"                                                                                           
 [9] "  params.cg_pipeline"                                                                              
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"               
[11] "  input:errorStrategy 'ignore'"                                                                    
[12] "  input:time '1day'"                                                                               
[13] "  input:"                                                                                          
[14] "  tuple val(sample), file(reads) from clean_reads_cg"                                              
[15] "  output:"                                                                                         
[16] "  tuple sample, file(\"shuffled/${sample}_shuffled.fastq.gz\") into shuffled_files"                
[17] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                        
[18] "  shell:"                                                                                          
[19] "  '''"                                                                                             
[20] "    mkdir -p shuffled logs/!{task.process}"                                                        
[21] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                             
[22] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                             
[23] "    # time stamp + capturing tool versions"                                                        
[24] "    date | tee -a $log_file $err_file > /dev/null"                                                 
[25] "    echo \"container : !{task.container}\" >> $log_file"                                           
[26] "    echo \"Nextflow command : \" >> $log_file"                                                     
[27] "    cat .command.sh >> $log_file"                                                                  
[28] "    run_assembly_shuffleReads.pl -gz !{reads} 2>> $err_file > shuffled/!{sample}_shuffled.fastq.gz"
[29] "  '''"                                                                                             
[30] "}"                                                                                                 

$shuffle$line_numbers
 [1] 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418
[20] 419 420 421 422 423 424

$shuffle$cpus_parsed
[1] 1


$cg_pipeline
$cg_pipeline$process_lines
 [1] "process cg_pipeline {"                                                                                                                                                                                                                              
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                                                                                                                                                                    
 [3] "  tag \"${sample}\""                                                                                                                                                                                                                                
 [4] "  container 'staphb/lyveset:latest'"                                                                                                                                                                                                                
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                                                                                                                      
 [6] "  errorStrategy 'ignore'"                                                                                                                                                                                                                           
 [7] "  time '1day'"                                                                                                                                                                                                                                      
 [8] "  when:"                                                                                                                                                                                                                                            
 [9] "  params.cg_pipeline"                                                                                                                                                                                                                               
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                                                                                                                
[11] "  input:errorStrategy 'ignore'"                                                                                                                                                                                                                     
[12] "  input:time '1day'"                                                                                                                                                                                                                                
[13] "  input:"                                                                                                                                                                                                                                           
[14] "  tuple val(sample), file(fastq), val(mash), val(genus), val(species), file(genome_file) from for_gc"                                                                                                                                               
[15] "  output:"                                                                                                                                                                                                                                          
[16] "  file(\"cg_pipeline/${sample}_cg_pipeline_report.txt\") optional true into cg_pipeline_files"                                                                                                                                                      
[17] "  tuple sample, env(read_length) into cg_avrl_results"                                                                                                                                                                                              
[18] "  tuple sample, env(quality) into cg_quality_results"                                                                                                                                                                                               
[19] "  tuple sample, env(coverage) into cg_cov_results"                                                                                                                                                                                                  
[20] "  tuple sample, env(reference_genome_length) into ref_genome_length"                                                                                                                                                                                
[21] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                                                                                                                                         
[22] "  shell:"                                                                                                                                                                                                                                           
[23] "  '''"                                                                                                                                                                                                                                              
[24] "    mkdir -p !{task.process} logs/!{task.process}"                                                                                                                                                                                                  
[25] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                                                                                                                                              
[26] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                                                                                                                                              
[27] "    # time stamp + capturing tool versions"                                                                                                                                                                                                         
[28] "    date | tee -a $log_file $err_file > /dev/null"                                                                                                                                                                                                  
[29] "    echo \"container : !{task.container}\" >> $log_file"                                                                                                                                                                                            
[30] "    echo \"Nextflow command : \" >> $log_file"                                                                                                                                                                                                      
[31] "    cat .command.sh >> $log_file"                                                                                                                                                                                                                   
[32] "    genome_length=''"                                                                                                                                                                                                                               
[33] "    if [ \"!{genus}\" != \"null\" ] && [ \"!{species}\" != \"null\" ] ; then genome_length=$(grep !{genus} !{genome_file} | grep !{species} | grep -v \"#\" | head -n 1 | cut -f 2 -d \":\" | cut -f 1 -d \",\" | awk '{ print $0 \"e+06\" }') ; fi"
[34] "    if [ -z \"$genome_length\" ] && [ \"!{mash}\" != \"null\" ] ; then genome_length=$(echo !{mash} | xargs printf \"%.0f\" ) ; fi"                                                                                                                 
[35] "    if [ -n \"$genome_length\" ]"                                                                                                                                                                                                                   
[36] "    then"                                                                                                                                                                                                                                           
[37] "      run_assembly_readMetrics.pl !{fastq} \\"                                                                                                                                                                                                      
[38] "        !{params.cg_pipeline_options} \\"                                                                                                                                                                                                           
[39] "        --fast \\"                                                                                                                                                                                                                                  
[40] "        --numcpus !{task.cpus} \\"                                                                                                                                                                                                                  
[41] "        -e $genome_length \\"                                                                                                                                                                                                                       
[42] "        2>> $err_file > cg_pipeline/!{sample}_cg_pipeline_report.txt"                                                                                                                                                                               
[43] "        read_length=$(cut -f 2 cg_pipeline/!{sample}_cg_pipeline_report.txt | tail -n 1 )"                                                                                                                                                          
[44] "        quality=$(cut -f 6 cg_pipeline/!{sample}_cg_pipeline_report.txt | tail -n 1 )"                                                                                                                                                              
[45] "        coverage=$(cut -f 9 cg_pipeline/!{sample}_cg_pipeline_report.txt | tail -n 1 )"                                                                                                                                                             
[46] "    else"                                                                                                                                                                                                                                           
[47] "      genome_length='0'"                                                                                                                                                                                                                            
[48] "      read_length='NA'"                                                                                                                                                                                                                             
[49] "      quality='NA'"                                                                                                                                                                                                                                 
[50] "      coverage='NA'"                                                                                                                                                                                                                                
[51] "      echo \"Could not determine genome length of isolate, so could not run GC pipeline\" | tee $log_file"                                                                                                                                          
[52] "    fi"                                                                                                                                                                                                                                             
[53] "    if [ -z \"$read_length\" ] ; then read_length='NA' ; fi"                                                                                                                                                                                        
[54] "    if [ -z \"$quality\" ] ; then quality='NA' ; fi"                                                                                                                                                                                                
[55] "    if [ -z \"$coverage\" ] ; then coverage='NA' ; fi"                                                                                                                                                                                              
[56] "    reference_genome_length=$genome_length"                                                                                                                                                                                                         
[57] "  '''"                                                                                                                                                                                                                                              
[58] "}"                                                                                                                                                                                                                                                  

$cg_pipeline$line_numbers
 [1] 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450
[20] 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469
[39] 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484

$cg_pipeline$cpus_parsed
[1] 4


$seqsero2
$seqsero2$process_lines
 [1] "process seqsero2 {"                                                                                                                                         
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                                                                            
 [3] "  tag \"${sample}\""                                                                                                                                        
 [4] "  container 'staphb/seqsero2:latest'"                                                                                                                       
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                              
 [6] "  errorStrategy 'ignore'"                                                                                                                                   
 [7] "  time '1day'"                                                                                                                                              
 [8] "  when:"                                                                                                                                                    
 [9] "  params.seqsero2 && flag =~ 'found'"                                                                                                                       
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                        
[11] "  input:errorStrategy 'ignore'"                                                                                                                             
[12] "  input:time '1day'"                                                                                                                                        
[13] "  input:"                                                                                                                                                   
[14] "  tuple val(sample), file(fastq_or_fasta), val(flag) from clean_reads_seqsero2.concat(fastas_seqsero2).join(salmonella_flag, by:0)"                         
[15] "  output:"                                                                                                                                                  
[16] "  tuple sample, env(antigenic_profile) into seqsero2_profile_results"                                                                                       
[17] "  tuple sample, env(serotype) into seqsero2_serotype_results"                                                                                               
[18] "  tuple sample, env(contamination) into seqsero2_contamination_results"                                                                                     
[19] "  file(\"seqsero2/${sample}/*\")"                                                                                                                           
[20] "  file(\"seqsero2/${sample}/SeqSero_result.tsv\") into seqsero2_files"                                                                                      
[21] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                                                 
[22] "  shell:"                                                                                                                                                   
[23] "  '''"                                                                                                                                                      
[24] "    mkdir -p !{task.process} logs/!{task.process}"                                                                                                          
[25] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                                                      
[26] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                                                      
[27] "    # time stamp + capturing tool versions"                                                                                                                 
[28] "    date | tee -a $log_file $err_file > /dev/null"                                                                                                          
[29] "    echo \"container : !{task.container}\" >> $log_file"                                                                                                    
[30] "    SeqSero2_package.py --version >> $log_file"                                                                                                             
[31] "    echo \"Nextflow command : \" >> $log_file"                                                                                                              
[32] "    cat .command.sh >> $log_file"                                                                                                                           
[33] "    fastq_check=$(echo \"!{fastq_or_fasta}\" | grep \"fastq\" | head -n 1 )"                                                                                
[34] "    if [ -n \"$fastq_check\" ] ; then seqsero_options=\"!{params.seqsero2_options_fastq}\" ; else seqsero_options=\"!{params.seqsero2_options_fasta}\" ; fi"
[35] "    SeqSero2_package.py $seqsero_options \\"                                                                                                                
[36] "      -i !{fastq_or_fasta} \\"                                                                                                                              
[37] "      -p !{task.cpus} \\"                                                                                                                                   
[38] "      -d seqsero2/!{sample} \\"                                                                                                                             
[39] "      -n !{sample} \\"                                                                                                                                      
[40] "      2>> $err_file >> $log_file"                                                                                                                           
[41] "    serotype=$(cut -f 9 seqsero2/!{sample}/SeqSero_result.tsv | tail -n 1)"                                                                                 
[42] "    contamination=$(cut -f 10 seqsero2/!{sample}/SeqSero_result.tsv | tail -n 1)"                                                                           
[43] "    antigenic_profile=$(cut -f 8 seqsero2/!{sample}/SeqSero_result.tsv | tail -n 1)"                                                                        
[44] "    enteritidis_check=$(grep \"Enteritidis\" seqsero2/!{sample}/SeqSero_result.tsv | head -n 1 )"                                                           
[45] "    sdf_check=$(grep \"Detected Sdf\" seqsero2/!{sample}/SeqSero_result.tsv | head -n 1 )"                                                                  
[46] "    if [ -n \"$sdf_check\" ] && [ -n \"$enteritidis_check\" ]"                                                                                              
[47] "    then"                                                                                                                                                   
[48] "      serotype=\"$serotype (Sdf+)\""                                                                                                                        
[49] "    elif [ -z \"$sdf_check\" ] && [ -n \"$enteritidis_check\" ]"                                                                                            
[50] "    then"                                                                                                                                                   
[51] "      serotype=\"$serotype (Sdf-)\""                                                                                                                        
[52] "    fi"                                                                                                                                                     
[53] "    if [ -z \"$serotype\" ] ; then serotype='NA' ; fi"                                                                                                      
[54] "    if [ -z \"$contamination\" ] ; then contamination='NA' ; fi"                                                                                            
[55] "    if [ -z \"$antigenic_profile\" ] ; then antigenic_profile='NA' ; fi"                                                                                    
[56] "  '''"                                                                                                                                                      
[57] "}"                                                                                                                                                          

$seqsero2$line_numbers
 [1] 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511
[20] 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530
[39] 531 532 533 534 535 536 537 538 539 540 541 542 543 544

$seqsero2$cpus_parsed
[1] 4


$shigatyper
$shigatyper$process_lines
 [1] "process shigatyper {"                                                                                                           
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                                                
 [3] "  tag \"${sample}\""                                                                                                            
 [4] "  container 'andrewlangvt/shigatyper:1'"                                                                                        
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                  
 [6] "  errorStrategy 'ignore'"                                                                                                       
 [7] "  time '1day'"                                                                                                                  
 [8] "  when:"                                                                                                                        
 [9] "  params.shigatyper && flag =~ 'found'"                                                                                         
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                            
[11] "  input:errorStrategy 'ignore'"                                                                                                 
[12] "  input:time '1day'"                                                                                                            
[13] "  input:"                                                                                                                       
[14] "  tuple val(sample), file(fastq), val(flag) from clean_reads_shigatyper.join(shigella_flag, by:0)"                              
[15] "  output:"                                                                                                                      
[16] "  file(\"${task.process}/${sample}_shigatyper.tsv\")"                                                                           
[17] "  tuple sample, env(predictions) into shigatyper_predictions"                                                                   
[18] "  tuple sample, env(lacy_cada) into shigatyper_cadA"                                                                            
[19] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                     
[20] "  shell:"                                                                                                                       
[21] "  '''"                                                                                                                          
[22] "    mkdir -p !{task.process} logs/!{task.process}"                                                                              
[23] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                          
[24] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                          
[25] "    # time stamp + capturing tool versions"                                                                                     
[26] "    date | tee -a $log_file $err_file > /dev/null"                                                                              
[27] "    echo \"container : !{task.container}\" >> $log_file"                                                                        
[28] "    shigatyper --version >> $log_file"                                                                                          
[29] "    echo \"Nextflow command : \" >> $log_file"                                                                                  
[30] "    cat .command.sh >> $log_file"                                                                                               
[31] "    shigatyper !{params.shigatyper_options} \\"                                                                                 
[32] "      --name !{sample} \\"                                                                                                      
[33] "      !{fastq} \\"                                                                                                              
[34] "      2>> $err_file \\"                                                                                                         
[35] "      > !{task.process}/!{sample}_shigatyper.tsv"                                                                               
[36] "    predictions=$(grep -v \"prediction\" !{task.process}/!{sample}_shigatyper.tsv | cut -f 2 | tr '\\\\n' ',' | sed 's/,$//g' )"
[37] "    lacy_cada=\"$(grep -ie \"lac\" -ie \"cad\" $err_file | head -n 1)\""                                                        
[38] "    if [ -z \"$predictions\" ] ; then predictions='none' ; fi"                                                                  
[39] "    if [ -z \"$lacy_cada\" ] ; then lacy_cada='none' ; fi"                                                                      
[40] "  '''"                                                                                                                          
[41] "}"                                                                                                                              

$shigatyper$line_numbers
 [1] 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570
[20] 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587

$shigatyper$cpus_parsed
[1] 4


$kleborate
$kleborate$process_lines
 [1] "process kleborate {"                                                                                                                           
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                                                               
 [3] "  tag \"${sample}\""                                                                                                                           
 [4] "  container 'staphb/kleborate:latest'"                                                                                                         
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                 
 [6] "  errorStrategy 'ignore'"                                                                                                                      
 [7] "  time '1day'"                                                                                                                                 
 [8] "  when:"                                                                                                                                       
 [9] "  params.kleborate && flag =~ 'found'"                                                                                                         
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                           
[11] "  input:errorStrategy 'ignore'"                                                                                                                
[12] "  input:time '1day'"                                                                                                                           
[13] "  input:"                                                                                                                                      
[14] "  tuple val(sample), file(contig), val(flag) from contigs_kleborate.concat(fastas_kleborate).join(klebsiella_flag, by:0)"                      
[15] "  output:"                                                                                                                                     
[16] "  tuple sample, env(kleborate_score) into kleborate_score"                                                                                     
[17] "  tuple sample, env(kleborate_mlst) into kleborate_mlst"                                                                                       
[18] "  file(\"${task.process}/${sample}_results.txt\") into kleborate_files"                                                                        
[19] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                                    
[20] "  shell:"                                                                                                                                      
[21] "  '''"                                                                                                                                         
[22] "    mkdir -p !{task.process} logs/!{task.process}"                                                                                             
[23] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                                         
[24] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                                         
[25] "    # time stamp + capturing tool versions"                                                                                                    
[26] "    date | tee -a $log_file $err_file > /dev/null"                                                                                             
[27] "    echo \"container : !{task.container}\" >> $log_file"                                                                                       
[28] "    kleborate --version >> $log_file"                                                                                                          
[29] "    echo \"Nextflow command : \" >> $log_file"                                                                                                 
[30] "    cat .command.sh >> $log_file"                                                                                                              
[31] "    kleborate !{params.kleborate_options} \\"                                                                                                  
[32] "      -o !{task.process}/!{sample}_results.txt \\"                                                                                             
[33] "      -a !{contig} \\"                                                                                                                         
[34] "      2>> $err_file >> $log_file"                                                                                                              
[35] "    virulence_column=$(head -n 1 !{task.process}/!{sample}_results.txt | tr '\\\\t' '\\\\n' | grep -n virulence_score | cut -f 1 -d \":\" )"   
[36] "    mlst_column=$(head -n 1 !{task.process}/!{sample}_results.txt | tr '\\\\t' '\\\\n' | grep -n ST | cut -f 1 -d \":\" )"                     
[37] "    if [ -n \"$virulence_column\" ] ; then kleborate_score=$(cut -f $virulence_column !{task.process}/!{sample}_results.txt | tail -n 1 ) ; fi"
[38] "    if [ -n \"$mlst_column\" ] ; then kleborate_mlst=$(cut -f $mlst_column !{task.process}/!{sample}_results.txt | tail -n 1 ) ; fi"           
[39] "    if [ -z \"$kleborate_score\" ] ; then kleborate_score='NA' ; fi"                                                                           
[40] "    if [ -z \"$kleborate_mlst\" ] ; then kleborate_mlst='NA' ; fi"                                                                             
[41] "  '''"                                                                                                                                         
[42] "}"                                                                                                                                             

$kleborate$line_numbers
 [1] 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608
[20] 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626

$kleborate$cpus_parsed
[1] 4


$serotypefinder
$serotypefinder$process_lines
 [1] "process serotypefinder {"                                                                                                    
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                                             
 [3] "  tag \"${sample}\""                                                                                                         
 [4] "  container 'staphb/serotypefinder:latest'"                                                                                  
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                               
 [6] "  errorStrategy 'ignore'"                                                                                                    
 [7] "  time '1day'"                                                                                                               
 [8] "  when:"                                                                                                                     
 [9] "  params.serotypefinder && flag =~ 'found'"                                                                                  
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                         
[11] "  input:errorStrategy 'ignore'"                                                                                              
[12] "  input:time '1day'"                                                                                                         
[13] "  input:"                                                                                                                    
[14] "  tuple val(sample), file(fasta), val(flag) from contigs_serotypefinder.concat(fastas_serotypefinder).join(ecoli_flag, by:0)"
[15] "  output:"                                                                                                                   
[16] "  file(\"${task.process}/${sample}/*\")"                                                                                     
[17] "  tuple sample, env(o_type) into serotypefinder_results_o"                                                                   
[18] "  tuple sample, env(h_type) into serotypefinder_results_h"                                                                   
[19] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                  
[20] "  shell:"                                                                                                                    
[21] "  '''"                                                                                                                       
[22] "    mkdir -p !{task.process}/!{sample} logs/!{task.process}"                                                                 
[23] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                       
[24] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                       
[25] "    # time stamp + capturing tool versions"                                                                                  
[26] "    date | tee -a $log_file $err_file > /dev/null"                                                                           
[27] "    echo \"container : !{task.container}\" >> $log_file"                                                                     
[28] "    echo \"Nextflow command : \" >> $log_file"                                                                               
[29] "    cat .command.sh >> $log_file"                                                                                            
[30] "    serotypefinder.py !{params.serotypefinder_options} \\"                                                                   
[31] "      -i !{fasta} \\"                                                                                                        
[32] "      -o !{task.process}/!{sample} \\"                                                                                       
[33] "      -x \\"                                                                                                                 
[34] "      2>> $err_file >> $log_file"                                                                                            
[35] "    h_type=$(cut -f 3 !{task.process}/!{sample}/results_tab.tsv | grep ^H | sort | uniq | tr '\\\\n' ',' | sed 's/,$//g' )"  
[36] "    o_type=$(cut -f 3 !{task.process}/!{sample}/results_tab.tsv | grep ^O | sort | uniq | tr '\\\\n' ',' | sed 's/,$//g' )"  
[37] "    if [ -z \"$h_type\" ] ; then h_type=\"none\" ; fi"                                                                       
[38] "    if [ -z \"$o_type\" ] ; then o_type=\"none\" ; fi"                                                                       
[39] "  '''"                                                                                                                       
[40] "}"                                                                                                                           

$serotypefinder$line_numbers
 [1] 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652
[20] 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668

$serotypefinder$cpus_parsed
[1] 4


$amrfinderplus
$amrfinderplus$process_lines
 [1] "process amrfinderplus {"                                                                                                                                                           
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                                                                                                   
 [3] "  tag \"${sample}\""                                                                                                                                                               
 [4] "  container 'staphb/ncbi-amrfinderplus:latest'"                                                                                                                                    
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                                                     
 [6] "  errorStrategy 'ignore'"                                                                                                                                                          
 [7] "  time '1day'"                                                                                                                                                                     
 [8] "  when:"                                                                                                                                                                           
 [9] "  params.amrfinderplus"                                                                                                                                                            
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                                               
[11] "  input:errorStrategy 'ignore'"                                                                                                                                                    
[12] "  input:time '1day'"                                                                                                                                                               
[13] "  input:"                                                                                                                                                                          
[14] "  tuple val(sample), file(contigs), val(genus), val(species) from contigs_amrfinder.concat(fastas_amrfinder).join(mash_genus_amrfinder, by: 0).join(mash_species_amrfinder, by: 0)"
[15] "  output:"                                                                                                                                                                         
[16] "  file(\"ncbi-AMRFinderplus/${sample}_amrfinder_plus.txt\") into amrfinder_files"                                                                                                  
[17] "  tuple sample, env(amr_genes) into amr_genes"                                                                                                                                     
[18] "  tuple sample, env(virulence_genes) into virulence_genes"                                                                                                                         
[19] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                                                                        
[20] "  shell:"                                                                                                                                                                          
[21] "  '''"                                                                                                                                                                             
[22] "    mkdir -p ncbi-AMRFinderplus logs/!{task.process}"                                                                                                                              
[23] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                                                                             
[24] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                                                                             
[25] "    # time stamp + capturing tool versions"                                                                                                                                        
[26] "    date | tee -a $log_file $err_file > /dev/null"                                                                                                                                 
[27] "    echo \"container : !{task.container}\" >> $log_file"                                                                                                                           
[28] "    echo \"Nextflow command : \" >> $log_file"                                                                                                                                     
[29] "    cat .command.sh >> $log_file"                                                                                                                                                  
[30] "    organism_options=(Acinetobacter_baumannii"                                                                                                                                     
[31] "    Campylobacter"                                                                                                                                                                 
[32] "    Enterococcus_faecalis"                                                                                                                                                         
[33] "    Enterococcus_faecium"                                                                                                                                                          
[34] "    Escherichia:Shigella"                                                                                                                                                          
[35] "    Klebsiella"                                                                                                                                                                    
[36] "    Salmonella"                                                                                                                                                                    
[37] "    Staphylococcus_aureus"                                                                                                                                                         
[38] "    Staphylococcus_pseudintermedius"                                                                                                                                               
[39] "    Streptococcus_agalactiae"                                                                                                                                                      
[40] "    Streptococcus_pneumoniae"                                                                                                                                                      
[41] "    Streptococcus_pyogenes"                                                                                                                                                        
[42] "    Vibrio_cholerae)"                                                                                                                                                              
[43] "    organism=$(history -p ${organism_options[@]} | grep -i !{genus} | grep -i !{species} | head -n 1 )"                                                                            
[44] "    if [ -z \"$organism\" ] ; then organism=$(history -p ${organism_options[@]} | grep -i !{genus} | head -n 1 | cut -f 1 -d \":\" ) ; fi"                                         
[45] "    if [ -n \"$organism\" ]"                                                                                                                                                       
[46] "    then"                                                                                                                                                                          
[47] "      organism_check=\"--organism $organism\""                                                                                                                                     
[48] "      echo \"Mash result of !{genus} !{species} matched with $organism\" >> $log_file"                                                                                             
[49] "    else"                                                                                                                                                                          
[50] "      organism_check=''"                                                                                                                                                           
[51] "      echo \"Mash result of !{genus} !{species} did not match any of the organisms\" >> $log_file"                                                                                 
[52] "    fi"                                                                                                                                                                            
[53] "    amrfinder !{params.amrfinderplus_options} \\"                                                                                                                                  
[54] "      --nucleotide !{contigs} \\"                                                                                                                                                  
[55] "      --threads !{task.cpus} \\"                                                                                                                                                   
[56] "      --name !{sample} \\"                                                                                                                                                         
[57] "      --output ncbi-AMRFinderplus/!{sample}_amrfinder_plus.txt \\"                                                                                                                 
[58] "      $organism_check \\"                                                                                                                                                          
[59] "      --plus \\"                                                                                                                                                                   
[60] "      2>> $err_file >> $log_file"                                                                                                                                                  
[61] "    amr_genes=$(cut -f 7 ncbi-AMRFinderplus/!{sample}_amrfinder_plus.txt | tail +2 | sort | uniq | tr '\\\\n' ',' | sed 's/,$//g' )"                                               
[62] "    virulence_genes=$(grep \"VIRULENCE\" ncbi-AMRFinderplus/!{sample}_amrfinder_plus.txt | cut -f 7 | sort | uniq | tr '\\\\n' ',' | sed 's/,$//g' )"                              
[63] "    if [ -z \"$amr_genes\" ] ; then amr_genes=\"none\" ; fi"                                                                                                                       
[64] "    if [ -z \"$virulence_genes\" ] ; then virulence_genes=\"none\" ; fi"                                                                                                           
[65] "  '''"                                                                                                                                                                             
[66] "}"                                                                                                                                                                                 

$amrfinderplus$line_numbers
 [1] 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689
[20] 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708
[39] 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727
[58] 728 729 730 731

$amrfinderplus$cpus_parsed
[1] 4


$kraken2
$kraken2$process_lines
 [1] "  process kraken2 {"                                                                                                                 
 [2] "    publishDir \"${params.outdir}\", mode: 'copy'"                                                                                   
 [3] "    tag \"${sample}\""                                                                                                               
 [4] "    container 'staphb/kraken2:latest'"                                                                                               
 [5] "    input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                               
 [6] "    input:errorStrategy 'ignore'"                                                                                                    
 [7] "    input:time '1day'"                                                                                                               
 [8] "    input:"                                                                                                                          
 [9] "    tuple val(sample), file(clean), path(kraken2_db) from clean_reads_kraken2.concat(fastas_kraken2).combine(local_kraken2)"         
[10] "    output:"                                                                                                                         
[11] "    file(\"${task.process}/${sample}_kraken2_report.txt\") into kraken2_files"                                                       
[12] "    file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                        
[13] "    tuple sample, env(top_hit) into kraken2_top_hit"                                                                                 
[14] "    tuple sample, env(top_perc) into kraken2_top_perc"                                                                               
[15] "    tuple sample, env(top_reads) into kraken2_top_reads"                                                                             
[16] "    shell:"                                                                                                                          
[17] "    '''"                                                                                                                             
[18] "      mkdir -p !{task.process} logs/!{task.process}"                                                                                 
[19] "      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                             
[20] "      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                             
[21] "      date | tee -a $log_file $err_file > /dev/null"                                                                                 
[22] "      echo \"container : !{task.container}\" >> $log_file"                                                                           
[23] "      kraken2 --version >> $log_file"                                                                                                
[24] "      echo \"Nextflow command : \" >> $log_file"                                                                                     
[25] "      cat .command.sh >> $log_file"                                                                                                  
[26] "      fastq_check=$(echo \"!{clean}\" | grep \"fastq\" | head -n 1 )"                                                                
[27] "      if [ -n \"$fastq_check\" ] ; then kraken2_parameter=\"--paired --classified-out cseqs#.fq\" ; else kraken2_parameter=\"\" ; fi"
[28] "      kraken2 !{params.kraken2_options} \\"                                                                                          
[29] "        $kraken2_parameter \\"                                                                                                       
[30] "        --threads !{task.cpus} \\"                                                                                                   
[31] "        --db !{kraken2_db} \\"                                                                                                       
[32] "        !{clean} \\"                                                                                                                 
[33] "        --report !{task.process}/!{sample}_kraken2_report.txt \\"                                                                    
[34] "        2>> $err_file >> $log_file"                                                                                                  
[35] "      top_hit=$(cat !{task.process}/!{sample}_kraken2_report.txt   | grep -w S | sort | tail -n 1 | awk '{print $6 \" \" $7}')"      
[36] "      top_perc=$(cat !{task.process}/!{sample}_kraken2_report.txt  | grep -w S | sort | tail -n 1 | awk '{print $1}')"               
[37] "      top_reads=$(cat !{task.process}/!{sample}_kraken2_report.txt | grep -w S | sort | tail -n 1 | awk '{print $3}')"               
[38] "      if [ -z \"$top_hit\" ] ; then top_hit=\"NA\" ; fi"                                                                             
[39] "      if [ -z \"$top_perc\" ] ; then top_perc=\"0\" ; fi"                                                                            
[40] "      if [ -z \"$top_reads\" ] ; then top_reads=\"0\" ; fi"                                                                          
[41] "    '''"                                                                                                                             
[42] "  }"                                                                                                                                 

$kraken2$line_numbers
 [1] 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757
[20] 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776
[39] 777 778

$kraken2$cpus_parsed
[1] 16


$blastn
$blastn$process_lines
 [1] "  process blastn {"                                                                           
 [2] "    publishDir \"${params.outdir}\", mode: 'copy'"                                            
 [3] "    tag \"${sample}\""                                                                        
 [4] "    container 'ncbi/blast:latest'"                                                            
 [5] "    input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"        
 [6] "    input:errorStrategy 'ignore'"                                                             
 [7] "    input:time '1day'"                                                                        
 [8] "    input:"                                                                                   
 [9] "    tuple val(sample), file(contig), path(blastdb) from contigs_blastn.combine(local_blastdb)"
[10] "    output:"                                                                                  
[11] "    tuple sample, file(\"blastn/${sample}.tsv\") into blastn_files"                           
[12] "    file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                 
[13] "    shell:"                                                                                   
[14] "    '''"                                                                                      
[15] "      mkdir -p !{task.process} logs/!{task.process}"                                          
[16] "      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                      
[17] "      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                      
[18] "      # time stamp + capturing tool versions"                                                 
[19] "      date | tee -a $log_file $err_file > /dev/null"                                          
[20] "      echo \"container : !{task.container}\" >> $log_file"                                    
[21] "      blastn -version >> $log_file"                                                           
[22] "      echo \"Nextflow command : \" >> $log_file"                                              
[23] "      cat .command.sh >> $log_file"                                                           
[24] "      blastn -query !{contig} \\"                                                             
[25] "        -out blastn/!{sample}.tsv \\"                                                         
[26] "        -num_threads !{task.cpus} \\"                                                         
[27] "        -db !{blastdb}/!{params.local_db_type} \\"                                            
[28] "        -outfmt '6 qseqid staxids bitscore std' \\"                                           
[29] "        -max_target_seqs 10 \\"                                                               
[30] "        -max_hsps 1 \\"                                                                       
[31] "        -evalue 1e-25 \\"                                                                     
[32] "        2>> $err_file >> $log_file"                                                           
[33] "    '''"                                                                                      
[34] "  }"                                                                                          

$blastn$line_numbers
 [1] 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805
[20] 806 807 808 809 810 811 812 813 814 815 816 817 818

$blastn$cpus_parsed
[1] 4


$bwa
$bwa$process_lines
 [1] "  process bwa {"                                                                                 
 [2] "    publishDir \"${params.outdir}\", mode: 'copy', pattern: \"logs/${task.process}/*.{log,err}\""
 [3] "    tag \"${sample}\""                                                                           
 [4] "    container 'staphb/bwa:latest'"                                                               
 [5] "    input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"           
 [6] "    input:errorStrategy 'ignore'"                                                                
 [7] "    input:time '1day'"                                                                           
 [8] "    input:"                                                                                      
 [9] "    tuple val(sample), file(reads), file(contig) from clean_reads_bwa.join(contigs_bwa, by:0)"   
[10] "    output:"                                                                                     
[11] "    tuple sample, file(\"${task.process}/${sample}.sam\") into sam_files"                        
[12] "    file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                    
[13] "    shell:"                                                                                      
[14] "    '''"                                                                                         
[15] "      mkdir -p !{task.process} logs/!{task.process}"                                             
[16] "      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                         
[17] "      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                         
[18] "      # time stamp + capturing tool versions"                                                    
[19] "      date | tee -a $log_file $err_file > /dev/null"                                             
[20] "      echo \"container : !{task.container}\" >> $log_file"                                       
[21] "      echo \"bwa $(bwa 2>&1 | grep Version )\" >> $log_file"                                     
[22] "      echo \"Nextflow command : \" >> $log_file"                                                 
[23] "      cat .command.sh >> $log_file"                                                              
[24] "      bwa index !{contig} 2>> $err_file >> $log_file"                                            
[25] "      bwa mem !{params.bwa_options} \\"                                                          
[26] "        -t !{task.cpus} \\"                                                                      
[27] "        !{contig} \\"                                                                            
[28] "        !{reads} \\"                                                                             
[29] "        2>> $err_file \\"                                                                        
[30] "        > !{task.process}/!{sample}.sam"                                                         
[31] "    '''"                                                                                         
[32] "  }"                                                                                             

$bwa$line_numbers
 [1] 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838
[20] 839 840 841 842 843 844 845 846 847 848 849

$bwa$cpus_parsed
[1] 4


$sort
$sort$process_lines
 [1] "  process sort {"                                                                     
 [2] "    publishDir \"${params.outdir}\", mode: 'copy'"                                    
 [3] "    tag \"${sample}\""                                                                
 [4] "    container 'staphb/samtools:latest'"                                               
 [5] "    input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"
 [6] "    input:errorStrategy 'ignore'"                                                     
 [7] "    input:time '1day'"                                                                
 [8] "    input:"                                                                           
 [9] "    tuple val(sample), file(sam) from sam_files"                                      
[10] "    output:"                                                                          
[11] "    tuple sample, file(\"aligned/${sample}.sorted.bam*\") into bam_files"             
[12] "    file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"         
[13] "    shell:"                                                                           
[14] "    '''"                                                                              
[15] "      mkdir -p aligned logs/!{task.process}"                                          
[16] "      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"              
[17] "      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"              
[18] "      # time stamp + capturing tool versions"                                         
[19] "      date | tee -a $log_file $err_file > /dev/null"                                  
[20] "      echo \"container : !{task.container}\" >> $log_file"                            
[21] "      samtools --version >> $log_file"                                                
[22] "      echo \"Nextflow command : \" >> $log_file"                                      
[23] "      cat .command.sh >> $log_file"                                                   
[24] "      samtools sort !{params.samtools_sort_options} \\"                               
[25] "        --threads !{task.cpus} \\"                                                    
[26] "        !{sam} \\"                                                                    
[27] "        -o aligned/!{sample}.sorted.bam \\"                                           
[28] "        --write-index \\"                                                             
[29] "        2>> $err_file >> $log_file"                                                   
[30] "    '''"                                                                              
[31] "  }"                                                                                  

$sort$line_numbers
 [1] 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869
[20] 870 871 872 873 874 875 876 877 878 879

$sort$cpus_parsed
[1] 4


$create
$create$process_lines
 [1] "  process create {"                                                                                                             
 [2] "    publishDir \"${params.outdir}\", mode: 'copy'"                                                                              
 [3] "    tag \"${sample}\""                                                                                                          
 [4] "    container 'chrishah/blobtools:v1.1.1'"                                                                                      
 [5] "    input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                          
 [6] "    input:errorStrategy 'ignore'"                                                                                               
 [7] "    input:time '1day'"                                                                                                          
 [8] "    input:"                                                                                                                     
 [9] "    tuple val(sample), file(contig), file(blastn), file(bam) from contigs_create.join(blastn_files, by:0).join(bam_files, by:0)"
[10] "    output:"                                                                                                                    
[11] "    tuple sample, file(\"blobtools/${sample}.blobDB.json\") into create_files_view, create_files_plot"                          
[12] "    file(\"blobtools/${sample}.${sample}.sorted.bam.cov\")"                                                                     
[13] "    file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                   
[14] "    shell:"                                                                                                                     
[15] "    '''"                                                                                                                        
[16] "      mkdir -p blobtools logs/!{task.process}"                                                                                  
[17] "      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                        
[18] "      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                        
[19] "      # time stamp + capturing tool versions"                                                                                   
[20] "      date | tee -a $log_file $err_file > /dev/null"                                                                            
[21] "      echo \"container : !{task.container}\" >> $log_file"                                                                      
[22] "      echo \"blobtools version $(blobtools -v)\" >> $log_file"                                                                  
[23] "      echo \"Nextflow command : \" >> $log_file"                                                                                
[24] "      cat .command.sh >> $log_file"                                                                                             
[25] "      blobtools create !{params.blobtools_create_options} \\"                                                                   
[26] "        -o blobtools/!{sample} \\"                                                                                              
[27] "        -i !{contig} \\"                                                                                                        
[28] "        -b !{sample}.sorted.bam \\"                                                                                             
[29] "        -t !{blastn} \\"                                                                                                        
[30] "        2>> $err_file >> $log_file"                                                                                             
[31] "    '''"                                                                                                                        
[32] "  }"                                                                                                                            

$create$line_numbers
 [1] 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899
[20] 900 901 902 903 904 905 906 907 908 909 910

$create$cpus_parsed
[1] 1


$view
$view$process_lines
 [1] "  process view {"                                                                     
 [2] "    publishDir \"${params.outdir}\", mode: 'copy'"                                    
 [3] "    tag \"${sample}\""                                                                
 [4] "    container 'chrishah/blobtools:v1.1.1'"                                            
 [5] "    input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"
 [6] "    input:errorStrategy 'ignore'"                                                     
 [7] "    input:time '1day'"                                                                
 [8] "    input:"                                                                           
 [9] "    tuple val(sample), file(json) from create_files_view"                             
[10] "    output:"                                                                          
[11] "    tuple sample, file(\"blobtools/${sample}.blobDB.table.txt\") into view_files"     
[12] "    file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"         
[13] "    shell:"                                                                           
[14] "    '''"                                                                              
[15] "      mkdir -p blobtools logs/!{task.process}"                                        
[16] "      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"              
[17] "      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"              
[18] "      # time stamp + capturing tool versions"                                         
[19] "      date | tee -a $log_file $err_file > /dev/null"                                  
[20] "      echo \"container : !{task.container}\" >> $log_file"                            
[21] "      echo \"blobtools version $(blobtools -v)\" >> $log_file"                        
[22] "      echo \"Nextflow command : \" >> $log_file"                                      
[23] "      cat .command.sh >> $log_file"                                                   
[24] "      blobtools view !{params.blobtools_view_options} \\"                             
[25] "        -i !{json} \\"                                                                
[26] "        -o blobtools/ \\"                                                             
[27] "        2>> $err_file >> $log_file"                                                   
[28] "    '''"                                                                              
[29] "  }"                                                                                  

$view$line_numbers
 [1] 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930
[20] 931 932 933 934 935 936 937 938

$view$cpus_parsed
[1] 1


$blobtools
$blobtools$process_lines
 [1] "  process blobtools {"                                                                                   
 [2] "    publishDir \"${params.outdir}\", mode: 'copy'"                                                       
 [3] "    tag \"${sample}\""                                                                                   
 [4] "    container 'chrishah/blobtools:v1.1.1'"                                                               
 [5] "    input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                   
 [6] "    input:errorStrategy 'ignore'"                                                                        
 [7] "    input:time '1day'"                                                                                   
 [8] "    input:"                                                                                              
 [9] "    tuple val(sample), file(json) from create_files_plot"                                                
[10] "    output:"                                                                                             
[11] "    file(\"blobtools/${sample}.*\")"                                                                     
[12] "    tuple sample, env(blobtools_species) into blobtools_species_results"                                 
[13] "    tuple sample, env(blobtools_perc) into blobtools_perc_results"                                       
[14] "    file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                            
[15] "    shell:"                                                                                              
[16] "    '''"                                                                                                 
[17] "      mkdir -p blobtools logs/!{task.process}"                                                           
[18] "      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                 
[19] "      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                 
[20] "      # time stamp + capturing tool versions"                                                            
[21] "      date | tee -a $log_file $err_file > /dev/null"                                                     
[22] "      echo \"container : !{task.container}\" >> $log_file"                                               
[23] "      echo \"blobtools version $(blobtools -v)\" >> $log_file"                                           
[24] "      echo \"Nextflow command : \" >> $log_file"                                                         
[25] "      cat .command.sh >> $log_file"                                                                      
[26] "      blobtools plot !{params.blobtools_plot_options} \\"                                                
[27] "        -i !{json} \\"                                                                                   
[28] "        -o blobtools/ \\"                                                                                
[29] "        2>> $err_file 2>> $log_file"                                                                     
[30] "      perc='0.0'"                                                                                        
[31] "      blobtools_species='missing'"                                                                       
[32] "      while read line"                                                                                   
[33] "      do"                                                                                                
[34] "        new_perc=$(echo $line | cut -f 13 -d \" \" | sed 's/%//g')"                                      
[35] "        min=$(echo $perc $new_perc | awk '{if ($1 > $2) print $1; else print $2}')"                      
[36] "        if [ \"$min\" != \"$perc\" ]"                                                                    
[37] "        then"                                                                                            
[38] "          perc=$new_perc"                                                                                
[39] "          blobtools_species=$(echo $line | cut -f 1 -d \" \" )"                                          
[40] "          blobtools_perc=$(echo $line | cut -f 13 -d \" \" )"                                            
[41] "        fi"                                                                                              
[42] "      done < <(grep -vw all blobtools/!{sample}*.stats.txt | grep -v \"# name\" | tr ' ' '_' | grep '%')"
[43] "    '''"                                                                                                 
[44] "  }"                                                                                                     

$blobtools$line_numbers
 [1] 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958
[20] 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977
[39] 978 979 980 981

$blobtools$cpus_parsed
[1] 1


$mlst
$mlst$process_lines
 [1] "process mlst {"                                                                     
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                    
 [3] "  tag \"${sample}\""                                                                
 [4] "  container 'staphb/mlst:latest'"                                                   
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"      
 [6] "  errorStrategy 'ignore'"                                                           
 [7] "  time '1day'"                                                                      
 [8] "  when:"                                                                            
 [9] "  params.mlst"                                                                      
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"
[11] "  input:errorStrategy 'ignore'"                                                     
[12] "  input:time '1day'"                                                                
[13] "  input:"                                                                           
[14] "  tuple val(sample), file(contig) from contigs_mlst.concat(fastas_mlst)"            
[15] "  output:"                                                                          
[16] "  file(\"${task.process}/${sample}_mlst.txt\") into mlst_files"                     
[17] "  tuple sample, env(mlst) into mlst_results"                                        
[18] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"         
[19] "  shell:"                                                                           
[20] "  '''"                                                                              
[21] "    mkdir -p !{task.process} logs/!{task.process}"                                  
[22] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"              
[23] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"              
[24] "    # time stamp + capturing tool versions"                                         
[25] "    date | tee -a $log_file $err_file > /dev/null"                                  
[26] "    echo \"container : !{task.container}\" >> $log_file"                            
[27] "    mlst --version >> $log_file"                                                    
[28] "    echo \"Nextflow command : \" >> $log_file"                                      
[29] "    cat .command.sh >> $log_file"                                                   
[30] "    mlst !{contig} 2>> $err_file > mlst/!{sample}_mlst.txt"                         
[31] "    mlst=$(awk '{ print $2 \":\" $3 }' mlst/!{sample}_mlst.txt)"                    
[32] "  '''"                                                                              
[33] "}"                                                                                  

$mlst$line_numbers
 [1]  987  988  989  990  991  992  993  994  995  996  997  998  999 1000 1001
[16] 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014

$mlst$cpus_parsed
[1] 1


$summary
$summary$process_lines
  [1] "process summary {"                                                                                                                                                                               
  [2] "  publishDir \"${params.outdir}\", mode: 'copy', overwrite: true"                                                                                                                                
  [3] "  tag \"${sample}\""                                                                                                                                                                             
  [4] "  container 'staphb/parallel-perl:latest'"                                                                                                                                                       
  [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                                                                   
  [6] "  errorStrategy 'ignore'"                                                                                                                                                                        
  [7] "  time '1day'"                                                                                                                                                                                   
  [8] "  when:"                                                                                                                                                                                         
  [9] "  params.summary"                                                                                                                                                                                
 [10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                                                             
 [11] "  input:errorStrategy 'ignore'"                                                                                                                                                                  
 [12] "  input:time '1day'"                                                                                                                                                                             
 [13] "  input:"                                                                                                                                                                                        
 [14] "  set val(sample), file(file),"                                                                                                                                                                  
 [15] "    val(seqyclean_perc_kept_results),"                                                                                                                                                           
 [16] "    val(seqyclean_pairskept_results),"                                                                                                                                                           
 [17] "    val(fastqc_1_results),"                                                                                                                                                                      
 [18] "    val(fastqc_2_results),"                                                                                                                                                                      
 [19] "    val(mash_genome_size_results),"                                                                                                                                                              
 [20] "    val(mash_coverage_results),"                                                                                                                                                                 
 [21] "    val(mash_genus_results),"                                                                                                                                                                    
 [22] "    val(mash_species_results),"                                                                                                                                                                  
 [23] "    val(mash_full_results),"                                                                                                                                                                     
 [24] "    val(mash_pvalue_results),"                                                                                                                                                                   
 [25] "    val(mash_distance_results),"                                                                                                                                                                 
 [26] "    val(quast_gc_results),"                                                                                                                                                                      
 [27] "    val(quast_contigs_results),"                                                                                                                                                                 
 [28] "    val(quast_N50_contigs_results),"                                                                                                                                                             
 [29] "    val(quast_length_results),"                                                                                                                                                                  
 [30] "    val(cg_avrl_results),"                                                                                                                                                                       
 [31] "    val(cg_quality_results),"                                                                                                                                                                    
 [32] "    val(cg_cov_results),"                                                                                                                                                                        
 [33] "    val(ref_genome_length),"                                                                                                                                                                     
 [34] "    val(seqsero2_profile_results),"                                                                                                                                                              
 [35] "    val(seqsero2_serotype_results),"                                                                                                                                                             
 [36] "    val(seqsero2_contamination_results),"                                                                                                                                                        
 [37] "    val(serotypefinder_results_o),"                                                                                                                                                              
 [38] "    val(serotypefinder_results_h),"                                                                                                                                                              
 [39] "    val(shigatyper_predictions),"                                                                                                                                                                
 [40] "    val(shigatyper_cadA),"                                                                                                                                                                       
 [41] "    val(kleborate_score),"                                                                                                                                                                       
 [42] "    val(kleborate_mlst),"                                                                                                                                                                        
 [43] "    val(blobtools_species_results),"                                                                                                                                                             
 [44] "    val(blobtools_perc_results),"                                                                                                                                                                
 [45] "    val(kraken2_top_hit),"                                                                                                                                                                       
 [46] "    val(kraken2_top_perc),"                                                                                                                                                                      
 [47] "    val(kraken2_top_reads),"                                                                                                                                                                     
 [48] "    val(amr_genes),"                                                                                                                                                                             
 [49] "    val(virulence_genes),"                                                                                                                                                                       
 [50] "    val(mlst_results) from results"                                                                                                                                                              
 [51] "  output:"                                                                                                                                                                                       
 [52] "  file(\"summary/${sample}.summary.txt\") into summary_files_txt"                                                                                                                                
 [53] "  file(\"summary/${sample}.summary.tsv\") into summary_files_tsv"                                                                                                                                
 [54] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                                                                                      
 [55] "  shell:"                                                                                                                                                                                        
 [56] "  '''"                                                                                                                                                                                           
 [57] "    mkdir -p !{task.process} logs/!{task.process}"                                                                                                                                               
 [58] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                                                                                           
 [59] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                                                                                           
 [60] "    date | tee -a $log_file $err_file > /dev/null"                                                                                                                                               
 [61] "    echo \"container : !{task.container}\" >> $log_file"                                                                                                                                         
 [62] "    echo \"Nextflow command : \" >> $log_file"                                                                                                                                                   
 [63] "    cat .command.sh >> $log_file"                                                                                                                                                                
 [64] "    sample_id_split=($(echo !{sample} | sed 's/-/ /g' | sed 's/_/ /g' ))"                                                                                                                        
 [65] "    if [ \"${#sample_id_split[@]}\" -ge \"5\" ]"                                                                                                                                                 
 [66] "    then"                                                                                                                                                                                        
 [67] "      sample_id=\"${sample_id_split[0]}-${sample_id_split[1]}\""                                                                                                                                 
 [68] "    elif [ \"${#sample_id_split[@]}\" -eq \"4\" ]"                                                                                                                                               
 [69] "    then"                                                                                                                                                                                        
 [70] "      sample_id=${sample_id_split[0]}"                                                                                                                                                           
 [71] "    else"                                                                                                                                                                                        
 [72] "      sample_id=!{sample}"                                                                                                                                                                       
 [73] "    fi"                                                                                                                                                                                          
 [74] "    header=\"sample_id;sample\""                                                                                                                                                                 
 [75] "    result=\"$sample_id;!{sample}\""                                                                                                                                                             
 [76] "    header=$header\";seqyclean_pairs_kept;seqyclean_percent_kept\""                                                                                                                              
 [77] "    result=$result\";!{seqyclean_pairskept_results};!{seqyclean_perc_kept_results}\""                                                                                                            
 [78] "    if [ \"!{params.fastqc}\" != \"false\" ]"                                                                                                                                                    
 [79] "    then"                                                                                                                                                                                        
 [80] "      header=$header\";fastqc_1_reads;fastqc_2_reads\""                                                                                                                                          
 [81] "      result=$result\";!{fastqc_1_results};!{fastqc_2_results}\""                                                                                                                                
 [82] "    fi"                                                                                                                                                                                          
 [83] "    if [ \"!{params.mash}\" != \"false\" ]"                                                                                                                                                      
 [84] "    then"                                                                                                                                                                                        
 [85] "      header=$header\";mash_genome_size;mash_coverage;mash_genus;mash_species;mash_full;mash_pvalue;mash_distance\""                                                                             
 [86] "      result=$result\";!{mash_genome_size_results};!{mash_coverage_results};!{mash_genus_results};!{mash_species_results};!{mash_full_results};!{mash_pvalue_results};!{mash_distance_results}\""
 [87] "    fi"                                                                                                                                                                                          
 [88] "    if [ \"!{params.quast}\" != \"false\" ]"                                                                                                                                                     
 [89] "    then"                                                                                                                                                                                        
 [90] "      header=$header\";quast_gc_%;quast_contigs;quast_N50;quast_length\""                                                                                                                        
 [91] "      result=$result\";!{quast_gc_results};!{quast_contigs_results};!{quast_N50_contigs_results};!{quast_length_results}\""                                                                      
 [92] "    fi"                                                                                                                                                                                          
 [93] "    if [ \"!{params.cg_pipeline}\" != \"false\" ]"                                                                                                                                               
 [94] "    then"                                                                                                                                                                                        
 [95] "      header=$header\";cg_average_read_length;cg_average_quality;cg_coverage;ref_genome_length\""                                                                                                
 [96] "      result=$result\";!{cg_avrl_results};!{cg_quality_results};!{cg_cov_results};!{ref_genome_length}\""                                                                                        
 [97] "    fi"                                                                                                                                                                                          
 [98] "    if [ \"!{params.seqsero2}\" != \"false\" ]"                                                                                                                                                  
 [99] "    then"                                                                                                                                                                                        
[100] "      header=$header\";seqsero2_profile;seqsero2_serotype;seqsero2_contamination\""                                                                                                              
[101] "      result=$result\";!{seqsero2_profile_results};!{seqsero2_serotype_results};!{seqsero2_contamination_results}\""                                                                             
[102] "    fi"                                                                                                                                                                                          
[103] "    if [ \"!{params.serotypefinder}\" != \"false\" ]"                                                                                                                                            
[104] "    then"                                                                                                                                                                                        
[105] "      header=$header\";serotypefinder_o_group;serotypefinder_h_group\""                                                                                                                          
[106] "      result=$result\";!{serotypefinder_results_o};!{serotypefinder_results_h}\""                                                                                                                
[107] "    fi"                                                                                                                                                                                          
[108] "    if [ \"!{params.kleborate}\" != \"false\" ]"                                                                                                                                                 
[109] "    then"                                                                                                                                                                                        
[110] "      header=$header\";kleborate_score;kleborate_mlst\""                                                                                                                                         
[111] "      result=$result\";!{kleborate_score};!{kleborate_mlst}\""                                                                                                                                   
[112] "    fi"                                                                                                                                                                                          
[113] "    if [ \"!{params.amrfinderplus}\" != \"false\" ]"                                                                                                                                             
[114] "    then"                                                                                                                                                                                        
[115] "      header=$header\";amr_genes;virulence_genes\""                                                                                                                                              
[116] "      result=$result\";!{amr_genes};!{virulence_genes}\""                                                                                                                                        
[117] "    fi"                                                                                                                                                                                          
[118] "    if [ \"!{params.blobtools}\" != \"false\" ]"                                                                                                                                                 
[119] "    then"                                                                                                                                                                                        
[120] "      header=$header\";blobtools_top_species;blobtools_percentage\""                                                                                                                             
[121] "      result=$result\";!{blobtools_species_results};!{blobtools_perc_results}\""                                                                                                                 
[122] "    fi"                                                                                                                                                                                          
[123] "    if [ \"!{params.kraken2}\" != \"false\" ]"                                                                                                                                                   
[124] "    then"                                                                                                                                                                                        
[125] "      header=$header\";kraken2_top_species;kraken2_num_reads;kraken2_percentage\""                                                                                                               
[126] "      result=$result\";!{kraken2_top_hit};!{kraken2_top_reads};!{kraken2_top_perc}\""                                                                                                            
[127] "    fi"                                                                                                                                                                                          
[128] "    if [ \"!{params.mlst}\" != \"false\" ]"                                                                                                                                                      
[129] "    then"                                                                                                                                                                                        
[130] "      header=$header\";mlst\""                                                                                                                                                                   
[131] "      result=$result\";!{mlst_results}\""                                                                                                                                                        
[132] "    fi"                                                                                                                                                                                          
[133] "    if [ \"!{params.shigatyper}\" != \"false\" ]"                                                                                                                                                
[134] "    then"                                                                                                                                                                                        
[135] "      header=$header\";shigatyper_predictions;shigatyper_cadA\""                                                                                                                                 
[136] "      result=$result\";!{shigatyper_predictions};!{shigatyper_cadA}\""                                                                                                                           
[137] "    fi"                                                                                                                                                                                          
[138] "    echo $header > summary/!{sample}.summary.txt"                                                                                                                                                
[139] "    echo $result >> summary/!{sample}.summary.txt"                                                                                                                                               
[140] "    cat summary/!{sample}.summary.txt | tr ';' '\\t' > summary/!{sample}.summary.tsv"                                                                                                            
[141] "  '''"                                                                                                                                                                                           
[142] "}"                                                                                                                                                                                               

$summary$line_numbers
  [1] 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074
 [16] 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089
 [31] 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104
 [46] 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119
 [61] 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134
 [76] 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149
 [91] 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164
[106] 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179
[121] 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194
[136] 1195 1196

$summary$cpus_parsed
[1] 1


$multiqc
$multiqc$process_lines
 [1] "process multiqc {"                                                                      
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                        
 [3] "  tag \"multiqc\""                                                                      
 [4] "  container 'ewels/multiqc:latest'"                                                     
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"          
 [6] "  errorStrategy 'ignore'"                                                               
 [7] "  time '1day'"                                                                          
 [8] "  when:"                                                                                
 [9] "  params.multiqc"                                                                       
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"    
[11] "  input:errorStrategy 'ignore'"                                                         
[12] "  input:time '1day'"                                                                    
[13] "  input:"                                                                               
[14] "  file(fastqc) from fastqc_files.collect().ifEmpty([])"                                 
[15] "  file(quast) from quast_files.collect().ifEmpty([])"                                   
[16] "  file(seqyclean) from seqyclean_files.collect().ifEmpty([])"                           
[17] "  file(kraken2) from kraken2_files.collect().ifEmpty([])"                               
[18] "  file(prokka) from prokka_files.collect().ifEmpty([])"                                 
[19] "  output:"                                                                              
[20] "  file(\"${task.process}/multiqc_report.html\") optional true"                          
[21] "  file(\"${task.process}/multiqc_data/*\") optional true"                               
[22] "  file(\"logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}\")"       
[23] "  shell:"                                                                               
[24] "  '''"                                                                                  
[25] "    mkdir -p !{task.process} quast fastqc kraken2 prokka seqyclean logs/!{task.process}"
[26] "    log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log"            
[27] "    err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err"            
[28] "    # time stamp + capturing tool versions"                                             
[29] "    date | tee -a $log_file $err_file > /dev/null"                                      
[30] "    echo \"container : !{task.container}\" >> $log_file"                                
[31] "    multiqc --version >> $log_file"                                                     
[32] "    echo \"Nextflow command : \" >> $log_file"                                          
[33] "    cat .command.sh >> $log_file"                                                       
[34] "    for quast_file in !{quast}"                                                         
[35] "    do"                                                                                 
[36] "      if [ -f \"$quast_file\" ]"                                                        
[37] "      then"                                                                             
[38] "        sample=$(echo $quast_file | sed 's/_quast_report.tsv//g' | head -n 1 )"         
[39] "        mkdir -p quast/$sample"                                                         
[40] "        mv $quast_file quast/$sample/report.tsv"                                        
[41] "      fi"                                                                               
[42] "    done"                                                                               
[43] "    multiqc !{params.multiqc_options} \\"                                               
[44] "      --outdir !{task.process} \\"                                                      
[45] "      --cl_config \"prokka_fn_snames: True\"  \\"                                       
[46] "      . \\"                                                                             
[47] "      2>> $err_file >> $log_file"                                                       
[48] "  '''"                                                                                  
[49] "}"                                                                                      

$multiqc$line_numbers
 [1] 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223
[16] 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238
[31] 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252

$multiqc$cpus_parsed
[1] 1


$roary
$roary$process_lines
 [1] "  process roary {"                                                                                     
 [2] "    publishDir \"${params.outdir}\", mode: 'copy'"                                                     
 [3] "    tag \"Core Genome Alignment\""                                                                     
 [4] "    container 'staphb/roary:latest'"                                                                   
 [5] "    input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                 
 [6] "    input:errorStrategy 'ignore'"                                                                      
 [7] "    input:time '1day'"                                                                                 
 [8] "    input:"                                                                                            
 [9] "    file(contigs) from gffs.concat(local_gffs).collect()"                                              
[10] "    output:"                                                                                           
[11] "    file(\"roary/*\")"                                                                                 
[12] "    file(\"roary/fixed_input_files/*\")"                                                               
[13] "    file(\"roary/core_gene_alignment.aln\") into roary_core_genome_iqtree, roary_core_genome_snp_dists"
[14] "    file(\"logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}\")"                    
[15] "    shell:"                                                                                            
[16] "    '''"                                                                                               
[17] "      mkdir -p logs/!{task.process}"                                                                   
[18] "      log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log"                         
[19] "      err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err"                         
[20] "      # time stamp + capturing tool versions"                                                          
[21] "      date | tee -a $log_file $err_file > /dev/null"                                                   
[22] "      roary -a >> $log_file"                                                                           
[23] "      echo \"There are $(ls *gff | wc -l) files for alignment\" >> $log_file"                          
[24] "      roary !{params.roary_options} \\"                                                                
[25] "        -p !{task.cpus} \\"                                                                            
[26] "        -f roary \\"                                                                                   
[27] "        -e -n \\"                                                                                      
[28] "        *.gff \\"                                                                                      
[29] "        2>> $err_file >> $log_file"                                                                    
[30] "    '''"                                                                                               
[31] "  }"                                                                                                   

$roary$line_numbers
 [1] 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270
[16] 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284

$roary$cpus_parsed
[1] 16


$iqtree2
$iqtree2$process_lines
 [1] "  process iqtree2 {"                                                                  
 [2] "    publishDir \"${params.outdir}\", mode: 'copy'"                                    
 [3] "    tag \"Pylogenetic Tree\""                                                         
 [4] "    container 'staphb/iqtree2:latest'"                                                
 [5] "    pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"      
 [6] "    errorStrategy 'ignore'"                                                           
 [7] "    time '1day'"                                                                      
 [8] "    when:"                                                                            
 [9] "    params.iqtree2"                                                                   
[10] "    input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"
[11] "    input:errorStrategy 'ignore'"                                                     
[12] "    input:time '1day'"                                                                
[13] "    input:"                                                                           
[14] "    file(msa) from roary_core_genome_iqtree"                                          
[15] "    output:"                                                                          
[16] "    file(\"${task.process}/iqtree{.ckp.gz,.treefile,.iqtree,.log,.splits.nex}\")"     
[17] "    file(\"${task.process}/iqtree.contree\") into treefile"                           
[18] "    file(\"logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}\")"   
[19] "    shell:"                                                                           
[20] "    '''"                                                                              
[21] "      mkdir -p !{task.process} logs/!{task.process}"                                  
[22] "      log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log"        
[23] "      err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err"        
[24] "      # time stamp + capturing tool versions"                                         
[25] "      date | tee -a $log_file $err_file > /dev/null"                                  
[26] "      iqtree2 -v >> $log_file"                                                        
[27] "      outgroup=''"                                                                    
[28] "      if [ -n \"!{params.outgroup}\" ] ; then outgroup=\"-o !{params.outgroup}\" ; fi"
[29] "      iqtree2 !{params.iqtree2_options} \\"                                           
[30] "        -s !{msa} \\"                                                                 
[31] "        -pre !{task.process}/iqtree \\"                                               
[32] "        -nt AUTO \\"                                                                  
[33] "        -ntmax !{task.cpus} \\"                                                       
[34] "        $outgroup \\"                                                                 
[35] "        2>> $err_file >> $log_file"                                                   
[36] "    '''"                                                                              
[37] "  }"                                                                                  

$iqtree2$line_numbers
 [1] 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302
[16] 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317
[31] 1318 1319

$iqtree2$cpus_parsed
[1] 16


$snp_dists
$snp_dists$process_lines
 [1] "  process snp_dists {"                                                                
 [2] "    publishDir \"${params.outdir}\", mode: 'copy'"                                    
 [3] "    tag \"SNP matrix\""                                                               
 [4] "    container 'staphb/snp-dists:latest'"                                              
 [5] "    pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"      
 [6] "    errorStrategy 'ignore'"                                                           
 [7] "    time '1day'"                                                                      
 [8] "    when:"                                                                            
 [9] "    params.snp_dists"                                                                 
[10] "    input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"
[11] "    input:errorStrategy 'ignore'"                                                     
[12] "    input:time '1day'"                                                                
[13] "    input:"                                                                           
[14] "    file(contigs) from roary_core_genome_snp_dists"                                   
[15] "    output:"                                                                          
[16] "    file(\"${task.process}/snp_matrix.txt\")"                                         
[17] "    file(\"logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}\")"   
[18] "    shell:"                                                                           
[19] "    '''"                                                                              
[20] "      mkdir -p !{task.process} logs/!{task.process}"                                  
[21] "      log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log"        
[22] "      err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err"        
[23] "      # time stamp + capturing tool versions"                                         
[24] "      date | tee -a $log_file $err_file > /dev/null"                                  
[25] "      snp-dists -v >> $log_file"                                                      
[26] "      snp-dists !{params.snp_dists_options} \\"                                       
[27] "        !{contigs} \\"                                                                
[28] "        2>> $err_file \\"                                                             
[29] "        > !{task.process}/snp_matrix.txt"                                             
[30] "    '''"                                                                              
[31] "  }"                                                                                  

$snp_dists$line_numbers
 [1] 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336
[16] 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347

$snp_dists$cpus_parsed
[1] 1


2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   process snp_dists {
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     tag "SNP matrix"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     container 'staphb/snp-dists:latest'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     time '1day'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     when:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     params.snp_dists
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:time '1day'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     file(contigs) from roary_core_genome_snp_dists
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     output:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     file("${task.process}/snp_matrix.txt")
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     shell:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     '''
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       snp-dists -v >> $log_file
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       snp-dists !{params.snp_dists_options} \
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         !{contigs} \
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         2>> $err_file \
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         > !{task.process}/snp_matrix.txt
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     '''
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   }
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   process iqtree2 {
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     tag "Pylogenetic Tree"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     container 'staphb/iqtree2:latest'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     time '1day'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     when:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     params.iqtree2
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:time '1day'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     file(msa) from roary_core_genome_iqtree
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     output:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     file("${task.process}/iqtree{.ckp.gz,.treefile,.iqtree,.log,.splits.nex}")
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     file("${task.process}/iqtree.contree") into treefile
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     shell:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     '''
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       iqtree2 -v >> $log_file
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       outgroup=''
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       if [ -n "!{params.outgroup}" ] ; then outgroup="-o !{params.outgroup}" ; fi
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       iqtree2 !{params.iqtree2_options} \
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         -s !{msa} \
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         -pre !{task.process}/iqtree \
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         -nt AUTO \
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         -ntmax !{task.cpus} \
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         $outgroup \
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         2>> $err_file >> $log_file
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     '''
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   }
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   process roary {
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     tag "Core Genome Alignment"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     container 'staphb/roary:latest'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:time '1day'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     file(contigs) from gffs.concat(local_gffs).collect()
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     output:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     file("roary/*")
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     file("roary/fixed_input_files/*")
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     file("roary/core_gene_alignment.aln") into roary_core_genome_iqtree, roary_core_genome_snp_dists
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     shell:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     '''
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       mkdir -p logs/!{task.process}
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       roary -a >> $log_file
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       echo "There are $(ls *gff | wc -l) files for alignment" >> $log_file
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       roary !{params.roary_options} \
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         -p !{task.cpus} \
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         -f roary \
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         -e -n \
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         *.gff \
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         2>> $err_file >> $log_file
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     '''
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   }
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL process multiqc {
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   tag "multiqc"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   container 'ewels/multiqc:latest'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   time '1day'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   when:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   params.multiqc
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:time '1day'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file(fastqc) from fastqc_files.collect().ifEmpty([])
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file(quast) from quast_files.collect().ifEmpty([])
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file(seqyclean) from seqyclean_files.collect().ifEmpty([])
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file(kraken2) from kraken2_files.collect().ifEmpty([])
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file(prokka) from prokka_files.collect().ifEmpty([])
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   output:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file("${task.process}/multiqc_report.html") optional true
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file("${task.process}/multiqc_data/*") optional true
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   shell:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   '''
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     mkdir -p !{task.process} quast fastqc kraken2 prokka seqyclean logs/!{task.process}
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     multiqc --version >> $log_file
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     for quast_file in !{quast}
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     do
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       if [ -f "$quast_file" ]
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       then
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         sample=$(echo $quast_file | sed 's/_quast_report.tsv//g' | head -n 1 )
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         mkdir -p quast/$sample
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         mv $quast_file quast/$sample/report.tsv
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       fi
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     done
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     multiqc !{params.multiqc_options} \
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       --outdir !{task.process} \
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       --cl_config "prokka_fn_snames: True"  \
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       . \
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       2>> $err_file >> $log_file
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   '''
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL }
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL process summary {
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   publishDir "${params.outdir}", mode: 'copy', overwrite: true
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   tag "${sample}"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   container 'staphb/parallel-perl:latest'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   time '1day'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   when:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   params.summary
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:time '1day'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   set val(sample), file(file),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(seqyclean_perc_kept_results),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(seqyclean_pairskept_results),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(fastqc_1_results),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(fastqc_2_results),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(mash_genome_size_results),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(mash_coverage_results),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(mash_genus_results),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(mash_species_results),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(mash_full_results),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(mash_pvalue_results),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(mash_distance_results),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(quast_gc_results),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(quast_contigs_results),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(quast_N50_contigs_results),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(quast_length_results),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(cg_avrl_results),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(cg_quality_results),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(cg_cov_results),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(ref_genome_length),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(seqsero2_profile_results),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(seqsero2_serotype_results),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(seqsero2_contamination_results),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(serotypefinder_results_o),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(serotypefinder_results_h),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(shigatyper_predictions),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(shigatyper_cadA),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(kleborate_score),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(kleborate_mlst),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(blobtools_species_results),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(blobtools_perc_results),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(kraken2_top_hit),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(kraken2_top_perc),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(kraken2_top_reads),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(amr_genes),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(virulence_genes),
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(mlst_results) from results
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   output:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file("summary/${sample}.summary.txt") into summary_files_txt
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file("summary/${sample}.summary.tsv") into summary_files_tsv
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   shell:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   '''
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     sample_id_split=($(echo !{sample} | sed 's/-/ /g' | sed 's/_/ /g' ))
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ "${#sample_id_split[@]}" -ge "5" ]
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       sample_id="${sample_id_split[0]}-${sample_id_split[1]}"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     elif [ "${#sample_id_split[@]}" -eq "4" ]
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       sample_id=${sample_id_split[0]}
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     else
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       sample_id=!{sample}
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     header="sample_id;sample"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     result="$sample_id;!{sample}"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     header=$header";seqyclean_pairs_kept;seqyclean_percent_kept"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     result=$result";!{seqyclean_pairskept_results};!{seqyclean_perc_kept_results}"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ "!{params.fastqc}" != "false" ]
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       header=$header";fastqc_1_reads;fastqc_2_reads"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       result=$result";!{fastqc_1_results};!{fastqc_2_results}"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ "!{params.mash}" != "false" ]
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       header=$header";mash_genome_size;mash_coverage;mash_genus;mash_species;mash_full;mash_pvalue;mash_distance"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       result=$result";!{mash_genome_size_results};!{mash_coverage_results};!{mash_genus_results};!{mash_species_results};!{mash_full_results};!{mash_pvalue_results};!{mash_distance_results}"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ "!{params.quast}" != "false" ]
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       header=$header";quast_gc_%;quast_contigs;quast_N50;quast_length"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       result=$result";!{quast_gc_results};!{quast_contigs_results};!{quast_N50_contigs_results};!{quast_length_results}"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ "!{params.cg_pipeline}" != "false" ]
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       header=$header";cg_average_read_length;cg_average_quality;cg_coverage;ref_genome_length"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       result=$result";!{cg_avrl_results};!{cg_quality_results};!{cg_cov_results};!{ref_genome_length}"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ "!{params.seqsero2}" != "false" ]
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       header=$header";seqsero2_profile;seqsero2_serotype;seqsero2_contamination"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       result=$result";!{seqsero2_profile_results};!{seqsero2_serotype_results};!{seqsero2_contamination_results}"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ "!{params.serotypefinder}" != "false" ]
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       header=$header";serotypefinder_o_group;serotypefinder_h_group"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       result=$result";!{serotypefinder_results_o};!{serotypefinder_results_h}"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ "!{params.kleborate}" != "false" ]
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       header=$header";kleborate_score;kleborate_mlst"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       result=$result";!{kleborate_score};!{kleborate_mlst}"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ "!{params.amrfinderplus}" != "false" ]
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       header=$header";amr_genes;virulence_genes"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       result=$result";!{amr_genes};!{virulence_genes}"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ "!{params.blobtools}" != "false" ]
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       header=$header";blobtools_top_species;blobtools_percentage"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       result=$result";!{blobtools_species_results};!{blobtools_perc_results}"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ "!{params.kraken2}" != "false" ]
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       header=$header";kraken2_top_species;kraken2_num_reads;kraken2_percentage"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       result=$result";!{kraken2_top_hit};!{kraken2_top_reads};!{kraken2_top_perc}"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ "!{params.mlst}" != "false" ]
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       header=$header";mlst"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       result=$result";!{mlst_results}"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ "!{params.shigatyper}" != "false" ]
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       header=$header";shigatyper_predictions;shigatyper_cadA"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       result=$result";!{shigatyper_predictions};!{shigatyper_cadA}"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     echo $header > summary/!{sample}.summary.txt
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     echo $result >> summary/!{sample}.summary.txt
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     cat summary/!{sample}.summary.txt | tr ';' '\t' > summary/!{sample}.summary.tsv
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   '''
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL }
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL process mlst {
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   tag "${sample}"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   container 'staphb/mlst:latest'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   time '1day'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   when:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   params.mlst
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:time '1day'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   tuple val(sample), file(contig) from contigs_mlst.concat(fastas_mlst)
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   output:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file("${task.process}/${sample}_mlst.txt") into mlst_files
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   tuple sample, env(mlst) into mlst_results
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   shell:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   '''
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     mlst --version >> $log_file
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     mlst !{contig} 2>> $err_file > mlst/!{sample}_mlst.txt
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     mlst=$(awk '{ print $2 ":" $3 }' mlst/!{sample}_mlst.txt)
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   '''
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL }
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   process blobtools {
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     tag "${sample}"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     container 'chrishah/blobtools:v1.1.1'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:time '1day'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     tuple val(sample), file(json) from create_files_plot
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     output:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     file("blobtools/${sample}.*")
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     tuple sample, env(blobtools_species) into blobtools_species_results
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     tuple sample, env(blobtools_perc) into blobtools_perc_results
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     shell:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     '''
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       mkdir -p blobtools logs/!{task.process}
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       # time stamp + capturing tool versions
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       echo "container : !{task.container}" >> $log_file
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       echo "blobtools version $(blobtools -v)" >> $log_file
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       echo "Nextflow command : " >> $log_file
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       cat .command.sh >> $log_file
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       blobtools plot !{params.blobtools_plot_options} \
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         -i !{json} \
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         -o blobtools/ \
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         2>> $err_file 2>> $log_file
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       perc='0.0'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       blobtools_species='missing'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       while read line
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       do
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         new_perc=$(echo $line | cut -f 13 -d " " | sed 's/%//g')
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         min=$(echo $perc $new_perc | awk '{if ($1 > $2) print $1; else print $2}')
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         if [ "$min" != "$perc" ]
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         then
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL           perc=$new_perc
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL           blobtools_species=$(echo $line | cut -f 1 -d " " )
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL           blobtools_perc=$(echo $line | cut -f 13 -d " " )
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         fi
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       done < <(grep -vw all blobtools/!{sample}*.stats.txt | grep -v "# name" | tr ' ' '_' | grep '%')
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     '''
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   }
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   process view {
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     tag "${sample}"
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     container 'chrishah/blobtools:v1.1.1'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:errorStrategy 'ignore'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:time '1day'
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     tuple val(sample), file(json) from create_files_view
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     output:
2022-03-14 09:23:03 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     tuple sample, file("blobtools/${sample}.blobDB.table.txt") into view_files
2022-03-14 09:23:03 [INFO] FOUND_DUMMY_CHANNEL_EXPRESSION:     tuple sample, file("blobtools/${sample}.blobDB.table.txt") into view_files
2022-03-14 09:23:03 [INFO] ADDING DUMMY PROCESS
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 0 UPPER_LINE_BOUND 92
2022-03-14 09:23:03 [INFO] ADDED 137 lines from process: seqyclean
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 132 UPPER_LINE_BOUND 140
2022-03-14 09:23:03 [INFO] ADDED 45 lines from process: spades
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 172 UPPER_LINE_BOUND 175
2022-03-14 09:23:03 [INFO] ADDED 45 lines from process: fastqc
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 212 UPPER_LINE_BOUND 214
2022-03-14 09:23:03 [INFO] ADDED 36 lines from process: mash_sketch
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 243 UPPER_LINE_BOUND 246
2022-03-14 09:23:03 [INFO] ADDED 64 lines from process: mash_dist
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 302 UPPER_LINE_BOUND 307
2022-03-14 09:23:03 [INFO] ADDED 45 lines from process: prokka
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 342 UPPER_LINE_BOUND 349
2022-03-14 09:23:03 [INFO] ADDED 56 lines from process: quast
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 393 UPPER_LINE_BOUND 400
2022-03-14 09:23:03 [INFO] ADDED 36 lines from process: shuffle
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 424 UPPER_LINE_BOUND 432
2022-03-14 09:23:03 [INFO] ADDED 65 lines from process: cg_pipeline
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 484 UPPER_LINE_BOUND 493
2022-03-14 09:23:03 [INFO] ADDED 65 lines from process: seqsero2
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 544 UPPER_LINE_BOUND 552
2022-03-14 09:23:03 [INFO] ADDED 48 lines from process: shigatyper
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 587 UPPER_LINE_BOUND 590
2022-03-14 09:23:03 [INFO] ADDED 44 lines from process: kleborate
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 626 UPPER_LINE_BOUND 634
2022-03-14 09:23:03 [INFO] ADDED 47 lines from process: serotypefinder
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 668 UPPER_LINE_BOUND 671
2022-03-14 09:23:03 [INFO] ADDED 68 lines from process: amrfinderplus
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 731 UPPER_LINE_BOUND 739
2022-03-14 09:23:03 [INFO] ADDED 49 lines from process: kraken2
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 778 UPPER_LINE_BOUND 787
2022-03-14 09:23:03 [INFO] ADDED 42 lines from process: blastn
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 818 UPPER_LINE_BOUND 820
2022-03-14 09:23:03 [INFO] ADDED 33 lines from process: bwa
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 849 UPPER_LINE_BOUND 851
2022-03-14 09:23:03 [INFO] ADDED 32 lines from process: sort
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 879 UPPER_LINE_BOUND 881
2022-03-14 09:23:03 [INFO] ADDED 33 lines from process: create
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 910 UPPER_LINE_BOUND 912
2022-03-14 09:23:03 [INFO] ADDED 30 lines from process: view
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 938 UPPER_LINE_BOUND 940
2022-03-14 09:23:03 [INFO] ADDED 45 lines from process: blobtools
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 981 UPPER_LINE_BOUND 987
2022-03-14 09:23:03 [INFO] ADDED 38 lines from process: mlst
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 1014 UPPER_LINE_BOUND 1060
2022-03-14 09:23:03 [INFO] ADDED 187 lines from process: summary
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 1196 UPPER_LINE_BOUND 1209
2022-03-14 09:23:03 [INFO] ADDED 61 lines from process: multiqc
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 1252 UPPER_LINE_BOUND 1256
2022-03-14 09:23:03 [INFO] ADDED 34 lines from process: roary
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 1284 UPPER_LINE_BOUND 1288
2022-03-14 09:23:03 [INFO] ADDED 40 lines from process: iqtree2
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 1319 UPPER_LINE_BOUND 1322
2022-03-14 09:23:03 [INFO] ADDED 33 lines from process: snp_dists
2022-03-14 09:23:03 [INFO] LOWER_LINE_BOUND 1347 UPPER_LINE_BOUND 1348
2022-03-14 09:23:03 [INFO] ADDED 17 lines from process: copy_workfiles
2022-03-14 09:23:03 [INFO] Writing updated processes to /Users/keng/codes/Grandeur/grandeur.ica.dev.nf
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:   mainScript = 'Cecret.nf'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:   name = 'Cecret'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:   author = 'Erin Young'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:   homePage = 'https://github.com/UPHL-BioNGS/Cecret'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:   version = 'v.2.3.20220113'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //########## Setting the Profile ##########
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     docker.enabled = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     docker.runOptions = "-u \$(id -u):\$(id -g)"
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     singularity.enabled = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     singularity.autoMounts = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     params.primer_set = 'ncov_V3'
2022-03-14 09:23:04 [INFO] ADDING_LINE_STRIPPING_PARAMS:     primer_set = 'ncov_V3'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     params.primer_set = 'ncov_V4'
2022-03-14 09:23:04 [INFO] ADDING_LINE_STRIPPING_PARAMS:     primer_set = 'ncov_V4'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     params.primer_set = 'ncov_V4.1'
2022-03-14 09:23:04 [INFO] ADDING_LINE_STRIPPING_PARAMS:     primer_set = 'ncov_V4.1'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     singularity.enabled = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     singularity.autoMounts = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     singularity.cacheDir = 'singularity'
2022-03-14 09:23:04 [INFO] ENTERING_PARAMS_ENCLOSURE:     params {
2022-03-14 09:23:04 [INFO] OTHER_LINE:     params {
2022-03-14 09:23:04 [INFO] LINE_OF_INTEREST:     params { PARAMS_ENCLOSURE: TRUE
2022-03-14 09:23:04 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:       reads = "Sequencing_reads/Raw"
2022-03-14 09:23:04 [INFO] ADDING_LINE:       reads = "Sequencing_reads/Raw"
2022-03-14 09:23:04 [INFO] LINE_OF_INTEREST:       reads = "Sequencing_reads/Raw" PARAMS_ENCLOSURE: TRUE
2022-03-14 09:23:04 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:       kraken2 = true
2022-03-14 09:23:04 [INFO] ADDING_LINE:       kraken2 = true
2022-03-14 09:23:04 [INFO] LINE_OF_INTEREST:       kraken2 = true PARAMS_ENCLOSURE: TRUE
2022-03-14 09:23:04 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:       kraken2_db = '/Volumes/IDGenomics_NAS/Data/kraken2_db/h+v'
2022-03-14 09:23:04 [INFO] ADDING_LINE:       kraken2_db = '/Volumes/IDGenomics_NAS/Data/kraken2_db/h+v'
2022-03-14 09:23:04 [INFO] LINE_OF_INTEREST:       kraken2_db = '/Volumes/IDGenomics_NAS/Data/kraken2_db/h+v' PARAMS_ENCLOSURE: TRUE
2022-03-14 09:23:04 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:       vadr = false
2022-03-14 09:23:04 [INFO] ADDING_LINE:       vadr = false
2022-03-14 09:23:04 [INFO] LINE_OF_INTEREST:       vadr = false PARAMS_ENCLOSURE: TRUE
2022-03-14 09:23:04 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:23:04 [INFO] OTHER_LINE:     }
2022-03-14 09:23:04 [INFO] IGNORE_PARAM_LINE:     }
2022-03-14 09:23:04 [INFO] LINE_OF_INTEREST:     } PARAMS_ENCLOSURE: TRUE
2022-03-14 09:23:04 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:23:04 [INFO] EXITED_PARAMS_ENCLOSURE:   }
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: }
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: includeConfig './configs/cecret_config_template.config'
2022-03-14 09:23:04 [INFO] DONE_PARSING


2022-03-14 09:23:04 [INFO] Reading in /Users/keng/codes/Cecret/./configs/cecret_config_template.config
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# Docker Params -------------------------------------------
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //docker.enabled = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //docker.runOptions = '-u \$(id -u):\$(id -g)'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //docker.sudo = false
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //docker.temp = /tmp
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //docker.remove = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //docker.registry = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //docker.fixOwnership = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //docker.engineOptions = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //docker.mountFlags = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# Singularity Params --------------------------------------
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //singularity.enabled = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //singularity.autoMounts = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //singularity.runOptions = 
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //process.stageInMode = link
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //singularity.engineOptions = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //singularity.cacheDir = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# AWS Batch Params ----------------------------------------
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //process.executor = 'awsbatch'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //process.queue = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //aws.batch.cliPath = '/home/ec2-user/miniconda/bin/aws'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //aws.region = 'us-east-1'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //workDir = 's3://'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# Google Cloud Params -------------------------------------
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //process.executor = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //google.project = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //google.location = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //google.region = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //workDir = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //google.lifeSciences.bootDiskSize = 50.GB
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# Nextflow Tower ------------------------------------------
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //tower.accessToken = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //tower.enabled = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# Adjustable Workflow parameters ---------------------------
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.reads = 'reads'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.single_reads = 'single_reads'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.fastas = 'fastas'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.outdir = 'cecret'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# Basic CPU usage grouping
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: params.maxcpus = 8
2022-03-14 09:23:04 [INFO] ADDING_LINE_STRIPPING_PARAMS: maxcpus = 8
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: params.medcpus = 4
2022-03-14 09:23:04 [INFO] ADDING_LINE_STRIPPING_PARAMS: medcpus = 4
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# Reference files for SARS-CoV-2 (part of the github repository)
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.reference_genome = Cecret/configs/MN908947.3.fasta
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.gff_file = Cecret/configs/MN908947.3.gff
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.primer_set = 'ncov_V3'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.primer_set = 'ncov_V4'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.primer_set = 'ncov_V4.1'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.primer_bed = Cecret/configs/artic_V4_SARS-CoV-2.scheme.bed
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.amplicon_bed = Cecret/configs/artic_V4_SARS-CoV-2.insert.bed
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# Tool toggles
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.trimmer = 'ivar'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.trimmer = 'samtools'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.trimmer = 'none'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.cleaner = 'seqyclean'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.cleaner = 'fastp'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.aligner = 'bwa'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.aligner = 'minimap2'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.msa = 'mafft'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.msa = 'nextclade'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.msa = 'nextalign'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# Docker Images -------------------------------------------
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: fastqc_container = 'staphb/fastqc:latest'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: seqyclean_container = 'staphb/seqyclean:latest'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: fastp_container = 'bromberglab/fastp:latest'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: bwa_container = 'staphb/bwa:latest'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: minimap2_container = 'staphb/minimap2:latest'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: samtools_container = 'staphb/samtools:latest'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: ivar_container = 'staphb/ivar:latest'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: bcftools_container = 'staphb/bcftools:latest'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: bamsnap_container = 'danielmsk/bamsnap:latest'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: kraken2_container = 'staphb/kraken2:latest'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: bedtools_container = 'staphb/bedtools:latest'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: pangolin_container = 'staphb/pangolin:latest'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: nextclade_container = 'nextstrain/nextclade:latest'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: vadr_container = 'staphb/vadr:latest'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: parallel_perl_container = 'staphb/parallel-perl:latest'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: mafft_container = 'staphb/mafft:latest'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: nextalign_container = 'nextstrain/nextalign:latest'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: snp_dists_container = 'staphb/snp-dists:latest'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: iqtree2_container = 'staphb/iqtree2:latest'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: pandas_container = 'quay.io/biocontainers/pandas:1.1.5'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# Workflow parameters --------------------------------------
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process seqyclean
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.cleaner = 'seqyclean'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# The seqyclean contaminant file MUST be in the container. It is not put through a channel.
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.seqyclean_contaminant_file = /Adapters_plus_PhiX_174.fasta
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.seqyclean_options = '-minlen 25 -qual'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process fastp
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.cleaner = 'fastp'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.fastp_options = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process bwa
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.aligner = 'bwa'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process minimap2
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.aligner = 'minimap2'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.minimap2_options = '-K 20M'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process fastqc
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.fastqc = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.fastqc_options = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process sort
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# No editable parameters
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process filter
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.filter_options = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.filter = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process ivar_trim
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.trimmer == 'ivar'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.ivar_trim_options = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process samtools_ampliconclip
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.trimmer == 'samtools'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.samtools_ampliconclip_options = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# trimming can also be skipped with
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.trimmer == 'none'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process ivar_variants
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.ivar_variants = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# params.minimum_depth is shared with ivar_consensus, summary, and samtools_depth
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.minimum_depth = 100
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# params.mpileup_depth is shared with ivar_consensus and bcftools_variants
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.mpileup_depth = 8000
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.ivar_variants_options = '-q 20 -t 0.6 '
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process ivar_consensus
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# params.minimum_depth is shared with ivar_variants, summary, and samtools_depth
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.minimum_depth = 100
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# params.mpileup_depth is shared with ivar_variants and bcftools_variants
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.mpileup_depth = 8000
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.ivar_consensus_options = '-q 20 -t 0.6 -n N'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process fasta_prep
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# No editable parameters
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process bcftools_variants
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.bcftools_variants = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# params.mpileup_depth is shared with ivar_variants and ivar_consensus
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.mpileup_depth = 8000
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process bamsnap
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.bamsnap = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.bamsnap_options = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process samtools_stats
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.samtools_stats_options = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.samtools_stats = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process samtools_coverage
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.samtools_coverage_options = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.samtools_coverage = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process samtools_flagstat
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.samtools_flagstat_options = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.samtools_flagstat = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process samtools_depth
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# params.minimum_depth is shared with ivar_variants, ivar_consensus, and summary
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.minimum_depth = 100
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.samtools_depth_options = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.samtools_depth = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process kraken2
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.kraken2_options = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.kraken2 = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.kraken2_db = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.kraken2_organism = Severe acute respiratory syndrome-related coronavirus
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process bedtools_multicov
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.bedtools_multicov = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.bedtools_options = '-f .1'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process samtools_ampliconstats
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.samtools_ampliconstats_options = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.samtools_ampliconstats = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process samtools_plot_ampliconstats
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.samtools_plot_ampliconstats_options = '-size 1200,900 -size2 1200,900 -size3 1200,900'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.samtools_plot_ampliconstats = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process pangolin
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.pangolin_options = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.pangolin = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process nextclade
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.nextclade_dataset = 'sars-cov-2'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.nextclade_options = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.nextclade = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process vadr
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.vadr_options = '--split --glsearch -s -r --nomisc --lowsim5seq 6 --lowsim3seq 6 --alt_fail lowscore,insertnn,deletinn'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.vadr_reference = 'sarscov2'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# If using a different organism, the models must be in the container. Even if the path is changed.
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.vadr_mdir = '/opt/vadr/vadr-models'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.vadr = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.vadr_trim_options = '--minlen 50 --maxlen 30000'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process summary
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# params.minimum_depth is shared with ivar_variants, ivar_consensus, and samtools_depth
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.minimum_depth = 100
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process mafft
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.msa == 'mafft'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.mafft_options = '--maxambiguous 0.5'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.relatedness = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process nextalign
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.msa == 'nextalign'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.nextalign_options = '--genes E,M,N,ORF1a,ORF1b,ORF3a,ORF6,ORF7a,ORF7b,ORF8,ORF9b,S --include-reference'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.relatedness = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process snpdists
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.snpdists_options = ''
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.snpdists = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process iqtree
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.iqtree2_outgroup = '-o MN908947'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.iqtree2_options = '-ninit 2 -n 2 -me 0.05 -m GTR'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.iqtree2 = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //# For process rename
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.rename = true
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.sample_file = 'covid_samples.csv'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.gisaid_threshold = '25000'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: //params.genbank_threshold = '15000'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:   errorStrategy = 'retry'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:   maxRetries = 1
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:   cpus = 1
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:   memory = '1 GB'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = fastqc_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = seqyclean_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = fastp_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     cpus = params.maxcpus
2022-03-14 09:23:04 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = maxcpus
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = bwa_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     cpus = params.maxcpus
2022-03-14 09:23:04 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = maxcpus
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = minimap2_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = samtools_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = samtools_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = ivar_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = samtools_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = ivar_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     errorStrategy = 'retry'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     maxRetries = 2
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     memory = '8 GB'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = ivar_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = pandas_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:    container = bcftools_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     cpus = params.maxcpus
2022-03-14 09:23:04 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = maxcpus
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = bamsnap_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     errorStrategy = 'ignore'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = samtools_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = samtools_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = samtools_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = samtools_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     cpus = params.maxcpus
2022-03-14 09:23:04 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = maxcpus
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = kraken2_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = bedtools_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = samtools_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = samtools_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = pangolin_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     cpus = params.medcpus
2022-03-14 09:23:04 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = medcpus
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = nextclade_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     cpus = params.medcpus
2022-03-14 09:23:04 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = medcpus
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = 'staphb/vadr:latest'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     errorStrategy = 'ignore'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = pandas_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = pandas_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     cpus = params.maxcpus
2022-03-14 09:23:04 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = maxcpus
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = mafft_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     errorStrategy = 'retry'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     maxRetries = 2
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     cpus = params.maxcpus
2022-03-14 09:23:04 [INFO] ADDING_LINE_STRIPPING_PARAMS:     cpus = maxcpus
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = nextalign_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = snp_dists_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:    cpus = params.maxcpus
2022-03-14 09:23:04 [INFO] ADDING_LINE_STRIPPING_PARAMS:    cpus = maxcpus
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:    container = iqtree2_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     container = parallel_perl_container
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS:     stageInMode = 'copy'
2022-03-14 09:23:04 [INFO] NOT_CHANGING_STATUS: }
2022-03-14 09:23:04 [INFO] DONE_PARSING


2022-03-14 09:23:04 [INFO] Adding params params.maxcpus, params.medcpus, params.cpus
2022-03-14 09:23:04 [INFO] Added 3 params
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.reads = workflow.launchDir + '/reads'
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.single_reads = workflow.launchDir + '/single_reads'
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.fastas = workflow.launchDir + '/fastas'
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:   println("'params.reads' and 'params.single_reads' cannot point to the same directory!")
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:   println("'params.reads' is set to " + params.reads)
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:   println("'params.single_reads' is set to " + params.single_reads)
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:   println("'params.fastas' is set to " + params.fastas)
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.outdir = workflow.launchDir + '/cecret'
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:     println("Set 'params.reads' to directory with paired-end reads")
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:     println("Set 'params.single_reads' to directory with single-end reads")
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:     println("Set 'params.fastas' to directory with fastas.")
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.reference_genome = workflow.projectDir + "/configs/MN908947.3.fasta"
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.gff_file = workflow.projectDir + "/configs/MN908947.3.gff"
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.primer_set = 'ncov_V4'
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:   params.primer_bed   = workflow.projectDir + "/configs/artic_V3_nCoV-2019.primer.bed"
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:   params.amplicon_bed = workflow.projectDir + "/configs/artic_V3_nCoV-2019.insert.bed"
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:   params.primer_bed   = workflow.projectDir + "/configs/artic_V4_SARS-CoV-2.primer.bed"
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:   params.amplicon_bed = workflow.projectDir + "/configs/artic_V4_SARS-CoV-2.insert.bed"
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:   params.primer_bed   = workflow.projectDir + "/configs/artic_V4.1_SARS-CoV-2.primer.bed"
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:   params.amplicon_bed = workflow.projectDir + "/configs/artic_V4.1_SARS-CoV-2.insert.bed"
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:   println("SARS-CoV-2 artic primer V3 : 'params.primer_set' = 'ncov_V3'" )
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:   println("SARS-CoV-2 artic primer V4 : 'params.primer_set' = 'ncov_V4'" )
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:   println("SARS-CoV-2 artic primer V4.1 (Version 4 with spike in) : 'params.primer_set' = 'ncov_V4.1'" )
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.trimmer = 'ivar'
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.cleaner = 'seqyclean'
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.aligner = 'bwa'
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.msa = 'mafft'
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:   params.medcpus = 5
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: println("The files and directory for results is " + params.outdir)
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:     println("No reference genome was selected. Set with 'params.reference_genome'")
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:     println("A bedfile for primers is required. Set with 'params.primer_bed'.")
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: amplicon_bed = params.bedtools_multicov
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: kraken2_db = params.kraken2
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.fastqc_options = ''
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:   params.seqyclean_contaminant_file="/Adapters_plus_PhiX_174.fasta"
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:   params.seqyclean_options = '-minlen 25 -qual'
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:   params.fastp_options = ''
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:   params.minimap2_options = '-K 20M'
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.filter_options = ''
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:   params.ivar_trim_options = ''
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:   params.samtools_ampliconclip_options = ''
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.minimum_depth = 100
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.mpileup_depth = 8000
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.ivar_variants_options = '-q 20 -t 0.6'
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:   params.ivar_variants
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.ivar_consensus_options = '-q 20 -t 0.6 -n N'
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.bamsnap_options = ''
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.samtools_stats_options = ''
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.samtools_coverage_options = ''
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.samtools_flagstat_options = ''
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.samtools_depth_options = ''
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.kraken2_options = ''
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.bedtools_multicov_options = '-f .1'
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.samtools_ampliconstats_options = ''
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.samtools_plot_ampliconstats_options = '-size 1200,900 -size2 1200,900 -size3 1200,900'
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.pangolin_options = ''
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.nextclade_options = ''
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.nextclade_dataset = 'sars-cov-2'
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.vadr_options = '--split --glsearch -s -r --nomisc --lowsim5seq 6 --lowsim3seq 6 --alt_fail lowscore,insertnn,deletinn'
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.vadr_reference = 'sarscov2'
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.vadr_mdir = '/opt/vadr/vadr-models'
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE: params.vadr_trim_options = '--minlen 50 --maxlen 30000'
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:     params.mafft_options = '--maxambiguous 0.5'
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:     params.nextalign_options = '--genes E,M,N,ORF1a,ORF1b,ORF3a,ORF6,ORF7a,ORF7b,ORF8,ORF9b,S --include-reference'
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:   params.snpdists_options = ''
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:   params.iqtree2_outgroup = 'MN908947'
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:   params.iqtree2_options = '-ninit 2 -n 2 -me 0.05 -m GTR'
2022-03-14 09:23:04 [INFO] ADDING_NF_SCRIPT_LINE:       println("No sample file was found. Set with 'params.sample_file'")
2022-03-14 09:23:04 [INFO] Parameters to check: params.primer_set
 2022-03-14 09:23:04 [INFO] Parameters to check: params.reads
 2022-03-14 09:23:04 [INFO] Parameters to check: params.kraken2
 2022-03-14 09:23:04 [INFO] Parameters to check: params.kraken2_db
 2022-03-14 09:23:04 [INFO] Parameters to check: params.vadr
 2022-03-14 09:23:04 [INFO] Parameters to check: params.maxcpus
 2022-03-14 09:23:04 [INFO] Parameters to check: params.medcpus
 2022-03-14 09:23:04 [INFO] Parameters to check: params.cpus
2022-03-14 09:23:04 [INFO] Parameters to add: params.kraken2
 2022-03-14 09:23:04 [INFO] Parameters to add: params.kraken2_db
 2022-03-14 09:23:04 [INFO] Parameters to add: params.vadr
 2022-03-14 09:23:04 [INFO] Parameters to add: params.maxcpus
 2022-03-14 09:23:04 [INFO] Parameters to add: params.medcpus
 2022-03-14 09:23:04 [INFO] Parameters to add: params.cpus
2022-03-14 09:23:04 [INFO] NO need to check param: params.primer_set
2022-03-14 09:23:04 [INFO] NO need to check param: params.reads
2022-03-14 09:23:04 [INFO] NO need to check param: params.kraken2
2022-03-14 09:23:04 [INFO] NO need to check param: params.kraken2_db
2022-03-14 09:23:04 [INFO] NO need to check param: params.vadr
2022-03-14 09:23:04 [INFO] NO need to check param: params.maxcpus
2022-03-14 09:23:04 [INFO] NO need to check param: params.medcpus
2022-03-14 09:23:04 [INFO] NO need to check param: params.cpus
2022-03-14 09:23:05 [INFO] Initializing key: 9
2022-03-14 09:23:05 [INFO] Appending to key: 9 parameter: kraken2
2022-03-14 09:23:05 [INFO] Appending to key: 9 parameter: kraken2_db
2022-03-14 09:23:05 [INFO] Appending to key: 9 parameter: vadr
2022-03-14 09:23:05 [INFO] Appending to key: 9 parameter: maxcpus
2022-03-14 09:23:05 [INFO] Appending to key: 9 parameter: medcpus
2022-03-14 09:23:05 [INFO] Appending to key: 9 parameter: cpus
2022-03-14 09:23:05 [INFO] ADDING UPDATED PARAMS to /Users/keng/codes/Cecret/Cecret.ica.nf
2022-03-14 09:23:05 [INFO] parameters found: params.primer_set
 2022-03-14 09:23:05 [INFO] parameters found: params.reads
 2022-03-14 09:23:05 [INFO] parameters found: params.kraken2
 2022-03-14 09:23:05 [INFO] parameters found: params.kraken2_db
 2022-03-14 09:23:05 [INFO] parameters found: params.vadr
 2022-03-14 09:23:05 [INFO] parameters found: params.maxcpus
 2022-03-14 09:23:05 [INFO] parameters found: params.medcpus
 2022-03-14 09:23:05 [INFO] parameters found: params.cpus
2022-03-14 09:23:05 [INFO] LOOKING into params.primer_set
2022-03-14 09:23:05 [INFO] LOOKING into params.reads
2022-03-14 09:23:05 [INFO] CHECKING if params.reads is file or folder. value: "Sequencing_reads/Raw"
2022-03-14 09:23:05 [INFO] LOOKING into params.kraken2
2022-03-14 09:23:05 [INFO] LOOKING into params.kraken2_db
2022-03-14 09:23:05 [INFO] CHECKING if params.kraken2_db is file or folder. value: '/Volumes/IDGenomics_NAS/Data/kraken2_db/h+v'
2022-03-14 09:23:05 [INFO] ADDING params.kraken2_db to dataInputs
2022-03-14 09:23:05 [INFO] LOOKING into params.vadr
2022-03-14 09:23:05 [INFO] LOOKING into params.maxcpus
2022-03-14 09:23:05 [INFO] LOOKING into params.medcpus
2022-03-14 09:23:05 [INFO] LOOKING into params.cpus
2022-03-14 09:23:05 [INFO] STEP3:Generating ICA XML based off of /Users/keng/codes/Cecret/Cecret.nf
2022-03-14 09:23:05 [INFO] STEP3a: Adding dataInputs
2022-03-14 09:23:05 [INFO] STEP3b: Adding parameter options
2022-03-14 09:23:05 [INFO] STEP4: Generating parameters XML to /Users/keng/codes/Cecret/Cecret.pipeline.xml
[1] "/Users/keng/codes/Cecret/Cecret.pipeline.xml"
2022-03-14 09:23:05 [INFO] READING IN: /Users/keng/codes/Cecret/./configs/cecret_config_template.config
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE: process {
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   errorStrategy = 'retry'
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   maxRetries = 1
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   cpus = 1
2022-03-14 09:23:05 [INFO] CPUS_PARSED: 1
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   memory = '1 GB'
2022-03-14 09:23:05 [INFO] MEM_PARSED: 1 GB
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:fastqc{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 204
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: fastqc
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME fastqc
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME fastqc
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = fastqc_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:seqyclean{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 207
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: seqyclean
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME seqyclean
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME seqyclean
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = seqyclean_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:fastp{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 210
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: fastp
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME fastp
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME fastp
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = fastp_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:bwa{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 213
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: bwa
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME bwa
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME bwa
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa
2022-03-14 09:23:05 [INFO] INITIAL_LINE:     cpus = params.maxcpus
2022-03-14 09:23:05 [INFO] TRANSLATED_LINE:     cpus = 8
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CPUS_PARSED: 8
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME bwa
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = bwa_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:minimap2{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 217
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: minimap2
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME minimap2
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME minimap2
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2
2022-03-14 09:23:05 [INFO] INITIAL_LINE:     cpus = params.maxcpus
2022-03-14 09:23:05 [INFO] TRANSLATED_LINE:     cpus = 8
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CPUS_PARSED: 8
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME minimap2
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = minimap2_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:sort{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 221
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: sort
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME sort
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME sort
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = samtools_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:filter{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 224
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: filter
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME filter
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME filter
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = samtools_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:ivar_trim{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 227
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: ivar_trim
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME ivar_trim
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME ivar_trim
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = ivar_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:samtools_ampliconclip{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 230
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: samtools_ampliconclip
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME samtools_ampliconclip
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME samtools_ampliconclip
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = samtools_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:ivar_variants{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 233
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: ivar_variants
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME ivar_variants
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME ivar_variants
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = ivar_container
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME ivar_variants
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_MEM_PARSED: 2.GB
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME ivar_variants
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME ivar_variants
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:ivar_consensus{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 239
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: ivar_consensus
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME ivar_consensus
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME ivar_consensus
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_MEM_PARSED: 8 GB
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME ivar_consensus
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = ivar_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:fasta_prep{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 243
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: fasta_prep
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME fasta_prep
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME fasta_prep
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = pandas_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:bcftools_variants{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 246
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: bcftools_variants
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME bcftools_variants
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME bcftools_variants
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:    container = bcftools_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:bamsnap{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 249
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: bamsnap
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME bamsnap
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME bamsnap
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap
2022-03-14 09:23:05 [INFO] INITIAL_LINE:     cpus = params.maxcpus
2022-03-14 09:23:05 [INFO] TRANSLATED_LINE:     cpus = 8
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CPUS_PARSED: 8
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME bamsnap
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = bamsnap_container
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME bamsnap
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:samtools_stats{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 254
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: samtools_stats
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME samtools_stats
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME samtools_stats
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = samtools_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:samtools_coverage{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 257
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: samtools_coverage
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME samtools_coverage
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME samtools_coverage
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = samtools_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:samtools_flagstat{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 260
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: samtools_flagstat
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME samtools_flagstat
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME samtools_flagstat
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = samtools_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:samtools_depth{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 263
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: samtools_depth
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME samtools_depth
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME samtools_depth
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = samtools_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:kraken2{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 266
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: kraken2
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME kraken2
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME kraken2
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2
2022-03-14 09:23:05 [INFO] INITIAL_LINE:     cpus = params.maxcpus
2022-03-14 09:23:05 [INFO] TRANSLATED_LINE:     cpus = 8
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CPUS_PARSED: 8
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME kraken2
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = kraken2_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:bedtools_multicov{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 270
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: bedtools_multicov
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME bedtools_multicov
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME bedtools_multicov
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = bedtools_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:samtools_ampliconstats{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 273
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: samtools_ampliconstats
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME samtools_ampliconstats
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME samtools_ampliconstats
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = samtools_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:samtools_plot_ampliconstats{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 276
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: samtools_plot_ampliconstats
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME samtools_plot_ampliconstats
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME samtools_plot_ampliconstats
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = samtools_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:pangolin{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 279
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: pangolin
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME pangolin
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME pangolin
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = pangolin_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:nextclade{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 282
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: nextclade
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME nextclade
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME nextclade
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade
2022-03-14 09:23:05 [INFO] INITIAL_LINE:     cpus = params.medcpus
2022-03-14 09:23:05 [INFO] TRANSLATED_LINE:     cpus = 4
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CPUS_PARSED: 4
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME nextclade
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = nextclade_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:vadr{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 286
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: vadr
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME vadr
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade, vadr
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME vadr
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade, vadr
2022-03-14 09:23:05 [INFO] INITIAL_LINE:     cpus = params.medcpus
2022-03-14 09:23:05 [INFO] TRANSLATED_LINE:     cpus = 4
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CPUS_PARSED: 4
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME vadr
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade, vadr
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = 'staphb/vadr:latest'
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME vadr
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade, vadr
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:summary{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 291
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: summary
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME summary
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade, vadr, summary
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME summary
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade, vadr, summary
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = pandas_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:combine_results{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 294
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: combine_results
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME combine_results
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade, vadr, summary, combine_results
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME combine_results
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade, vadr, summary, combine_results
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = pandas_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:mafft{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 297
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: mafft
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME mafft
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade, vadr, summary, combine_results, mafft
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME mafft
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade, vadr, summary, combine_results, mafft
2022-03-14 09:23:05 [INFO] INITIAL_LINE:     cpus = params.maxcpus
2022-03-14 09:23:05 [INFO] TRANSLATED_LINE:     cpus = 8
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CPUS_PARSED: 8
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME mafft
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade, vadr, summary, combine_results, mafft
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = mafft_container
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME mafft
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade, vadr, summary, combine_results, mafft
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME mafft
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade, vadr, summary, combine_results, mafft
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:nextalign{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 303
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: nextalign
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME nextalign
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade, vadr, summary, combine_results, mafft, nextalign
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME nextalign
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade, vadr, summary, combine_results, mafft, nextalign
2022-03-14 09:23:05 [INFO] INITIAL_LINE:     cpus = params.maxcpus
2022-03-14 09:23:05 [INFO] TRANSLATED_LINE:     cpus = 8
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CPUS_PARSED: 8
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME nextalign
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade, vadr, summary, combine_results, mafft, nextalign
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = nextalign_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:snpdists{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 307
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: snpdists
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME snpdists
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade, vadr, summary, combine_results, mafft, nextalign, snpdists
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME snpdists
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade, vadr, summary, combine_results, mafft, nextalign, snpdists
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = snp_dists_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:iqtree2{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 310
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: iqtree2
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME iqtree2
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade, vadr, summary, combine_results, mafft, nextalign, snpdists, iqtree2
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME iqtree2
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade, vadr, summary, combine_results, mafft, nextalign, snpdists, iqtree2
2022-03-14 09:23:05 [INFO] INITIAL_LINE:    cpus = params.maxcpus
2022-03-14 09:23:05 [INFO] TRANSLATED_LINE:    cpus = 8
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CPUS_PARSED: 8
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME iqtree2
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade, vadr, summary, combine_results, mafft, nextalign, snpdists, iqtree2
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:    container = iqtree2_container
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_FOUND:   withName:rename{
2022-03-14 09:23:05 [INFO] LINE_NUMBER: 314
2022-03-14 09:23:05 [INFO] GETTING_METADATA_FOR_PROCESS_LABEL: rename
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME rename
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade, vadr, summary, combine_results, mafft, nextalign, snpdists, iqtree2, rename
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME rename
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade, vadr, summary, combine_results, mafft, nextalign, snpdists, iqtree2, rename
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_CONTAINER_PARSED:     container = parallel_perl_container
2022-03-14 09:23:05 [INFO] PROCESS_LABEL_NAME rename
[1] TRUE
2022-03-14 09:23:05 [INFO] NAMES: default, fastqc, seqyclean, fastp, bwa, minimap2, sort, filter, ivar_trim, samtools_ampliconclip, ivar_variants, ivar_consensus, fasta_prep, bcftools_variants, bamsnap, samtools_stats, samtools_coverage, samtools_flagstat, samtools_depth, kraken2, bedtools_multicov, samtools_ampliconstats, samtools_plot_ampliconstats, pangolin, nextclade, vadr, summary, combine_results, mafft, nextalign, snpdists, iqtree2, rename
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_LABEL_CLOSURE:   }
2022-03-14 09:23:05 [INFO] PROCESS_CLOSURE_LINE:   }
2022-03-14 09:23:05 [INFO] EXITING_PROCESS_CLOSURE: }
$default
$default$errorStrategy
[1] "ignore"

$default$cpus
[1] "1"

$default$mem
[1] "1 GB"


$fastqc
$fastqc$errorStrategy
[1] "ignore"

$fastqc$container
[1] "    container = fastqc_container"


$seqyclean
$seqyclean$errorStrategy
[1] "ignore"

$seqyclean$container
[1] "    container = seqyclean_container"


$fastp
$fastp$errorStrategy
[1] "ignore"

$fastp$container
[1] "    container = fastp_container"


$bwa
$bwa$errorStrategy
[1] "ignore"

$bwa$cpus
[1] "8"

$bwa$container
[1] "    container = bwa_container"


$minimap2
$minimap2$errorStrategy
[1] "ignore"

$minimap2$cpus
[1] "8"

$minimap2$container
[1] "    container = minimap2_container"


$sort
$sort$errorStrategy
[1] "ignore"

$sort$container
[1] "    container = samtools_container"


$filter
$filter$errorStrategy
[1] "ignore"

$filter$container
[1] "    container = samtools_container"


$ivar_trim
$ivar_trim$errorStrategy
[1] "ignore"

$ivar_trim$container
[1] "    container = ivar_container"


$samtools_ampliconclip
$samtools_ampliconclip$errorStrategy
[1] "ignore"

$samtools_ampliconclip$container
[1] "    container = samtools_container"


$ivar_variants
$ivar_variants$errorStrategy
[1] "ignore"

$ivar_variants$container
[1] "    container = ivar_container"

$ivar_variants$mem
[1] "2.GB"


$ivar_consensus
$ivar_consensus$errorStrategy
[1] "ignore"

$ivar_consensus$mem
[1] "8 GB"

$ivar_consensus$container
[1] "    container = ivar_container"


$fasta_prep
$fasta_prep$errorStrategy
[1] "ignore"

$fasta_prep$container
[1] "    container = pandas_container"


$bcftools_variants
$bcftools_variants$errorStrategy
[1] "ignore"

$bcftools_variants$container
[1] "   container = bcftools_container"


$bamsnap
$bamsnap$errorStrategy
[1] "ignore"

$bamsnap$cpus
[1] "8"

$bamsnap$container
[1] "    container = bamsnap_container"


$samtools_stats
$samtools_stats$errorStrategy
[1] "ignore"

$samtools_stats$container
[1] "    container = samtools_container"


$samtools_coverage
$samtools_coverage$errorStrategy
[1] "ignore"

$samtools_coverage$container
[1] "    container = samtools_container"


$samtools_flagstat
$samtools_flagstat$errorStrategy
[1] "ignore"

$samtools_flagstat$container
[1] "    container = samtools_container"


$samtools_depth
$samtools_depth$errorStrategy
[1] "ignore"

$samtools_depth$container
[1] "    container = samtools_container"


$kraken2
$kraken2$errorStrategy
[1] "ignore"

$kraken2$cpus
[1] "8"

$kraken2$container
[1] "    container = kraken2_container"


$bedtools_multicov
$bedtools_multicov$errorStrategy
[1] "ignore"

$bedtools_multicov$container
[1] "    container = bedtools_container"


$samtools_ampliconstats
$samtools_ampliconstats$errorStrategy
[1] "ignore"

$samtools_ampliconstats$container
[1] "    container = samtools_container"


$samtools_plot_ampliconstats
$samtools_plot_ampliconstats$errorStrategy
[1] "ignore"

$samtools_plot_ampliconstats$container
[1] "    container = samtools_container"


$pangolin
$pangolin$errorStrategy
[1] "ignore"

$pangolin$container
[1] "    container = pangolin_container"


$nextclade
$nextclade$errorStrategy
[1] "ignore"

$nextclade$cpus
[1] "4"

$nextclade$container
[1] "    container = nextclade_container"


$vadr
$vadr$errorStrategy
[1] "ignore"

$vadr$cpus
[1] "4"

$vadr$container
[1] "    container = 'staphb/vadr:latest'"


$summary
$summary$errorStrategy
[1] "ignore"

$summary$container
[1] "    container = pandas_container"


$combine_results
$combine_results$errorStrategy
[1] "ignore"

$combine_results$container
[1] "    container = pandas_container"


$mafft
$mafft$errorStrategy
[1] "ignore"

$mafft$cpus
[1] "8"

$mafft$container
[1] "    container = mafft_container"


$nextalign
$nextalign$errorStrategy
[1] "ignore"

$nextalign$cpus
[1] "8"

$nextalign$container
[1] "    container = nextalign_container"


$snpdists
$snpdists$errorStrategy
[1] "ignore"

$snpdists$container
[1] "    container = snp_dists_container"


$iqtree2
$iqtree2$errorStrategy
[1] "ignore"

$iqtree2$cpus
[1] "8"

$iqtree2$container
[1] "   container = iqtree2_container"


$rename
$rename$errorStrategy
[1] "ignore"

$rename$container
[1] "    container = parallel_perl_container"


2022-03-14 09:23:07 [INFO] script /Users/keng/codes/Cecret/Cecret.ica.nf is DSL2 enabled: FALSE
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: fastqc
2022-03-14 09:23:07 [INFO] PROCESS_LINE: process fastqc {
2022-03-14 09:23:07 [INFO] ADDING_LINE: process fastqc {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tag "$sample"
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tag "$sample"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   cpus 1
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   container 'staphb/fastqc:latest'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   container 'staphb/fastqc:latest'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: fastqc
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/fastqc:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   params.fastqc && sample != null
2022-03-14 09:23:07 [INFO] ADDING_LINE:   params.fastqc && sample != null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: fastqc
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/fastqc:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple val(sample), file(raw), val(type) from fastq_reads_fastqc
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple val(sample), file(raw), val(type) from fastq_reads_fastqc
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("${task.process}/*.{html,zip}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("${task.process}/*.{html,zip}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple sample, env(raw_1) into fastqc_1_results
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple sample, env(raw_1) into fastqc_1_results
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple sample, env(raw_2) into fastqc_2_results
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple sample, env(raw_2) into fastqc_2_results
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:07 [INFO] ADDING_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     fastqc --version >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:     fastqc --version >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     fastqc !{params.fastqc_options} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:     fastqc !{params.fastqc_options} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       --outdir !{task.process} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       --outdir !{task.process} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       --threads !{task.cpus} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       --threads !{task.cpus} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       !{raw} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       !{raw} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:       2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     zipped_fastq=($(ls !{task.process}/*fastqc.zip) "")
2022-03-14 09:23:07 [INFO] ADDING_LINE:     zipped_fastq=($(ls !{task.process}/*fastqc.zip) "")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     raw_1=$(unzip -p ${zipped_fastq[0]} */fastqc_data.txt | grep "Total Sequences" | awk '{ print $3 }' )
2022-03-14 09:23:07 [INFO] ADDING_LINE:     raw_1=$(unzip -p ${zipped_fastq[0]} */fastqc_data.txt | grep "Total Sequences" | awk '{ print $3 }' )
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     raw_2=NA
2022-03-14 09:23:07 [INFO] ADDING_LINE:     raw_2=NA
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ -f "${zipped_fastq[1]}" ] ; then raw_2=$(unzip -p !{task.process}/*fastqc.zip */fastqc_data.txt | grep "Total Sequences" | awk '{ print $3 }' ) ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ -f "${zipped_fastq[1]}" ] ; then raw_2=$(unzip -p !{task.process}/*fastqc.zip */fastqc_data.txt | grep "Total Sequences" | awk '{ print $3 }' ) ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ -f "${zipped_fastq[1]}" ] ; then raw_2=$(unzip -p !{task.process}/*fastqc.zip */fastqc_data.txt | grep "Total Sequences" | awk '{ print $3 }' ) ; fi
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ -z "$raw_1" ] ; then raw_1="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ -z "$raw_1" ] ; then raw_1="0" ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ -z "$raw_1" ] ; then raw_1="0" ; fi
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ -z "$raw_2" ] ; then raw_2="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ -z "$raw_2" ] ; then raw_2="0" ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ -z "$raw_2" ] ; then raw_2="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE: }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS fastqc
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: seqyclean
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   process seqyclean {
2022-03-14 09:23:07 [INFO] ADDING_LINE:   process seqyclean {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tag "${sample}"
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tag "${sample}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     cpus 1
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     container 'staphb/seqyclean:latest'
2022-03-14 09:23:07 [INFO] ADDING_LINE:     container 'staphb/seqyclean:latest'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     when:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:     
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: seqyclean
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/seqyclean:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:     when:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     sample != null
2022-03-14 09:23:07 [INFO] ADDING_LINE:     sample != null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:     input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: seqyclean
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/seqyclean:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:     input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple val(sample), file(reads), val(paired_single) from fastq_reads_seqyclean
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple val(sample), file(reads), val(paired_single) from fastq_reads_seqyclean
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:     output:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple sample, file("${task.process}/${sample}_clean_PE{1,2}.fastq.gz") optional true into paired_files
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple sample, file("${task.process}/${sample}_clean_PE{1,2}.fastq.gz") optional true into paired_files
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple sample, file("${task.process}/${sample}_cln_SE.fastq.gz") optional true into single_files
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple sample, file("${task.process}/${sample}_cln_SE.fastq.gz") optional true into single_files
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple sample, file("${task.process}/${sample}_clean_PE{1,2}.fastq.gz"), val(paired_single) optional true into paired_files_kraken2
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple sample, file("${task.process}/${sample}_clean_PE{1,2}.fastq.gz"), val(paired_single) optional true into paired_files_kraken2
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple sample, file("${task.process}/${sample}_cln_SE.fastq.gz"), val(paired_single) optional true into single_files_kraken2
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple sample, file("${task.process}/${sample}_cln_SE.fastq.gz"), val(paired_single) optional true into single_files_kraken2
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     file("${task.process}/${sample}_cl*n_SummaryStatistics.tsv") into seqyclean_files
2022-03-14 09:23:07 [INFO] ADDING_LINE:     file("${task.process}/${sample}_cl*n_SummaryStatistics.tsv") into seqyclean_files
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     file("${task.process}/${sample}_cl*n_SummaryStatistics.txt")
2022-03-14 09:23:07 [INFO] ADDING_LINE:     file("${task.process}/${sample}_cl*n_SummaryStatistics.txt")
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple sample, env(perc_kept) into seqyclean_perc_kept_results
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple sample, env(perc_kept) into seqyclean_perc_kept_results
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple sample, env(kept) into seqyclean_pairskept_results
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple sample, env(kept) into seqyclean_pairskept_results
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple sample, env(cleaner_version) into cleaner_version
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple sample, env(cleaner_version) into cleaner_version
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:     shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:       mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:07 [INFO] ADDING_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] ADDING_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       echo "seqyclean version: $(seqyclean -h | grep Version)" >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:       echo "seqyclean version: $(seqyclean -h | grep Version)" >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       cleaner_version="seqyclean : $(seqyclean -h | grep Version)"
2022-03-14 09:23:07 [INFO] ADDING_LINE:       cleaner_version="seqyclean : $(seqyclean -h | grep Version)"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       kept=''
2022-03-14 09:23:07 [INFO] ADDING_LINE:       kept=''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       perc_kept=''
2022-03-14 09:23:07 [INFO] ADDING_LINE:       perc_kept=''
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:       if [ "!{paired_single}" == "single" ]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       if [ "!{paired_single}" == "single" ]
2022-03-14 09:23:07 [INFO] ADDING_LINE:       if [ "!{paired_single}" == "single" ]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       then
2022-03-14 09:23:07 [INFO] ADDING_LINE:       then
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         seqyclean !{params.seqyclean_options} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         seqyclean !{params.seqyclean_options} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:           -c !{params.seqyclean_contaminant_file} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:           -c !{params.seqyclean_contaminant_file} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:           -U !{reads} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:           -U !{reads} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:           -o !{task.process}/!{sample}_cln \
2022-03-14 09:23:07 [INFO] ADDING_LINE:           -o !{task.process}/!{sample}_cln \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:           -gz \
2022-03-14 09:23:07 [INFO] ADDING_LINE:           -gz \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:           2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:           2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         kept=$(cut -f 36 !{task.process}/!{sample}_cln_SummaryStatistics.tsv | grep -v "Kept" | head -n 1)
2022-03-14 09:23:07 [INFO] ADDING_LINE:         kept=$(cut -f 36 !{task.process}/!{sample}_cln_SummaryStatistics.tsv | grep -v "Kept" | head -n 1)
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         perc_kept=$(cut -f 37 !{task.process}/!{sample}_cln_SummaryStatistics.tsv | grep -v "Kept" | head -n 1)
2022-03-14 09:23:07 [INFO] ADDING_LINE:         perc_kept=$(cut -f 37 !{task.process}/!{sample}_cln_SummaryStatistics.tsv | grep -v "Kept" | head -n 1)
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       else
2022-03-14 09:23:07 [INFO] ADDING_LINE:       else
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         seqyclean !{params.seqyclean_options} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         seqyclean !{params.seqyclean_options} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:           -c !{params.seqyclean_contaminant_file} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:           -c !{params.seqyclean_contaminant_file} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:           -1 !{reads[0]} -2 !{reads[1]} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:           -1 !{reads[0]} -2 !{reads[1]} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:           -o !{task.process}/!{sample}_clean \
2022-03-14 09:23:07 [INFO] ADDING_LINE:           -o !{task.process}/!{sample}_clean \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:           -gz \
2022-03-14 09:23:07 [INFO] ADDING_LINE:           -gz \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:           2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:           2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         kept=$(cut -f 58 !{task.process}/!{sample}_clean_SummaryStatistics.tsv | grep -v "Kept" | head -n 1)
2022-03-14 09:23:07 [INFO] ADDING_LINE:         kept=$(cut -f 58 !{task.process}/!{sample}_clean_SummaryStatistics.tsv | grep -v "Kept" | head -n 1)
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         perc_kept=$(cut -f 59 !{task.process}/!{sample}_clean_SummaryStatistics.tsv | grep -v "Kept" | head -n 1)
2022-03-14 09:23:07 [INFO] ADDING_LINE:         perc_kept=$(cut -f 59 !{task.process}/!{sample}_clean_SummaryStatistics.tsv | grep -v "Kept" | head -n 1)
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:       fi
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:       if [ -z "$kept" ] ; then kept="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       if [ -z "$kept" ] ; then kept="0" ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:       if [ -z "$kept" ] ; then kept="0" ; fi
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:       if [ -z "$perc_kept" ] ; then perc_kept="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       if [ -z "$perc_kept" ] ; then perc_kept="0" ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:       if [ -z "$perc_kept" ] ; then perc_kept="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS seqyclean
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: fastp
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   process fastp {
2022-03-14 09:23:07 [INFO] ADDING_LINE:   process fastp {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tag "${sample}"
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tag "${sample}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     cpus 1
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     container 'bromberglab/fastp:latest'
2022-03-14 09:23:07 [INFO] ADDING_LINE:     container 'bromberglab/fastp:latest'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     when:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:     
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: fastp
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'bromberglab/fastp:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:     when:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     sample != null
2022-03-14 09:23:07 [INFO] ADDING_LINE:     sample != null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:     input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: fastp
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'bromberglab/fastp:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:     input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple val(sample), file(reads), val(paired_single) from fastq_reads_fastp
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple val(sample), file(reads), val(paired_single) from fastq_reads_fastp
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:     output:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple sample, file("${task.process}/${sample}_clean_PE{1,2}.fastq.gz") optional true into paired_files
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple sample, file("${task.process}/${sample}_clean_PE{1,2}.fastq.gz") optional true into paired_files
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple sample, file("${task.process}/${sample}_cln.fastq.gz") optional true into single_files
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple sample, file("${task.process}/${sample}_cln.fastq.gz") optional true into single_files
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple sample, file("${task.process}/${sample}_clean_PE{1,2}.fastq.gz"), val(paired_single) optional true into paired_files_kraken2
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple sample, file("${task.process}/${sample}_clean_PE{1,2}.fastq.gz"), val(paired_single) optional true into paired_files_kraken2
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple sample, file("${task.process}/${sample}_cln.fastq.gz"), val(paired_single) optional true into single_files_kraken2
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple sample, file("${task.process}/${sample}_cln.fastq.gz"), val(paired_single) optional true into single_files_kraken2
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     file("${task.process}/${sample}_fastp.{html,json}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:     file("${task.process}/${sample}_fastp.{html,json}")
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple sample, env(passed_reads) into fastp_results
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple sample, env(passed_reads) into fastp_results
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple sample, env(cleaner_version) into cleaner_version
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple sample, env(cleaner_version) into cleaner_version
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:     shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:       mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:07 [INFO] ADDING_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] ADDING_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       fastp --version >> $log_file 2>> $err_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:       fastp --version >> $log_file 2>> $err_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       cleaner_version="$(fastp --version 2>&1 | head -n 1)"
2022-03-14 09:23:07 [INFO] ADDING_LINE:       cleaner_version="$(fastp --version 2>&1 | head -n 1)"
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:       if [ "!{paired_single}" == "single" ]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       if [ "!{paired_single}" == "single" ]
2022-03-14 09:23:07 [INFO] ADDING_LINE:       if [ "!{paired_single}" == "single" ]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       then
2022-03-14 09:23:07 [INFO] ADDING_LINE:       then
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         fastp !{params.fastp_options} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         fastp !{params.fastp_options} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:           -i !{reads} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:           -i !{reads} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:           -o !{task.process}/!{sample}_cln.fastq.gz \
2022-03-14 09:23:07 [INFO] ADDING_LINE:           -o !{task.process}/!{sample}_cln.fastq.gz \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:           -h !{task.process}/!{sample}_fastp.html \
2022-03-14 09:23:07 [INFO] ADDING_LINE:           -h !{task.process}/!{sample}_fastp.html \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:           -j !{task.process}/!{sample}_fastp.json \
2022-03-14 09:23:07 [INFO] ADDING_LINE:           -j !{task.process}/!{sample}_fastp.json \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:           2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:           2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       else
2022-03-14 09:23:07 [INFO] ADDING_LINE:       else
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         fastp !{params.fastp_options} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         fastp !{params.fastp_options} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:           -i !{reads[0]} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:           -i !{reads[0]} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:           -I !{reads[1]} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:           -I !{reads[1]} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:           -o !{task.process}/!{sample}_clean_PE1.fastq.gz \
2022-03-14 09:23:07 [INFO] ADDING_LINE:           -o !{task.process}/!{sample}_clean_PE1.fastq.gz \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:           -O !{task.process}/!{sample}_clean_PE2.fastq.gz \
2022-03-14 09:23:07 [INFO] ADDING_LINE:           -O !{task.process}/!{sample}_clean_PE2.fastq.gz \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:           -h !{task.process}/!{sample}_fastp.html \
2022-03-14 09:23:07 [INFO] ADDING_LINE:           -h !{task.process}/!{sample}_fastp.html \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:           -j !{task.process}/!{sample}_fastp.json \
2022-03-14 09:23:07 [INFO] ADDING_LINE:           -j !{task.process}/!{sample}_fastp.json \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:           2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:           2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:       fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       passed_reads=$(grep "reads passed filter" $err_file | tail -n 1 | cut -f 2 -d ":" | sed 's/ //g' )
2022-03-14 09:23:07 [INFO] ADDING_LINE:       passed_reads=$(grep "reads passed filter" $err_file | tail -n 1 | cut -f 2 -d ":" | sed 's/ //g' )
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:       if [ -z "$passed_reads" ] ; then passed_reads="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       if [ -z "$passed_reads" ] ; then passed_reads="0" ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:       if [ -z "$passed_reads" ] ; then passed_reads="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS fastp
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: bwa
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   process bwa {
2022-03-14 09:23:07 [INFO] ADDING_LINE:   process bwa {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     publishDir "${params.outdir}", mode: 'copy', pattern: "logs/bwa/*.{log,err}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tag "${sample}"
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tag "${sample}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     cpus params.maxcpus
2022-03-14 09:23:07 [INFO] INITIAL_LINE:     cpus params.maxcpus
2022-03-14 09:23:07 [INFO] TRANSLATED_LINE:     cpus 8
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     container 'staphb/bwa:latest'
2022-03-14 09:23:07 [INFO] ADDING_LINE:     container 'staphb/bwa:latest'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:     input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: bwa
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 8 MEM  CONTAINER 'staphb/bwa:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:     input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple val(sample), file(reads), file(reference_genome) from paired_files.concat(single_files).combine(reference_genome)
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple val(sample), file(reads), file(reference_genome) from paired_files.concat(single_files).combine(reference_genome)
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:     output:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple sample, file("aligned/${sample}.sam") into sams, sams_filter
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple sample, file("aligned/${sample}.sam") into sams, sams_filter
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple sample, env(bwa_version) into aligner_version
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple sample, env(bwa_version) into aligner_version
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:     shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       mkdir -p aligned logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:       mkdir -p aligned logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:07 [INFO] ADDING_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] ADDING_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       echo "bwa $(bwa 2>&1 | grep Version )" >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:       echo "bwa $(bwa 2>&1 | grep Version )" >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       bwa_version="bwa : "$(bwa 2>&1 | grep Version)
2022-03-14 09:23:07 [INFO] ADDING_LINE:       bwa_version="bwa : "$(bwa 2>&1 | grep Version)
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       # index the reference fasta file
2022-03-14 09:23:07 [INFO] ADDING_LINE:       # index the reference fasta file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       bwa index !{reference_genome}
2022-03-14 09:23:07 [INFO] ADDING_LINE:       bwa index !{reference_genome}
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       # bwa mem command
2022-03-14 09:23:07 [INFO] ADDING_LINE:       # bwa mem command
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       bwa mem -t !{task.cpus} !{reference_genome} !{reads} 2>> $err_file > aligned/!{sample}.sam
2022-03-14 09:23:07 [INFO] ADDING_LINE:       bwa mem -t !{task.cpus} !{reference_genome} !{reads} 2>> $err_file > aligned/!{sample}.sam
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS bwa
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: minimap2
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   process minimap2 {
2022-03-14 09:23:07 [INFO] ADDING_LINE:   process minimap2 {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     publishDir "${params.outdir}", mode: 'copy', pattern: "logs/minimap2/*.{log,err}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tag "${sample}"
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tag "${sample}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     cpus params.maxcpus
2022-03-14 09:23:07 [INFO] INITIAL_LINE:     cpus params.maxcpus
2022-03-14 09:23:07 [INFO] TRANSLATED_LINE:     cpus 8
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     container 'staphb/minimap2:latest'
2022-03-14 09:23:07 [INFO] ADDING_LINE:     container 'staphb/minimap2:latest'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:     input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: minimap2
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 8 MEM  CONTAINER 'staphb/minimap2:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:     input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple val(sample), file(reads), file(reference_genome) from paired_files.concat(single_files).combine(reference_genome)
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple val(sample), file(reads), file(reference_genome) from paired_files.concat(single_files).combine(reference_genome)
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:     output:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple sample, file("aligned/${sample}.sam") into sams, sams_filter
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple sample, file("aligned/${sample}.sam") into sams, sams_filter
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple sample, env(minimap2_version) into aligner_version
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple sample, env(minimap2_version) into aligner_version
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:     shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       mkdir -p aligned logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:       mkdir -p aligned logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:07 [INFO] ADDING_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] ADDING_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       minimap2 --version >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:       minimap2 --version >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       minimap2_version=$(echo "minimap2 : "$(minimap2 --version))
2022-03-14 09:23:07 [INFO] ADDING_LINE:       minimap2_version=$(echo "minimap2 : "$(minimap2 --version))
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       minimap2 !{params.minimap2_options} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       minimap2 !{params.minimap2_options} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         -ax sr -t !{task.cpus} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         -ax sr -t !{task.cpus} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         -o aligned/!{sample}.sam \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         -o aligned/!{sample}.sam \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         !{reference_genome} !{reads} 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:         !{reference_genome} !{reads} 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS minimap2
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: sort
2022-03-14 09:23:07 [INFO] PROCESS_LINE: process sort {
2022-03-14 09:23:07 [INFO] ADDING_LINE: process sort {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   cpus params.maxcpus
2022-03-14 09:23:07 [INFO] INITIAL_LINE:   cpus params.maxcpus
2022-03-14 09:23:07 [INFO] TRANSLATED_LINE:   cpus 8
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   container 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   container 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: sort
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 8 MEM  CONTAINER 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple val(sample), file(sam) from sams
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple val(sample), file(sam) from sams
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple sample, file("aligned/${sample}.sorted.bam") into pre_trim_bams, pre_trim_bams2
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple sample, file("aligned/${sample}.sorted.bam") into pre_trim_bams, pre_trim_bams2
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple sample, file("aligned/${sample}.sorted.bam"), file("aligned/${sample}.sorted.bam.bai") into pre_trim_bams_bamsnap, pre_trim_bams_bedtools
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple sample, file("aligned/${sample}.sorted.bam"), file("aligned/${sample}.sorted.bam.bai") into pre_trim_bams_bamsnap, pre_trim_bams_bedtools
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     mkdir -p aligned logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:     mkdir -p aligned logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:07 [INFO] ADDING_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     samtools --version >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:     samtools --version >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     samtools sort !{sam} 2>> $err_file | \
2022-03-14 09:23:07 [INFO] ADDING_LINE:     samtools sort !{sam} 2>> $err_file | \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       samtools view -F 4 -o aligned/!{sample}.sorted.bam 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:       samtools view -F 4 -o aligned/!{sample}.sorted.bam 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     # indexing the bams
2022-03-14 09:23:07 [INFO] ADDING_LINE:     # indexing the bams
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     samtools index aligned/!{sample}.sorted.bam 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:     samtools index aligned/!{sample}.sorted.bam 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE: }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS sort
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: filter
2022-03-14 09:23:07 [INFO] PROCESS_LINE: process filter {
2022-03-14 09:23:07 [INFO] ADDING_LINE: process filter {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   cpus 1
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   container 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   container 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: filter
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   params.filter
2022-03-14 09:23:07 [INFO] ADDING_LINE:   params.filter
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: filter
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple val(sample), file(sam) from sams_filter
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple val(sample), file(sam) from sams_filter
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple sample, file("${task.process}/${sample}_filtered_{R1,R2}.fastq.gz") optional true into filtered_reads
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple sample, file("${task.process}/${sample}_filtered_{R1,R2}.fastq.gz") optional true into filtered_reads
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("${task.process}/${sample}_filtered_unpaired.fastq.gz") optional true
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("${task.process}/${sample}_filtered_unpaired.fastq.gz") optional true
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:07 [INFO] ADDING_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     samtools --version >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:     samtools --version >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     samtools sort -n !{sam} 2>> $err_file | \
2022-03-14 09:23:07 [INFO] ADDING_LINE:     samtools sort -n !{sam} 2>> $err_file | \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       samtools fastq -F 4 !{params.filter_options} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       samtools fastq -F 4 !{params.filter_options} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       -s !{task.process}/!{sample}_filtered_unpaired.fastq.gz \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       -s !{task.process}/!{sample}_filtered_unpaired.fastq.gz \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       -1 !{task.process}/!{sample}_filtered_R1.fastq.gz \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       -1 !{task.process}/!{sample}_filtered_R1.fastq.gz \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       -2 !{task.process}/!{sample}_filtered_R2.fastq.gz \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       -2 !{task.process}/!{sample}_filtered_R2.fastq.gz \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:       2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE: }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS filter
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: ivar_trim
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   process ivar_trim {
2022-03-14 09:23:07 [INFO] ADDING_LINE:   process ivar_trim {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tag "${sample}"
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tag "${sample}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     cpus 1
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     container 'staphb/ivar:latest'
2022-03-14 09:23:07 [INFO] ADDING_LINE:     container 'staphb/ivar:latest'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:     input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: ivar_trim
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/ivar:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:     input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple val(sample), file(bam), file(primer_bed) from pre_trim_bams.combine(primer_bed)
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple val(sample), file(bam), file(primer_bed) from pre_trim_bams.combine(primer_bed)
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:     output:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple sample, file("${task.process}/${sample}.primertrim.sorted.bam") into trimmed_bams, trimmed_bams4, trimmed_bams5
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple sample, file("${task.process}/${sample}.primertrim.sorted.bam") into trimmed_bams, trimmed_bams4, trimmed_bams5
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple sample, file("${task.process}/${sample}.primertrim.sorted.bam"), file("ivar_trim/${sample}.primertrim.sorted.bam.bai") into bam_bai
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple sample, file("${task.process}/${sample}.primertrim.sorted.bam"), file("ivar_trim/${sample}.primertrim.sorted.bam.bai") into bam_bai
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple sample, env(trimmer_version) into trimmer_version
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple sample, env(trimmer_version) into trimmer_version
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:     shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:       mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:07 [INFO] ADDING_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] ADDING_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       ivar version >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:       ivar version >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       trimmer_version="ivar : $(ivar version | grep version)"
2022-03-14 09:23:07 [INFO] ADDING_LINE:       trimmer_version="ivar : $(ivar version | grep version)"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       # trimming the reads
2022-03-14 09:23:07 [INFO] ADDING_LINE:       # trimming the reads
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       ivar trim !{params.ivar_trim_options} -e -i !{bam} -b !{primer_bed} -p !{task.process}/!{sample}.primertrim 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:       ivar trim !{params.ivar_trim_options} -e -i !{bam} -b !{primer_bed} -p !{task.process}/!{sample}.primertrim 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       # sorting and indexing the trimmed bams
2022-03-14 09:23:07 [INFO] ADDING_LINE:       # sorting and indexing the trimmed bams
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       samtools sort !{task.process}/!{sample}.primertrim.bam -o !{task.process}/!{sample}.primertrim.sorted.bam 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:       samtools sort !{task.process}/!{sample}.primertrim.bam -o !{task.process}/!{sample}.primertrim.sorted.bam 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       samtools index !{task.process}/!{sample}.primertrim.sorted.bam 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:       samtools index !{task.process}/!{sample}.primertrim.sorted.bam 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS ivar_trim
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: samtools_ampliconclip
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   process samtools_ampliconclip {
2022-03-14 09:23:07 [INFO] ADDING_LINE:   process samtools_ampliconclip {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tag "${sample}"
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tag "${sample}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     cpus 1
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     container 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_LINE:     container 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:     input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: samtools_ampliconclip
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:     input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple val(sample), file(bam), file(primer_bed) from pre_trim_bams.combine(primer_bed)
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple val(sample), file(bam), file(primer_bed) from pre_trim_bams.combine(primer_bed)
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:     output:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple sample, file("${task.process}/${sample}.primertrim.sorted.bam") into trimmed_bams, trimmed_bams4, trimmed_bams5
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple sample, file("${task.process}/${sample}.primertrim.sorted.bam") into trimmed_bams, trimmed_bams4, trimmed_bams5
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple sample, file("${task.process}/${sample}.primertrim.sorted.bam"), file("${task.process}/${sample}.primertrim.sorted.bam.bai") into bam_bai
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple sample, file("${task.process}/${sample}.primertrim.sorted.bam"), file("${task.process}/${sample}.primertrim.sorted.bam.bai") into bam_bai
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tuple sample, env(trimmer_version) into trimmer_version
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tuple sample, env(trimmer_version) into trimmer_version
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:     shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:       mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:07 [INFO] ADDING_LINE:       # time stamp + capturing tool versions
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] ADDING_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       samtools --version >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:       samtools --version >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       trimmer_version="samtools ampliconclip : $(samtools --version | head -n 1)"
2022-03-14 09:23:07 [INFO] ADDING_LINE:       trimmer_version="samtools ampliconclip : $(samtools --version | head -n 1)"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       # trimming the reads
2022-03-14 09:23:07 [INFO] ADDING_LINE:       # trimming the reads
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       samtools ampliconclip !{params.samtools_ampliconclip_options} -b !{primer_bed} !{bam} 2>> $err_file | \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       samtools ampliconclip !{params.samtools_ampliconclip_options} -b !{primer_bed} !{bam} 2>> $err_file | \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         samtools sort 2>> $err_file |  \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         samtools sort 2>> $err_file |  \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         samtools view -F 4 -o !{task.process}/!{sample}.primertrim.sorted.bam 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:         samtools view -F 4 -o !{task.process}/!{sample}.primertrim.sorted.bam 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       samtools index !{task.process}/!{sample}.primertrim.sorted.bam 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:       samtools index !{task.process}/!{sample}.primertrim.sorted.bam 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS samtools_ampliconclip
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: ivar_variants
2022-03-14 09:23:07 [INFO] PROCESS_LINE: process ivar_variants {
2022-03-14 09:23:07 [INFO] ADDING_LINE: process ivar_variants {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   cpus 1
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   container 'staphb/ivar:latest'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   container 'staphb/ivar:latest'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   memory {2.GB * task.attempt}
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   errorStrategy 'retry'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   errorStrategy 'retry'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   maxRetries 2
2022-03-14 09:23:07 [INFO] ADDING_LINE:   maxRetries 2
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: ivar_variants
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/ivar:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   params.ivar_variants
2022-03-14 09:23:07 [INFO] ADDING_LINE:   params.ivar_variants
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: ivar_variants
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/ivar:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple val(sample), file(bam), file(reference_genome), file(gff_file) from trimmed_bams_genome.combine(gff_file)
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple val(sample), file(bam), file(reference_genome), file(gff_file) from trimmed_bams_genome.combine(gff_file)
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple sample, file("${task.process}/${sample}.variants.tsv")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple sample, file("${task.process}/${sample}.variants.tsv")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple sample, file("${task.process}/${sample}.ivar_variants.vcf") into ivar_variant_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple sample, file("${task.process}/${sample}.ivar_variants.vcf") into ivar_variant_file
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple sample, env(variants_num) into ivar_variants_results
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple sample, env(variants_num) into ivar_variants_results
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:07 [INFO] ADDING_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     samtools --version >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:     samtools --version >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     ivar version >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:     ivar version >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     samtools mpileup -A -d !{params.mpileup_depth} -B -Q 0 --reference !{reference_genome} !{bam} 2>> $err_file | \
2022-03-14 09:23:07 [INFO] ADDING_LINE:     samtools mpileup -A -d !{params.mpileup_depth} -B -Q 0 --reference !{reference_genome} !{bam} 2>> $err_file | \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       ivar variants -p !{task.process}/!{sample}.variants !{params.ivar_variants_options} -m !{params.minimum_depth} -r !{reference_genome} -g !{gff_file} 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:       ivar variants -p !{task.process}/!{sample}.variants !{params.ivar_variants_options} -m !{params.minimum_depth} -r !{reference_genome} -g !{gff_file} 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     variants_num=$(grep "TRUE" !{task.process}/!{sample}.variants.tsv | wc -l)
2022-03-14 09:23:07 [INFO] ADDING_LINE:     variants_num=$(grep "TRUE" !{task.process}/!{sample}.variants.tsv | wc -l)
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ -z "$variants_num" ] ; then variants_num="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ -z "$variants_num" ] ; then variants_num="0" ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ -z "$variants_num" ] ; then variants_num="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     echo '##fileformat=VCFv4.2' > !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] ADDING_LINE:     echo '##fileformat=VCFv4.2' > !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     echo '##source=iVar' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] ADDING_LINE:     echo '##source=iVar' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     echo '##INFO=<ID=DP,Number=1,Type=Integer,Description="Total Depth">' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] ADDING_LINE:     echo '##INFO=<ID=DP,Number=1,Type=Integer,Description="Total Depth">' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     echo '##FILTER=<ID=PASS,Description="Result of p-value <= 0.05">' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] ADDING_LINE:     echo '##FILTER=<ID=PASS,Description="Result of p-value <= 0.05">' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     echo '##FILTER=<ID=FAIL,Description="Result of p-value > 0.05">' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] ADDING_LINE:     echo '##FILTER=<ID=FAIL,Description="Result of p-value > 0.05">' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     echo '##FORMAT=<ID=GT,Number=1,Type=String,Description="Genotype">' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] ADDING_LINE:     echo '##FORMAT=<ID=GT,Number=1,Type=String,Description="Genotype">' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     echo '##FORMAT=<ID=REF_DP,Number=1,Type=Integer,Description="Depth of reference base">' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] ADDING_LINE:     echo '##FORMAT=<ID=REF_DP,Number=1,Type=Integer,Description="Depth of reference base">' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     echo '##FORMAT=<ID=REF_RV,Number=1,Type=Integer,Description="Depth of reference base on reverse reads">' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] ADDING_LINE:     echo '##FORMAT=<ID=REF_RV,Number=1,Type=Integer,Description="Depth of reference base on reverse reads">' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     echo '##FORMAT=<ID=REF_QUAL,Number=1,Type=Integer,Description="Mean quality of reference base">' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] ADDING_LINE:     echo '##FORMAT=<ID=REF_QUAL,Number=1,Type=Integer,Description="Mean quality of reference base">' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     echo '##FORMAT=<ID=ALT_DP,Number=1,Type=Integer,Description="Depth of alternate base">' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] ADDING_LINE:     echo '##FORMAT=<ID=ALT_DP,Number=1,Type=Integer,Description="Depth of alternate base">' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     echo '##FORMAT=<ID=ALT_RV,Number=1,Type=Integer,Description="Deapth of alternate base on reverse reads">' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] ADDING_LINE:     echo '##FORMAT=<ID=ALT_RV,Number=1,Type=Integer,Description="Deapth of alternate base on reverse reads">' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     echo '##FORMAT=<ID=ALT_QUAL,Number=1,Type=String,Description="Mean quality of alternate base">' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] ADDING_LINE:     echo '##FORMAT=<ID=ALT_QUAL,Number=1,Type=String,Description="Mean quality of alternate base">' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     echo '##FORMAT=<ID=ALT_FREQ,Number=1,Type=String,Description="Frequency of alternate base">' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] ADDING_LINE:     echo '##FORMAT=<ID=ALT_FREQ,Number=1,Type=String,Description="Frequency of alternate base">' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     echo -e '#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\t!{sample}' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] ADDING_LINE:     echo -e '#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\t!{sample}' >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     tail -n+2 !{task.process}/!{sample}.variants.tsv | \
2022-03-14 09:23:07 [INFO] ADDING_LINE:     tail -n+2 !{task.process}/!{sample}.variants.tsv | \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       awk '{print $1 "\t" $2 "\t.\t" $3 "\t" $4 "\t.\t.\tREF_DP=" $5 ";REF_RV=" $6 ";REF_QUAL=" $7 ";ALT_DP=" $8 ";ALT_RV=" $9 ";ALT_QUAL=" $10 "\tGT:PL\t1/1:" $12 "," $12-$8 "," $8 }' \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       awk '{print $1 "\t" $2 "\t.\t" $3 "\t" $4 "\t.\t.\tREF_DP=" $5 ";REF_RV=" $6 ";REF_QUAL=" $7 ";ALT_DP=" $8 ";ALT_RV=" $9 ";ALT_QUAL=" $10 "\tGT:PL\t1/1:" $12 "," $12-$8 "," $8 }' \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] ADDING_LINE:       >> !{task.process}/!{sample}.ivar_variants.vcf
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE: }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS ivar_variants
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: ivar_consensus
2022-03-14 09:23:07 [INFO] PROCESS_LINE: process ivar_consensus {
2022-03-14 09:23:07 [INFO] ADDING_LINE: process ivar_consensus {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy', pattern: "logs/ivar_consensus/*.{log,err}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy', pattern: "consensus/*.consensus.fa"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   cpus 1
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   container 'staphb/ivar:latest'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   container 'staphb/ivar:latest'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   memory {2.GB * task.attempt}
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   errorStrategy {'retry'}
2022-03-14 09:23:07 [INFO] ADDING_LINE:   errorStrategy {'retry'}
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   maxRetries 2
2022-03-14 09:23:07 [INFO] ADDING_LINE:   maxRetries 2
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: ivar_consensus
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/ivar:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple val(sample), file(bam), file(reference_genome) from trimmed_bams_ivar_consensus
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple val(sample), file(bam), file(reference_genome) from trimmed_bams_ivar_consensus
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple sample, file("consensus/${sample}.consensus.fa") into consensus_rename
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple sample, file("consensus/${sample}.consensus.fa") into consensus_rename
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("consensus/${sample}.consensus.fa") into consensus_pangolin, consensus_vadr, consensus_nextclade, consensus_msa
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("consensus/${sample}.consensus.fa") into consensus_pangolin, consensus_vadr, consensus_nextclade, consensus_msa
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("consensus/${sample}.consensus.qual.txt")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("consensus/${sample}.consensus.qual.txt")
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple sample, env(num_N), env(num_ACTG), env(num_degenerate), env(num_total), env(first_line) into consensus_results
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple sample, env(num_N), env(num_ACTG), env(num_degenerate), env(num_total), env(first_line) into consensus_results
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple sample, env(ivar_version) into ivar_version
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple sample, env(ivar_version) into ivar_version
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     mkdir -p consensus logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:     mkdir -p consensus logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     samtools --version >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:     samtools --version >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     ivar version >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:     ivar version >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     ivar_version=$(ivar version | grep "version")
2022-03-14 09:23:07 [INFO] ADDING_LINE:     ivar_version=$(ivar version | grep "version")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     samtools mpileup -A -d !{params.mpileup_depth} -B -Q 0 --reference !{reference_genome} !{bam} 2>> $err_file | \
2022-03-14 09:23:07 [INFO] ADDING_LINE:     samtools mpileup -A -d !{params.mpileup_depth} -B -Q 0 --reference !{reference_genome} !{bam} 2>> $err_file | \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       ivar consensus !{params.ivar_consensus_options} -m !{params.minimum_depth} -p consensus/!{sample}.consensus 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:       ivar consensus !{params.ivar_consensus_options} -m !{params.minimum_depth} -p consensus/!{sample}.consensus 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ -f "consensus/!{sample}.consensus.fa" ]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ -f "consensus/!{sample}.consensus.fa" ]
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ -f "consensus/!{sample}.consensus.fa" ]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:07 [INFO] ADDING_LINE:     then
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       num_N=$(grep -v ">" consensus/!{sample}.consensus.fa | grep -o 'N' | wc -l )
2022-03-14 09:23:07 [INFO] ADDING_LINE:       num_N=$(grep -v ">" consensus/!{sample}.consensus.fa | grep -o 'N' | wc -l )
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       num_ACTG=$(grep -v ">" consensus/!{sample}.consensus.fa | grep -o -E "C|A|T|G" | wc -l )
2022-03-14 09:23:07 [INFO] ADDING_LINE:       num_ACTG=$(grep -v ">" consensus/!{sample}.consensus.fa | grep -o -E "C|A|T|G" | wc -l )
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       num_degenerate=$(grep -v ">" consensus/!{sample}.consensus.fa | grep -o -E "B|D|E|F|H|I|J|K|L|M|O|P|Q|R|S|U|V|W|X|Y|Z" | wc -l )
2022-03-14 09:23:07 [INFO] ADDING_LINE:       num_degenerate=$(grep -v ">" consensus/!{sample}.consensus.fa | grep -o -E "B|D|E|F|H|I|J|K|L|M|O|P|Q|R|S|U|V|W|X|Y|Z" | wc -l )
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       first_line=$(grep ">" consensus/!{sample}.consensus.fa | sed 's/>//g' )
2022-03-14 09:23:07 [INFO] ADDING_LINE:       first_line=$(grep ">" consensus/!{sample}.consensus.fa | sed 's/>//g' )
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:       if [ -z "$num_N" ] ; then num_N="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       if [ -z "$num_N" ] ; then num_N="0" ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:       if [ -z "$num_N" ] ; then num_N="0" ; fi
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:       if [ -z "$num_ACTG" ] ; then num_ACTG="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       if [ -z "$num_ACTG" ] ; then num_ACTG="0" ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:       if [ -z "$num_ACTG" ] ; then num_ACTG="0" ; fi
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:       if [ -z "$num_degenerate" ] ; then num_degenerate="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       if [ -z "$num_degenerate" ] ; then num_degenerate="0" ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:       if [ -z "$num_degenerate" ] ; then num_degenerate="0" ; fi
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:       if [ -z "$first_line" ] ; then first_line=!{sample} ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       if [ -z "$first_line" ] ; then first_line=!{sample} ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:       if [ -z "$first_line" ] ; then first_line=!{sample} ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     else
2022-03-14 09:23:07 [INFO] ADDING_LINE:     else
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       num_N="0"
2022-03-14 09:23:07 [INFO] ADDING_LINE:       num_N="0"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       num_ACTG="0"
2022-03-14 09:23:07 [INFO] ADDING_LINE:       num_ACTG="0"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       num_degenerate="0"
2022-03-14 09:23:07 [INFO] ADDING_LINE:       num_degenerate="0"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       first_line=!{sample}
2022-03-14 09:23:07 [INFO] ADDING_LINE:       first_line=!{sample}
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ -z "$num_N" ] ; then num_N="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ -z "$num_N" ] ; then num_N="0" ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ -z "$num_N" ] ; then num_N="0" ; fi
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ -z "$num_ACTG" ] ; then num_ACTG="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ -z "$num_ACTG" ] ; then num_ACTG="0" ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ -z "$num_ACTG" ] ; then num_ACTG="0" ; fi
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ -z "$num_degenerate" ] ; then num_degenerate="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ -z "$num_degenerate" ] ; then num_degenerate="0" ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ -z "$num_degenerate" ] ; then num_degenerate="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     num_total=$(( $num_N + $num_degenerate + $num_ACTG ))
2022-03-14 09:23:07 [INFO] ADDING_LINE:     num_total=$(( $num_N + $num_degenerate + $num_ACTG ))
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE: }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS ivar_consensus
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: fasta_prep
2022-03-14 09:23:07 [INFO] PROCESS_LINE: process fasta_prep {
2022-03-14 09:23:07 [INFO] ADDING_LINE: process fasta_prep {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy', overwrite: true
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tag "${fasta}"
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tag "${fasta}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   cpus 1
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   container 'quay.io/biocontainers/pandas:1.1.5'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   container 'quay.io/biocontainers/pandas:1.1.5'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: fasta_prep
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'quay.io/biocontainers/pandas:1.1.5'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   sample != null && sample != 'input.1'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   sample != null && sample != 'input.1'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: fasta_prep
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'quay.io/biocontainers/pandas:1.1.5'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple val(sample), file(fasta) from fastas
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple val(sample), file(fasta) from fastas
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple sample, env(num_N), env(num_ACTG), env(num_degenerate), env(num_total), env(first_line) into fastas_results
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple sample, env(num_N), env(num_ACTG), env(num_degenerate), env(num_total), env(first_line) into fastas_results
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("${task.process}/${fasta}") optional true into fastas_rename, fastas_pangolin, fastas_vadr, fastas_nextclade, fastas_msa
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("${task.process}/${fasta}") optional true into fastas_rename, fastas_pangolin, fastas_vadr, fastas_nextclade, fastas_msa
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ !{fasta} != 'null' ]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ !{fasta} != 'null' ]
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ !{fasta} != 'null' ]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:07 [INFO] ADDING_LINE:     then
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       echo ">!{sample}" > !{task.process}/!{fasta}
2022-03-14 09:23:07 [INFO] ADDING_LINE:       echo ">!{sample}" > !{task.process}/!{fasta}
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       grep -v ">" !{fasta} | fold -w 75 >> !{task.process}/!{fasta}
2022-03-14 09:23:07 [INFO] ADDING_LINE:       grep -v ">" !{fasta} | fold -w 75 >> !{task.process}/!{fasta}
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       num_N=$(grep -v ">" !{fasta} | grep -o 'N' | wc -l )
2022-03-14 09:23:07 [INFO] ADDING_LINE:       num_N=$(grep -v ">" !{fasta} | grep -o 'N' | wc -l )
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       num_ACTG=$(grep -v ">" !{fasta} | grep -o -E "C|A|T|G" | wc -l )
2022-03-14 09:23:07 [INFO] ADDING_LINE:       num_ACTG=$(grep -v ">" !{fasta} | grep -o -E "C|A|T|G" | wc -l )
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       num_degenerate=$(grep -v ">" !{fasta} | grep -o -E "B|D|E|F|H|I|J|K|L|M|O|P|Q|R|S|U|V|W|X|Y|Z" | wc -l )
2022-03-14 09:23:07 [INFO] ADDING_LINE:       num_degenerate=$(grep -v ">" !{fasta} | grep -o -E "B|D|E|F|H|I|J|K|L|M|O|P|Q|R|S|U|V|W|X|Y|Z" | wc -l )
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       first_line=$(grep ">" consensus/!{sample}.consensus.fa | sed 's/>//g' )
2022-03-14 09:23:07 [INFO] ADDING_LINE:       first_line=$(grep ">" consensus/!{sample}.consensus.fa | sed 's/>//g' )
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       num_total=$(( $num_N + $num_degenerate + $num_ACTG ))
2022-03-14 09:23:07 [INFO] ADDING_LINE:       num_total=$(( $num_N + $num_degenerate + $num_ACTG ))
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:       if [ -z "$num_N" ] ; then num_N="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       if [ -z "$num_N" ] ; then num_N="0" ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:       if [ -z "$num_N" ] ; then num_N="0" ; fi
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:       if [ -z "$num_ACTG" ] ; then num_ACTG="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       if [ -z "$num_ACTG" ] ; then num_ACTG="0" ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:       if [ -z "$num_ACTG" ] ; then num_ACTG="0" ; fi
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:       if [ -z "$num_degenerate" ] ; then num_degenerate="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       if [ -z "$num_degenerate" ] ; then num_degenerate="0" ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:       if [ -z "$num_degenerate" ] ; then num_degenerate="0" ; fi
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:       if [ -z "$first_line" ] ; then first_line=!{sample} ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       if [ -z "$first_line" ] ; then first_line=!{sample} ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:       if [ -z "$first_line" ] ; then first_line=!{sample} ; fi
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:       if [ -z "$num_total" ] ; then num_total=0 ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       if [ -z "$num_total" ] ; then num_total=0 ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:       if [ -z "$num_total" ] ; then num_total=0 ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE: }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS fasta_prep
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: bcftools_variants
2022-03-14 09:23:07 [INFO] PROCESS_LINE: process bcftools_variants {
2022-03-14 09:23:07 [INFO] ADDING_LINE: process bcftools_variants {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   cpus 1
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   container 'staphb/bcftools:latest'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   container 'staphb/bcftools:latest'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: bcftools_variants
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/bcftools:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   params.bcftools_variants
2022-03-14 09:23:07 [INFO] ADDING_LINE:   params.bcftools_variants
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: bcftools_variants
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/bcftools:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple val(sample), file(bam), file(reference_genome) from trimmed_bams_bcftools_variants
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple val(sample), file(bam), file(reference_genome) from trimmed_bams_bcftools_variants
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple sample, file("${task.process}/${sample}.vcf") into bcftools_variants_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple sample, file("${task.process}/${sample}.vcf") into bcftools_variants_file
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple sample, env(variants_num) into bcftools_variants_results
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple sample, env(variants_num) into bcftools_variants_results
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:07 [INFO] ADDING_LINE:     # time stamp + capturing tool versions
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     bcftools --version >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:     bcftools --version >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     bcftools mpileup -A -d !{params.mpileup_depth} -B -Q 0 -f !{reference_genome} !{bam} 2>> $err_file | \
2022-03-14 09:23:07 [INFO] ADDING_LINE:     bcftools mpileup -A -d !{params.mpileup_depth} -B -Q 0 -f !{reference_genome} !{bam} 2>> $err_file | \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       bcftools call -mv -Ov -o !{task.process}/!{sample}.vcf 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:       bcftools call -mv -Ov -o !{task.process}/!{sample}.vcf 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     variants_num=$(grep -v "#" bcftools_variants/!{sample}.vcf | wc -l)
2022-03-14 09:23:07 [INFO] ADDING_LINE:     variants_num=$(grep -v "#" bcftools_variants/!{sample}.vcf | wc -l)
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ -z "$variants_num" ] ; then variants_num="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ -z "$variants_num" ] ; then variants_num="0" ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ -z "$variants_num" ] ; then variants_num="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE: }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS bcftools_variants
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: bamsnap
2022-03-14 09:23:07 [INFO] PROCESS_LINE: process bamsnap {
2022-03-14 09:23:07 [INFO] ADDING_LINE: process bamsnap {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   cpus params.medcpus
2022-03-14 09:23:07 [INFO] INITIAL_LINE:   cpus params.medcpus
2022-03-14 09:23:07 [INFO] TRANSLATED_LINE:   cpus 4
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   container 'danielmsk/bamsnap:latest'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   container 'danielmsk/bamsnap:latest'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   time '1h'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   time '1h'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: bamsnap
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 4 MEM  CONTAINER 'danielmsk/bamsnap:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   params.bamsnap
2022-03-14 09:23:07 [INFO] ADDING_LINE:   params.bamsnap
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: bamsnap
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 4 MEM  CONTAINER 'danielmsk/bamsnap:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple val(sample), file(bam), file(bai), file(ivar), file(bcftools), file(reference_genome) from bamsnap_files
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple val(sample), file(bam), file(bai), file(ivar), file(bcftools), file(reference_genome) from bamsnap_files
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("${task.process}/${sample}/{ivar,bcftools}/*.{png,log}") optional true
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("${task.process}/${sample}/{ivar,bcftools}/*.{png,log}") optional true
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("${task.process}/${sample}/*.{png,log}") optional true
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("${task.process}/${sample}/*.{png,log}") optional true
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     mkdir -p logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:     mkdir -p logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     bamsnap --version >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:     bamsnap --version >> $log_file
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [[ "!{ivar}" != *"input"* ]]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [[ "!{ivar}" != *"input"* ]]
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [[ "!{ivar}" != *"input"* ]]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:07 [INFO] ADDING_LINE:     then
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       mkdir -p bamsnap/!{sample}
2022-03-14 09:23:07 [INFO] ADDING_LINE:       mkdir -p bamsnap/!{sample}
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       bamsnap \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       bamsnap \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         -draw coordinates bamplot coverage base \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         -draw coordinates bamplot coverage base \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         !{params.bamsnap_options} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         !{params.bamsnap_options} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         -process !{task.cpus} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         -process !{task.cpus} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         -ref !{reference_genome} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         -ref !{reference_genome} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         -bam !{bam} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         -bam !{bam} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         -vcf !{ivar} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         -vcf !{ivar} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         -out !{task.process}/!{sample}/ivar \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         -out !{task.process}/!{sample}/ivar \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         -imagetype png \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         -imagetype png \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         -save_image_only 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:         -save_image_only 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [[ "!{bcftools}" != *"input"* ]]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [[ "!{bcftools}" != *"input"* ]]
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [[ "!{bcftools}" != *"input"* ]]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:07 [INFO] ADDING_LINE:     then
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       mkdir -p bamsnap/!{sample}
2022-03-14 09:23:07 [INFO] ADDING_LINE:       mkdir -p bamsnap/!{sample}
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       bamsnap \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       bamsnap \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         -draw coordinates bamplot coverage base \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         -draw coordinates bamplot coverage base \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         !{params.bamsnap_options} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         !{params.bamsnap_options} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         -process !{task.cpus} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         -process !{task.cpus} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         -ref !{reference_genome} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         -ref !{reference_genome} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         -bam !{bam} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         -bam !{bam} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         -vcf !{bcftools} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         -vcf !{bcftools} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         -out !{task.process}/!{sample}/bcftools \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         -out !{task.process}/!{sample}/bcftools \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         -imagetype png \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         -imagetype png \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         -save_image_only 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:         -save_image_only 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE: }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS bamsnap
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: samtools_stats
2022-03-14 09:23:07 [INFO] PROCESS_LINE: process samtools_stats {
2022-03-14 09:23:07 [INFO] ADDING_LINE: process samtools_stats {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   cpus 1
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   container 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   container 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: samtools_stats
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   params.samtools_stats
2022-03-14 09:23:07 [INFO] ADDING_LINE:   params.samtools_stats
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: samtools_stats
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple val(sample), file(aligned), file(trimmed) from pre_post_bams
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple val(sample), file(aligned), file(trimmed) from pre_post_bams
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("${task.process}/aligned/${sample}.stats.txt")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("${task.process}/aligned/${sample}.stats.txt")
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("${task.process}/trimmed/${sample}.stats.trim.txt") optional true
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("${task.process}/trimmed/${sample}.stats.trim.txt") optional true
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple sample, env(insert_size_before_trimming) into samtools_stats_before_size_results
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple sample, env(insert_size_before_trimming) into samtools_stats_before_size_results
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple sample, env(insert_size_after_trimming) into samtools_stats_after_size_results
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple sample, env(insert_size_after_trimming) into samtools_stats_after_size_results
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     mkdir -p !{task.process}/aligned !{task.process}/trimmed logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:     mkdir -p !{task.process}/aligned !{task.process}/trimmed logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     samtools --version >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:     samtools --version >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     samtools stats !{params.samtools_stats_options} !{aligned} 2>> $err_file > !{task.process}/aligned/!{sample}.stats.txt
2022-03-14 09:23:07 [INFO] ADDING_LINE:     samtools stats !{params.samtools_stats_options} !{aligned} 2>> $err_file > !{task.process}/aligned/!{sample}.stats.txt
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ "!{trimmed}" == "null" ] || [[ "!{trimmed}" == *"input"* ]]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ "!{trimmed}" == "null" ] || [[ "!{trimmed}" == *"input"* ]]
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ "!{trimmed}" == "null" ] || [[ "!{trimmed}" == *"input"* ]]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:07 [INFO] ADDING_LINE:     then
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       insert_size_after_trimming="NA"
2022-03-14 09:23:07 [INFO] ADDING_LINE:       insert_size_after_trimming="NA"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     else
2022-03-14 09:23:07 [INFO] ADDING_LINE:     else
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       samtools stats !{params.samtools_stats_options} !{trimmed} 2>> $err_file > !{task.process}/trimmed/!{sample}.stats.trim.txt
2022-03-14 09:23:07 [INFO] ADDING_LINE:       samtools stats !{params.samtools_stats_options} !{trimmed} 2>> $err_file > !{task.process}/trimmed/!{sample}.stats.trim.txt
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       insert_size_after_trimming=$(grep "insert size average" !{task.process}/trimmed/!{sample}.stats.trim.txt | cut -f 3)
2022-03-14 09:23:07 [INFO] ADDING_LINE:       insert_size_after_trimming=$(grep "insert size average" !{task.process}/trimmed/!{sample}.stats.trim.txt | cut -f 3)
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     insert_size_before_trimming=$(grep "insert size average" !{task.process}/aligned/!{sample}.stats.txt | cut -f 3)
2022-03-14 09:23:07 [INFO] ADDING_LINE:     insert_size_before_trimming=$(grep "insert size average" !{task.process}/aligned/!{sample}.stats.txt | cut -f 3)
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ -z "$insert_size_before_trimming" ] ; then insert_size_before_trimming=0 ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ -z "$insert_size_before_trimming" ] ; then insert_size_before_trimming=0 ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ -z "$insert_size_before_trimming" ] ; then insert_size_before_trimming=0 ; fi
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ -z "$insert_size_after_trimming" ] ; then insert_size_after_trimming=0 ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ -z "$insert_size_after_trimming" ] ; then insert_size_after_trimming=0 ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ -z "$insert_size_after_trimming" ] ; then insert_size_after_trimming=0 ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE: }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS samtools_stats
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: samtools_coverage
2022-03-14 09:23:07 [INFO] PROCESS_LINE: process samtools_coverage {
2022-03-14 09:23:07 [INFO] ADDING_LINE: process samtools_coverage {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   cpus 1
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   container 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   container 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: samtools_coverage
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   params.samtools_coverage
2022-03-14 09:23:07 [INFO] ADDING_LINE:   params.samtools_coverage
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: samtools_coverage
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple val(sample), file(aligned), file(trimmed) from pre_post_bams2
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple val(sample), file(aligned), file(trimmed) from pre_post_bams2
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("${task.process}/{aligned,trimmed}/${sample}.cov.{txt,hist}") optional true
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("${task.process}/{aligned,trimmed}/${sample}.cov.{txt,hist}") optional true
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple sample, env(coverage) into samtools_coverage_results
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple sample, env(coverage) into samtools_coverage_results
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple sample, env(depth) into samtools_covdepth_results
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple sample, env(depth) into samtools_covdepth_results
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     mkdir -p !{task.process}/aligned !{task.process}/trimmed logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:     mkdir -p !{task.process}/aligned !{task.process}/trimmed logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     samtools --version >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:     samtools --version >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     samtools coverage !{params.samtools_coverage_options} !{aligned} -m -o !{task.process}/aligned/!{sample}.cov.hist 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:     samtools coverage !{params.samtools_coverage_options} !{aligned} -m -o !{task.process}/aligned/!{sample}.cov.hist 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     samtools coverage !{params.samtools_coverage_options} !{aligned}    -o !{task.process}/aligned/!{sample}.cov.txt 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:     samtools coverage !{params.samtools_coverage_options} !{aligned}    -o !{task.process}/aligned/!{sample}.cov.txt 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ "!{trimmed}" == "null" ] || [[ "!{trimmed}" == *"input"* ]]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ "!{trimmed}" == "null" ] || [[ "!{trimmed}" == *"input"* ]]
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ "!{trimmed}" == "null" ] || [[ "!{trimmed}" == *"input"* ]]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:07 [INFO] ADDING_LINE:     then
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       coverage=$(cut -f 6 !{task.process}/aligned/!{sample}.cov.trim.txt | tail -n 1)
2022-03-14 09:23:07 [INFO] ADDING_LINE:       coverage=$(cut -f 6 !{task.process}/aligned/!{sample}.cov.trim.txt | tail -n 1)
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       depth=$(cut -f 7 !{task.process}/aligned/!{sample}.cov.trim.txt | tail -n 1)
2022-03-14 09:23:07 [INFO] ADDING_LINE:       depth=$(cut -f 7 !{task.process}/aligned/!{sample}.cov.trim.txt | tail -n 1)
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     else
2022-03-14 09:23:07 [INFO] ADDING_LINE:     else
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       samtools coverage !{params.samtools_coverage_options} !{trimmed} -m -o !{task.process}/trimmed/!{sample}.cov.trim.hist 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:       samtools coverage !{params.samtools_coverage_options} !{trimmed} -m -o !{task.process}/trimmed/!{sample}.cov.trim.hist 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       samtools coverage !{params.samtools_coverage_options} !{trimmed}    -o !{task.process}/trimmed/!{sample}.cov.trim.txt 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:       samtools coverage !{params.samtools_coverage_options} !{trimmed}    -o !{task.process}/trimmed/!{sample}.cov.trim.txt 2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       coverage=$(cut -f 6 !{task.process}/trimmed/!{sample}.cov.trim.txt | tail -n 1)
2022-03-14 09:23:07 [INFO] ADDING_LINE:       coverage=$(cut -f 6 !{task.process}/trimmed/!{sample}.cov.trim.txt | tail -n 1)
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       depth=$(cut -f 7 !{task.process}/trimmed/!{sample}.cov.trim.txt | tail -n 1)
2022-03-14 09:23:07 [INFO] ADDING_LINE:       depth=$(cut -f 7 !{task.process}/trimmed/!{sample}.cov.trim.txt | tail -n 1)
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ -z "$coverage" ] ; then coverage="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ -z "$coverage" ] ; then coverage="0" ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ -z "$coverage" ] ; then coverage="0" ; fi
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ -z "$depth" ] ; then depth="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ -z "$depth" ] ; then depth="0" ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ -z "$depth" ] ; then depth="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE: }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS samtools_coverage
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: samtools_flagstat
2022-03-14 09:23:07 [INFO] PROCESS_LINE: process samtools_flagstat {
2022-03-14 09:23:07 [INFO] ADDING_LINE: process samtools_flagstat {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   cpus 1
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   container 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   container 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: samtools_flagstat
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple val(sample), file(aligned), file(trimmed) from pre_post_bams3
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple val(sample), file(aligned), file(trimmed) from pre_post_bams3
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: samtools_flagstat
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   params.samtools_flagstat
2022-03-14 09:23:07 [INFO] ADDING_LINE:   params.samtools_flagstat
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("${task.process}/{aligned,trimmed}/${sample}.flagstat.txt") optional true
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("${task.process}/{aligned,trimmed}/${sample}.flagstat.txt") optional true
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     mkdir -p !{task.process}/aligned !{task.process}/trimmed logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:     mkdir -p !{task.process}/aligned !{task.process}/trimmed logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     samtools --version >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:     samtools --version >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     samtools flagstat !{params.samtools_flagstat_options} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:     samtools flagstat !{params.samtools_flagstat_options} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       !{aligned} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       !{aligned} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       2>> $err_file > !{task.process}/aligned/!{sample}.flagstat.txt
2022-03-14 09:23:07 [INFO] ADDING_LINE:       2>> $err_file > !{task.process}/aligned/!{sample}.flagstat.txt
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ "!{trimmed}" == "null" ] || [[ "!{trimmed}" == *"input"* ]]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ "!{trimmed}" == "null" ] || [[ "!{trimmed}" == *"input"* ]]
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ "!{trimmed}" == "null" ] || [[ "!{trimmed}" == *"input"* ]]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:07 [INFO] ADDING_LINE:     then
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       echo "No trimmed bam"
2022-03-14 09:23:07 [INFO] ADDING_LINE:       echo "No trimmed bam"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     else
2022-03-14 09:23:07 [INFO] ADDING_LINE:     else
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       samtools flagstat !{params.samtools_flagstat_options} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       samtools flagstat !{params.samtools_flagstat_options} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         !{trimmed} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         !{trimmed} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         2>> $err_file > !{task.process}/trimmed/!{sample}.flagstat.txt
2022-03-14 09:23:07 [INFO] ADDING_LINE:         2>> $err_file > !{task.process}/trimmed/!{sample}.flagstat.txt
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE: }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS samtools_flagstat
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: samtools_depth
2022-03-14 09:23:07 [INFO] PROCESS_LINE: process samtools_depth {
2022-03-14 09:23:07 [INFO] ADDING_LINE: process samtools_depth {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   cpus 1
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   container 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   container 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: samtools_depth
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple val(sample), file(aligned), file(trimmed) from pre_post_bams4
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple val(sample), file(aligned), file(trimmed) from pre_post_bams4
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: samtools_depth
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   params.samtools_depth
2022-03-14 09:23:07 [INFO] ADDING_LINE:   params.samtools_depth
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("${task.process}/{aligned,trimmed}/${sample}.depth.txt") optional true
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("${task.process}/{aligned,trimmed}/${sample}.depth.txt") optional true
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple sample, env(depth) into samtools_depth_results
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple sample, env(depth) into samtools_depth_results
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     mkdir -p !{task.process}/aligned !{task.process}/trimmed logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:     mkdir -p !{task.process}/aligned !{task.process}/trimmed logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     samtools --version >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:     samtools --version >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     samtools depth !{params.samtools_depth_options} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:     samtools depth !{params.samtools_depth_options} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       !{aligned} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       !{aligned} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       2>> $err_file > !{task.process}/aligned/!{sample}.depth.txt
2022-03-14 09:23:07 [INFO] ADDING_LINE:       2>> $err_file > !{task.process}/aligned/!{sample}.depth.txt
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ "!{trimmed}" == "null" ] || [[ "!{trimmed}" == *"input"* ]]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ "!{trimmed}" == "null" ] || [[ "!{trimmed}" == *"input"* ]]
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ "!{trimmed}" == "null" ] || [[ "!{trimmed}" == *"input"* ]]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:07 [INFO] ADDING_LINE:     then
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       depth=$(awk '{ if ($3 > !{params.minimum_depth} ) print $0 }' !{task.process}/aligned/!{sample}.depth.txt | wc -l )
2022-03-14 09:23:07 [INFO] ADDING_LINE:       depth=$(awk '{ if ($3 > !{params.minimum_depth} ) print $0 }' !{task.process}/aligned/!{sample}.depth.txt | wc -l )
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     else
2022-03-14 09:23:07 [INFO] ADDING_LINE:     else
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       samtools depth !{params.samtools_depth_options} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       samtools depth !{params.samtools_depth_options} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         !{trimmed} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         !{trimmed} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         2>> $err_file > !{task.process}/trimmed/!{sample}.depth.txt
2022-03-14 09:23:07 [INFO] ADDING_LINE:         2>> $err_file > !{task.process}/trimmed/!{sample}.depth.txt
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       depth=$(awk '{ if ($3 > !{params.minimum_depth} ) print $0 }' !{task.process}/trimmed/!{sample}.depth.txt | wc -l )
2022-03-14 09:23:07 [INFO] ADDING_LINE:       depth=$(awk '{ if ($3 > !{params.minimum_depth} ) print $0 }' !{task.process}/trimmed/!{sample}.depth.txt | wc -l )
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ -z "$depth" ] ; then depth="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ -z "$depth" ] ; then depth="0" ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ -z "$depth" ] ; then depth="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE: }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS samtools_depth
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: kraken2
2022-03-14 09:23:07 [INFO] PROCESS_LINE: process kraken2 {
2022-03-14 09:23:07 [INFO] ADDING_LINE: process kraken2 {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   cpus params.maxcpus
2022-03-14 09:23:07 [INFO] INITIAL_LINE:   cpus params.maxcpus
2022-03-14 09:23:07 [INFO] TRANSLATED_LINE:   cpus 8
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   container 'staphb/kraken2:latest'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   container 'staphb/kraken2:latest'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: kraken2
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 8 MEM  CONTAINER 'staphb/kraken2:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   params.kraken2
2022-03-14 09:23:07 [INFO] ADDING_LINE:   params.kraken2
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: kraken2
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 8 MEM  CONTAINER 'staphb/kraken2:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple val(sample), file(clean), val(paired_single), path(kraken2_db) from paired_files_kraken2.concat(single_files_kraken2).combine(kraken2_db)
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple val(sample), file(clean), val(paired_single), path(kraken2_db) from paired_files_kraken2.concat(single_files_kraken2).combine(kraken2_db)
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("${task.process}/${sample}_kraken2_report.txt")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("${task.process}/${sample}_kraken2_report.txt")
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple sample, env(percentage_cov) into kraken2_sars_results
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple sample, env(percentage_cov) into kraken2_sars_results
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple sample, env(percentage_human) into kraken2_human_results
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple sample, env(percentage_human) into kraken2_human_results
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     kraken2 --version >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:     kraken2 --version >> $log_file
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ ! -d !{kraken2_db} ]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ ! -d !{kraken2_db} ]
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ ! -d !{kraken2_db} ]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:07 [INFO] ADDING_LINE:     then
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       echo "Kraken2 database could not be found. Please specify with params.kraken2_db" | tee -a $err_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:       echo "Kraken2 database could not be found. Please specify with params.kraken2_db" | tee -a $err_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ "!{paired_single}" == "single" ]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ "!{paired_single}" == "single" ]
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ "!{paired_single}" == "single" ]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:07 [INFO] ADDING_LINE:     then
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       kraken2 !{params.kraken2_options} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       kraken2 !{params.kraken2_options} \
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:         --classified-out cseqs#.fq \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         --classified-out cseqs#.fq \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         --classified-out cseqs#.fq \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         --threads !{task.cpus} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         --threads !{task.cpus} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         --db !{kraken2_db} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         --db !{kraken2_db} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         !{clean} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         !{clean} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         --report !{task.process}/!{sample}_kraken2_report.txt \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         --report !{task.process}/!{sample}_kraken2_report.txt \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:         2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     else
2022-03-14 09:23:07 [INFO] ADDING_LINE:     else
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       kraken2 !{params.kraken2_options} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       kraken2 !{params.kraken2_options} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         --paired \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         --paired \
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:         --classified-out cseqs#.fq \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         --classified-out cseqs#.fq \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         --classified-out cseqs#.fq \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         --threads !{task.cpus} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         --threads !{task.cpus} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         --db !{kraken2_db} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         --db !{kraken2_db} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         !{clean} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         !{clean} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         --report !{task.process}/!{sample}_kraken2_report.txt \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         --report !{task.process}/!{sample}_kraken2_report.txt \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:         2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     percentage_human=$(grep "Homo sapiens" !{task.process}/!{sample}_kraken2_report.txt | awk '{print $1}')
2022-03-14 09:23:07 [INFO] ADDING_LINE:     percentage_human=$(grep "Homo sapiens" !{task.process}/!{sample}_kraken2_report.txt | awk '{print $1}')
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     percentage_cov=$(grep "!{params.kraken2_organism}" !{task.process}/!{sample}_kraken2_report.txt | awk '{print $1}')
2022-03-14 09:23:07 [INFO] ADDING_LINE:     percentage_cov=$(grep "!{params.kraken2_organism}" !{task.process}/!{sample}_kraken2_report.txt | awk '{print $1}')
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ -z "$percentage_human" ] ; then percentage_human="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ -z "$percentage_human" ] ; then percentage_human="0" ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ -z "$percentage_human" ] ; then percentage_human="0" ; fi
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ -z "$percentage_cov" ] ; then percentage_cov="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ -z "$percentage_cov" ] ; then percentage_cov="0" ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ -z "$percentage_cov" ] ; then percentage_cov="0" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE: }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS kraken2
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: bedtools_multicov
2022-03-14 09:23:07 [INFO] PROCESS_LINE: process bedtools_multicov {
2022-03-14 09:23:07 [INFO] ADDING_LINE: process bedtools_multicov {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   cpus 1
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   container 'staphb/bedtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   container 'staphb/bedtools:latest'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: bedtools_multicov
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/bedtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   params.bedtools_multicov
2022-03-14 09:23:07 [INFO] ADDING_LINE:   params.bedtools_multicov
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: bedtools_multicov
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/bedtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple val(sample), file(bam), file(bai), file(amplicon_bed) from bam_bai.combine(amplicon_bed)
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple val(sample), file(bam), file(bai), file(amplicon_bed) from bam_bai.combine(amplicon_bed)
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("${task.process}/${sample}.multicov.txt")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("${task.process}/${sample}.multicov.txt")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple sample, env(num_failed_amplicons) into bedtools_results
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple sample, env(num_failed_amplicons) into bedtools_results
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     bedtools --version >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:     bedtools --version >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     bedtools multicov !{params.bedtools_multicov_options} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:     bedtools multicov !{params.bedtools_multicov_options} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       -bams !{bam} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       -bams !{bam} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       -bed !{amplicon_bed} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       -bed !{amplicon_bed} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       2>> $err_file >> !{task.process}/!{sample}.multicov.txt
2022-03-14 09:23:07 [INFO] ADDING_LINE:       2>> $err_file >> !{task.process}/!{sample}.multicov.txt
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     result_column=$(head -n 1 !{task.process}/!{sample}.multicov.txt | awk '{print NF}' )
2022-03-14 09:23:07 [INFO] ADDING_LINE:     result_column=$(head -n 1 !{task.process}/!{sample}.multicov.txt | awk '{print NF}' )
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     num_failed_amplicons=$(cat !{task.process}/!{sample}.multicov.txt | tr ' ' '\t' | cut -f $result_column | awk '{ if ( $1 < 20 ) print $0 }' | wc -l )
2022-03-14 09:23:07 [INFO] ADDING_LINE:     num_failed_amplicons=$(cat !{task.process}/!{sample}.multicov.txt | tr ' ' '\t' | cut -f $result_column | awk '{ if ( $1 < 20 ) print $0 }' | wc -l )
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ -z "$num_failed_amplicons" ] ; then num_failed_amplicons="NA" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ -z "$num_failed_amplicons" ] ; then num_failed_amplicons="NA" ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ -z "$num_failed_amplicons" ] ; then num_failed_amplicons="NA" ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE: }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS bedtools_multicov
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: samtools_ampliconstats
2022-03-14 09:23:07 [INFO] PROCESS_LINE: process samtools_ampliconstats {
2022-03-14 09:23:07 [INFO] ADDING_LINE: process samtools_ampliconstats {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   cpus 1
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   container 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   container 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: samtools_ampliconstats
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   params.samtools_ampliconstats
2022-03-14 09:23:07 [INFO] ADDING_LINE:   params.samtools_ampliconstats
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: samtools_ampliconstats
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple val(sample), file(bam), file(primer_bed) from trimmed_bams5.combine(primer_bed_ampliconstats)
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple val(sample), file(bam), file(primer_bed) from trimmed_bams5.combine(primer_bed_ampliconstats)
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple sample, file("${task.process}/${sample}_ampliconstats.txt") into samtools_ampliconstats_files
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple sample, file("${task.process}/${sample}_ampliconstats.txt") into samtools_ampliconstats_files
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple sample, env(num_failed_amplicons) into samtools_ampliconstats_results
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple sample, env(num_failed_amplicons) into samtools_ampliconstats_results
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     samtools --version >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:     samtools --version >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     samtools ampliconstats !{params.samtools_ampliconstats_options} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:     samtools ampliconstats !{params.samtools_ampliconstats_options} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       !{primer_bed} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       !{primer_bed} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       !{bam} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       !{bam} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       2>> $err_file > !{task.process}/!{sample}_ampliconstats.txt
2022-03-14 09:23:07 [INFO] ADDING_LINE:       2>> $err_file > !{task.process}/!{sample}_ampliconstats.txt
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     num_failed_amplicons=$(grep ^FREADS !{task.process}/!{sample}_ampliconstats.txt | cut -f 2- | tr '\t' '\n' | awk '{ if ($1 < 20) print $0 }' | wc -l)
2022-03-14 09:23:07 [INFO] ADDING_LINE:     num_failed_amplicons=$(grep ^FREADS !{task.process}/!{sample}_ampliconstats.txt | cut -f 2- | tr '\t' '\n' | awk '{ if ($1 < 20) print $0 }' | wc -l)
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ -z "$num_failed_amplicons" ] ; then num_failed_amplicons=0 ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ -z "$num_failed_amplicons" ] ; then num_failed_amplicons=0 ; fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ -z "$num_failed_amplicons" ] ; then num_failed_amplicons=0 ; fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE: }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS samtools_ampliconstats
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: samtools_plot_ampliconstats
2022-03-14 09:23:07 [INFO] PROCESS_LINE: process samtools_plot_ampliconstats {
2022-03-14 09:23:07 [INFO] ADDING_LINE: process samtools_plot_ampliconstats {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   cpus 1
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   container 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   container 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: samtools_plot_ampliconstats
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   params.samtools_plot_ampliconstats
2022-03-14 09:23:07 [INFO] ADDING_LINE:   params.samtools_plot_ampliconstats
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: samtools_plot_ampliconstats
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'staphb/samtools:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple val(sample), file(ampliconstats) from samtools_ampliconstats_files
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple val(sample), file(ampliconstats) from samtools_ampliconstats_files
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("${task.process}/${sample}*")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("${task.process}/${sample}*")
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     mkdir -p !{task.process}/!{sample} logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:     mkdir -p !{task.process}/!{sample} logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     samtools --version >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:     samtools --version >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     plot-ampliconstats !{params.samtools_plot_ampliconstats_options} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:     plot-ampliconstats !{params.samtools_plot_ampliconstats_options} \
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:       !{task.process}/!{sample} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       !{task.process}/!{sample} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       !{ampliconstats}
2022-03-14 09:23:07 [INFO] ADDING_LINE:       !{ampliconstats}
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE: }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS samtools_plot_ampliconstats
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: pangolin
2022-03-14 09:23:07 [INFO] PROCESS_LINE: process pangolin {
2022-03-14 09:23:07 [INFO] ADDING_LINE: process pangolin {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tag "SARS-CoV-2 lineage Determination"
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tag "SARS-CoV-2 lineage Determination"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   cpus params.medcpus
2022-03-14 09:23:07 [INFO] INITIAL_LINE:   cpus params.medcpus
2022-03-14 09:23:07 [INFO] TRANSLATED_LINE:   cpus 4
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   container 'staphb/pangolin:latest'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   container 'staphb/pangolin:latest'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   stageInMode 'copy'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   stageInMode 'copy'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: pangolin
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 4 MEM  CONTAINER 'staphb/pangolin:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   params.pangolin
2022-03-14 09:23:07 [INFO] ADDING_LINE:   params.pangolin
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: pangolin
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 4 MEM  CONTAINER 'staphb/pangolin:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   file(fasta) from consensus_pangolin.concat(fastas_pangolin).concat(multifastas_pangolin).collect()
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file(fasta) from consensus_pangolin.concat(fastas_pangolin).concat(multifastas_pangolin).collect()
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("${task.process}/*")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("${task.process}/*")
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("${task.process}/lineage_report.csv") into pangolin_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("${task.process}/lineage_report.csv") into pangolin_file
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     pangolin --all-versions >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:     pangolin --all-versions >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     for fasta in !{fasta}
2022-03-14 09:23:07 [INFO] ADDING_LINE:     for fasta in !{fasta}
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     do
2022-03-14 09:23:07 [INFO] ADDING_LINE:     do
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       cat $fasta >> ultimate_fasta.fasta
2022-03-14 09:23:07 [INFO] ADDING_LINE:       cat $fasta >> ultimate_fasta.fasta
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     done
2022-03-14 09:23:07 [INFO] ADDING_LINE:     done
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     pangolin !{params.pangolin_options} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:     pangolin !{params.pangolin_options} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       --threads !{task.cpus} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       --threads !{task.cpus} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       --outdir !{task.process} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       --outdir !{task.process} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       ultimate_fasta.fasta \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       ultimate_fasta.fasta \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:       2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     cp ultimate_fasta.fasta !{task.process}/combined.fasta
2022-03-14 09:23:07 [INFO] ADDING_LINE:     cp ultimate_fasta.fasta !{task.process}/combined.fasta
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE: }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS pangolin
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: nextclade
2022-03-14 09:23:07 [INFO] PROCESS_LINE: process nextclade {
2022-03-14 09:23:07 [INFO] ADDING_LINE: process nextclade {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tag "Clade Determination"
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tag "Clade Determination"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   cpus params.medcpus
2022-03-14 09:23:07 [INFO] INITIAL_LINE:   cpus params.medcpus
2022-03-14 09:23:07 [INFO] TRANSLATED_LINE:   cpus 4
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   container 'nextstrain/nextclade:latest'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   container 'nextstrain/nextclade:latest'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: nextclade
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 4 MEM  CONTAINER 'nextstrain/nextclade:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   params.nextclade || params.msa == 'nextalign'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   params.nextclade || params.msa == 'nextalign'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: nextclade
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 4 MEM  CONTAINER 'nextstrain/nextclade:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   file(fasta) from consensus_nextclade.concat(fastas_nextclade).concat(multifastas_nextclade).collect()
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file(fasta) from consensus_nextclade.concat(fastas_nextclade).concat(multifastas_nextclade).collect()
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("${task.process}/nextclade.csv") into nextclade_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("${task.process}/nextclade.csv") into nextclade_file
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("${task.process}/*")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("${task.process}/*")
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("${task.process}/nextclade.aligned.fasta") into nextclade_aligned_fasta
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("${task.process}/nextclade.aligned.fasta") into nextclade_aligned_fasta
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   path("dataset") into prepped_nextalign
2022-03-14 09:23:07 [INFO] ADDING_LINE:   path("dataset") into prepped_nextalign
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     mkdir -p !{task.process} dataset logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:     mkdir -p !{task.process} dataset logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     nextclade --version >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:     nextclade --version >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     nextclade_version=$(nextclade --version)
2022-03-14 09:23:07 [INFO] ADDING_LINE:     nextclade_version=$(nextclade --version)
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     nextclade dataset get --name !{params.nextclade_dataset} --output-dir dataset
2022-03-14 09:23:07 [INFO] ADDING_LINE:     nextclade dataset get --name !{params.nextclade_dataset} --output-dir dataset
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     for fasta in !{fasta}
2022-03-14 09:23:07 [INFO] ADDING_LINE:     for fasta in !{fasta}
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     do
2022-03-14 09:23:07 [INFO] ADDING_LINE:     do
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       cat $fasta >> ultimate_fasta.fasta
2022-03-14 09:23:07 [INFO] ADDING_LINE:       cat $fasta >> ultimate_fasta.fasta
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     done
2022-03-14 09:23:07 [INFO] ADDING_LINE:     done
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     nextclade !{params.nextclade_options} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:     nextclade !{params.nextclade_options} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       --input-fasta=ultimate_fasta.fasta \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       --input-fasta=ultimate_fasta.fasta \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       --input-dataset dataset \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       --input-dataset dataset \
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:       --output-json=!{task.process}/nextclade.json \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       --output-json=!{task.process}/nextclade.json \
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:       --output-csv=!{task.process}/nextclade.csv \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       --output-csv=!{task.process}/nextclade.csv \
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:       --output-tsv=!{task.process}/nextclade.tsv \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       --output-tsv=!{task.process}/nextclade.tsv \
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:       --output-tree=!{task.process}/nextclade.auspice.json \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       --output-tree=!{task.process}/nextclade.auspice.json \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       --output-dir=!{task.process} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       --output-dir=!{task.process} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       --output-basename=nextclade \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       --output-basename=nextclade \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:       2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     cp ultimate_fasta.fasta !{task.process}/combined.fasta
2022-03-14 09:23:07 [INFO] ADDING_LINE:     cp ultimate_fasta.fasta !{task.process}/combined.fasta
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE: }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS nextclade
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: vadr
2022-03-14 09:23:07 [INFO] PROCESS_LINE: process vadr {
2022-03-14 09:23:07 [INFO] ADDING_LINE: process vadr {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tag "QC metrics"
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tag "QC metrics"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   cpus params.medcpus
2022-03-14 09:23:07 [INFO] INITIAL_LINE:   cpus params.medcpus
2022-03-14 09:23:07 [INFO] TRANSLATED_LINE:   cpus 4
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   container 'staphb/vadr:latest'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   container 'staphb/vadr:latest'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: vadr
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 4 MEM  CONTAINER 'staphb/vadr:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   params.vadr
2022-03-14 09:23:07 [INFO] ADDING_LINE:   params.vadr
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: vadr
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 4 MEM  CONTAINER 'staphb/vadr:latest'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   file(fasta) from consensus_vadr.concat(fastas_vadr).concat(multifastas_vadr).collect()
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file(fasta) from consensus_vadr.concat(fastas_vadr).concat(multifastas_vadr).collect()
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("${task.process}/*") optional true
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("${task.process}/*") optional true
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("${task.process}/vadr.vadr.sqa") optional true into vadr_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("${task.process}/vadr.vadr.sqa") optional true into vadr_file
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     mkdir -p logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:     mkdir -p logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     echo "no version" >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:     echo "no version" >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     v-annotate.pl -h >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:     v-annotate.pl -h >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     for fasta in !{fasta}
2022-03-14 09:23:07 [INFO] ADDING_LINE:     for fasta in !{fasta}
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     do
2022-03-14 09:23:07 [INFO] ADDING_LINE:     do
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       cat $fasta >> ultimate_fasta.fasta
2022-03-14 09:23:07 [INFO] ADDING_LINE:       cat $fasta >> ultimate_fasta.fasta
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     done
2022-03-14 09:23:07 [INFO] ADDING_LINE:     done
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     fasta-trim-terminal-ambigs.pl !{params.vadr_trim_options} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:     fasta-trim-terminal-ambigs.pl !{params.vadr_trim_options} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       ultimate_fasta.fasta > trimmed_ultimate_fasta.fasta
2022-03-14 09:23:07 [INFO] ADDING_LINE:       ultimate_fasta.fasta > trimmed_ultimate_fasta.fasta
2022-03-14 09:23:07 [INFO] EXPRESSION_LINE:     if [ -s "trimmed_ultimate_fasta.fasta" ]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     if [ -s "trimmed_ultimate_fasta.fasta" ]
2022-03-14 09:23:07 [INFO] ADDING_LINE:     if [ -s "trimmed_ultimate_fasta.fasta" ]
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:07 [INFO] ADDING_LINE:     then
2022-03-14 09:23:07 [INFO] PROCESS_LINE:       v-annotate.pl !{params.vadr_options} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:       v-annotate.pl !{params.vadr_options} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         --cpu !{task.cpus} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         --cpu !{task.cpus} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         --noseqnamemax \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         --noseqnamemax \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         --mkey !{params.vadr_reference} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         --mkey !{params.vadr_reference} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         --mdir !{params.vadr_mdir} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         --mdir !{params.vadr_mdir} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         trimmed_ultimate_fasta.fasta \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         trimmed_ultimate_fasta.fasta \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         !{task.process} \
2022-03-14 09:23:07 [INFO] ADDING_LINE:         !{task.process} \
2022-03-14 09:23:07 [INFO] PROCESS_LINE:         2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] ADDING_LINE:         2>> $err_file >> $log_file
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:07 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     cp ultimate_fasta.fasta !{task.process}/combined.fasta
2022-03-14 09:23:07 [INFO] ADDING_LINE:     cp ultimate_fasta.fasta !{task.process}/combined.fasta
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     cp trimmed_ultimate_fasta.fasta !{task.process}/trimmed.fasta
2022-03-14 09:23:07 [INFO] ADDING_LINE:     cp trimmed_ultimate_fasta.fasta !{task.process}/trimmed.fasta
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE: }
2022-03-14 09:23:07 [INFO] UPDATING_PROCESS vadr
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_NAME: summary
2022-03-14 09:23:07 [INFO] PROCESS_LINE: process summary {
2022-03-14 09:23:07 [INFO] ADDING_LINE: process summary {
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy', overwrite: true
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tag "${sample}"
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   cpus 1
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   container 'quay.io/biocontainers/pandas:1.1.5'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   container 'quay.io/biocontainers/pandas:1.1.5'
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:07 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:07 [WARN] NO_PROCESS_LABEL: For process name: summary
2022-03-14 09:23:07 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:07 [INFO] CPUS 1 MEM  CONTAINER 'quay.io/biocontainers/pandas:1.1.5'
2022-03-14 09:23:07 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:07 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:07 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:07 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   tuple val(sample), val(num_N), val(num_ACTG), val(num_degenerate), val(num_total), val(first_line),
2022-03-14 09:23:07 [INFO] ADDING_LINE:   tuple val(sample), val(num_N), val(num_ACTG), val(num_degenerate), val(num_total), val(first_line),
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     val(raw_1),
2022-03-14 09:23:07 [INFO] ADDING_LINE:     val(raw_1),
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     val(raw_2),
2022-03-14 09:23:07 [INFO] ADDING_LINE:     val(raw_2),
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     val(pairskept),
2022-03-14 09:23:07 [INFO] ADDING_LINE:     val(pairskept),
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     val(perc_kept),
2022-03-14 09:23:07 [INFO] ADDING_LINE:     val(perc_kept),
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     val(reads_passed),
2022-03-14 09:23:07 [INFO] ADDING_LINE:     val(reads_passed),
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     val(ivar_variants),
2022-03-14 09:23:07 [INFO] ADDING_LINE:     val(ivar_variants),
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     val(bcftools_variants),
2022-03-14 09:23:07 [INFO] ADDING_LINE:     val(bcftools_variants),
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     val(coverage),
2022-03-14 09:23:07 [INFO] ADDING_LINE:     val(coverage),
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     val(covdepth),
2022-03-14 09:23:07 [INFO] ADDING_LINE:     val(covdepth),
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     val(depth),
2022-03-14 09:23:07 [INFO] ADDING_LINE:     val(depth),
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     val(samtools_stats_before_size_results),
2022-03-14 09:23:07 [INFO] ADDING_LINE:     val(samtools_stats_before_size_results),
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     val(samtools_stats_after_size_results),
2022-03-14 09:23:07 [INFO] ADDING_LINE:     val(samtools_stats_after_size_results),
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     val(percentage_human),
2022-03-14 09:23:07 [INFO] ADDING_LINE:     val(percentage_human),
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     val(percentage_cov),
2022-03-14 09:23:07 [INFO] ADDING_LINE:     val(percentage_cov),
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     val(bedtools_num_failed_amplicons),
2022-03-14 09:23:07 [INFO] ADDING_LINE:     val(bedtools_num_failed_amplicons),
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     val(samtools_num_failed_amplicons),
2022-03-14 09:23:07 [INFO] ADDING_LINE:     val(samtools_num_failed_amplicons),
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     val(aligner_version),
2022-03-14 09:23:07 [INFO] ADDING_LINE:     val(aligner_version),
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     val(trimmer_version),
2022-03-14 09:23:07 [INFO] ADDING_LINE:     val(trimmer_version),
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     val(cleaner_version),
2022-03-14 09:23:07 [INFO] ADDING_LINE:     val(cleaner_version),
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     val(ivar_version) from results
2022-03-14 09:23:07 [INFO] ADDING_LINE:     val(ivar_version) from results
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("${task.process}/${sample}.summary.csv") into summary_file, summary
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("${task.process}/${sample}.summary.csv") into summary_file, summary
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] ADDING_LINE:   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:07 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:07 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:07 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] ADDING_LINE:     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:07 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:07 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     sample_id=($(echo !{sample} | cut -f 1 -d "_" ))
2022-03-14 09:23:08 [INFO] ADDING_LINE:     sample_id=($(echo !{sample} | cut -f 1 -d "_" ))
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     header="sample_id,sample,fasta_line"
2022-03-14 09:23:08 [INFO] ADDING_LINE:     header="sample_id,sample,fasta_line"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     result="${sample_id},!{sample},!{first_line}"
2022-03-14 09:23:08 [INFO] ADDING_LINE:     result="${sample_id},!{sample},!{first_line}"
2022-03-14 09:23:08 [INFO] EXPRESSION_LINE:     if [ "!{params.fastqc}" != "false" ]
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     if [ "!{params.fastqc}" != "false" ]
2022-03-14 09:23:08 [INFO] ADDING_LINE:     if [ "!{params.fastqc}" != "false" ]
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:08 [INFO] ADDING_LINE:     then
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       header="$header,fastqc_raw_reads_1,fastqc_raw_reads_2"
2022-03-14 09:23:08 [INFO] ADDING_LINE:       header="$header,fastqc_raw_reads_1,fastqc_raw_reads_2"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       result="$result,!{raw_1},!{raw_2}"
2022-03-14 09:23:08 [INFO] ADDING_LINE:       result="$result,!{raw_1},!{raw_2}"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:08 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:08 [INFO] EXPRESSION_LINE:     if [ "!{params.cleaner}" == "seqyclean" ]
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     if [ "!{params.cleaner}" == "seqyclean" ]
2022-03-14 09:23:08 [INFO] ADDING_LINE:     if [ "!{params.cleaner}" == "seqyclean" ]
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:08 [INFO] ADDING_LINE:     then
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       header="$header,seqyclean_pairs_kept_after_cleaning,seqyclean_percent_kept_after_cleaning"
2022-03-14 09:23:08 [INFO] ADDING_LINE:       header="$header,seqyclean_pairs_kept_after_cleaning,seqyclean_percent_kept_after_cleaning"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       result="$result,!{pairskept},!{perc_kept}"
2022-03-14 09:23:08 [INFO] ADDING_LINE:       result="$result,!{pairskept},!{perc_kept}"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:08 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:08 [INFO] EXPRESSION_LINE:     if [ "!{params.cleaner}" == "fastp" ]
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     if [ "!{params.cleaner}" == "fastp" ]
2022-03-14 09:23:08 [INFO] ADDING_LINE:     if [ "!{params.cleaner}" == "fastp" ]
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:08 [INFO] ADDING_LINE:     then
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       header="$header,fastp_reads_passed"
2022-03-14 09:23:08 [INFO] ADDING_LINE:       header="$header,fastp_reads_passed"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       result="$result,!{reads_passed}"
2022-03-14 09:23:08 [INFO] ADDING_LINE:       result="$result,!{reads_passed}"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:08 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:08 [INFO] EXPRESSION_LINE:     if [ "!{params.samtools_coverage}" != "false" ]
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     if [ "!{params.samtools_coverage}" != "false" ]
2022-03-14 09:23:08 [INFO] ADDING_LINE:     if [ "!{params.samtools_coverage}" != "false" ]
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:08 [INFO] ADDING_LINE:     then
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       header="$header,depth_after_trimming,1X_coverage_after_trimming"
2022-03-14 09:23:08 [INFO] ADDING_LINE:       header="$header,depth_after_trimming,1X_coverage_after_trimming"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       result="$result,!{covdepth},!{coverage}"
2022-03-14 09:23:08 [INFO] ADDING_LINE:       result="$result,!{covdepth},!{coverage}"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:08 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:08 [INFO] EXPRESSION_LINE:     if [ "!{params.samtools_depth}" != "false" ]
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     if [ "!{params.samtools_depth}" != "false" ]
2022-03-14 09:23:08 [INFO] ADDING_LINE:     if [ "!{params.samtools_depth}" != "false" ]
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:08 [INFO] ADDING_LINE:     then
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       header="$header,num_pos_!{params.minimum_depth}X"
2022-03-14 09:23:08 [INFO] ADDING_LINE:       header="$header,num_pos_!{params.minimum_depth}X"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       result="$result,!{depth}"
2022-03-14 09:23:08 [INFO] ADDING_LINE:       result="$result,!{depth}"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:08 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:08 [INFO] EXPRESSION_LINE:     if [ "!{params.samtools_stats}" != "false" ]
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     if [ "!{params.samtools_stats}" != "false" ]
2022-03-14 09:23:08 [INFO] ADDING_LINE:     if [ "!{params.samtools_stats}" != "false" ]
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:08 [INFO] ADDING_LINE:     then
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       header="$header,insert_size_before_trimming,insert_size_after_trimming"
2022-03-14 09:23:08 [INFO] ADDING_LINE:       header="$header,insert_size_before_trimming,insert_size_after_trimming"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       result="$result,!{samtools_stats_before_size_results},!{samtools_stats_after_size_results}"
2022-03-14 09:23:08 [INFO] ADDING_LINE:       result="$result,!{samtools_stats_before_size_results},!{samtools_stats_after_size_results}"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:08 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:08 [INFO] EXPRESSION_LINE:     if [ "!{params.kraken2}" != "false" ]
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     if [ "!{params.kraken2}" != "false" ]
2022-03-14 09:23:08 [INFO] ADDING_LINE:     if [ "!{params.kraken2}" != "false" ]
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:08 [INFO] ADDING_LINE:     then
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       organism=$(echo "!{params.kraken2_organism}" | sed 's/ /_/g')
2022-03-14 09:23:08 [INFO] ADDING_LINE:       organism=$(echo "!{params.kraken2_organism}" | sed 's/ /_/g')
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       header="$header,%_human_reads,percent_${organism}_reads"
2022-03-14 09:23:08 [INFO] ADDING_LINE:       header="$header,%_human_reads,percent_${organism}_reads"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       result="$result,!{percentage_human},!{percentage_cov}"
2022-03-14 09:23:08 [INFO] ADDING_LINE:       result="$result,!{percentage_human},!{percentage_cov}"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:08 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:08 [INFO] EXPRESSION_LINE:     if [ "!{params.ivar_variants}" != "false" ]
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     if [ "!{params.ivar_variants}" != "false" ]
2022-03-14 09:23:08 [INFO] ADDING_LINE:     if [ "!{params.ivar_variants}" != "false" ]
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:08 [INFO] ADDING_LINE:     then
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       header="$header,ivar_num_variants_identified"
2022-03-14 09:23:08 [INFO] ADDING_LINE:       header="$header,ivar_num_variants_identified"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       result="$result,!{ivar_variants}"
2022-03-14 09:23:08 [INFO] ADDING_LINE:       result="$result,!{ivar_variants}"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:08 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:08 [INFO] EXPRESSION_LINE:     if [ "!{params.bcftools_variants}" != "false" ]
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     if [ "!{params.bcftools_variants}" != "false" ]
2022-03-14 09:23:08 [INFO] ADDING_LINE:     if [ "!{params.bcftools_variants}" != "false" ]
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:08 [INFO] ADDING_LINE:     then
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       header="$header,bcftools_variants_identified"
2022-03-14 09:23:08 [INFO] ADDING_LINE:       header="$header,bcftools_variants_identified"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       result="$result,!{bcftools_variants}"
2022-03-14 09:23:08 [INFO] ADDING_LINE:       result="$result,!{bcftools_variants}"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:08 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:08 [INFO] EXPRESSION_LINE:     if [ "!{params.bedtools_multicov}" != "false" ]
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     if [ "!{params.bedtools_multicov}" != "false" ]
2022-03-14 09:23:08 [INFO] ADDING_LINE:     if [ "!{params.bedtools_multicov}" != "false" ]
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:08 [INFO] ADDING_LINE:     then
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       header="$header,bedtools_num_failed_amplicons"
2022-03-14 09:23:08 [INFO] ADDING_LINE:       header="$header,bedtools_num_failed_amplicons"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       result="$result,!{bedtools_num_failed_amplicons}"
2022-03-14 09:23:08 [INFO] ADDING_LINE:       result="$result,!{bedtools_num_failed_amplicons}"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:08 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:08 [INFO] EXPRESSION_LINE:     if [ "!{params.samtools_ampliconstats}" != "false" ]
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     if [ "!{params.samtools_ampliconstats}" != "false" ]
2022-03-14 09:23:08 [INFO] ADDING_LINE:     if [ "!{params.samtools_ampliconstats}" != "false" ]
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     then
2022-03-14 09:23:08 [INFO] ADDING_LINE:     then
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       header="$header,samtools_num_failed_amplicons"
2022-03-14 09:23:08 [INFO] ADDING_LINE:       header="$header,samtools_num_failed_amplicons"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       result="$result,!{samtools_num_failed_amplicons}"
2022-03-14 09:23:08 [INFO] ADDING_LINE:       result="$result,!{samtools_num_failed_amplicons}"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     fi
2022-03-14 09:23:08 [INFO] ADDING_LINE:     fi
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     header="$header,num_N,num_degenerage,num_non-ambiguous,num_total"
2022-03-14 09:23:08 [INFO] ADDING_LINE:     header="$header,num_N,num_degenerage,num_non-ambiguous,num_total"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     result="$result,!{num_N},!{num_degenerate},!{num_ACTG},!{num_total}"
2022-03-14 09:23:08 [INFO] ADDING_LINE:     result="$result,!{num_N},!{num_degenerate},!{num_ACTG},!{num_total}"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     header="$header,cleaner_version,aligner_version,trimmer_version,ivar_version"
2022-03-14 09:23:08 [INFO] ADDING_LINE:     header="$header,cleaner_version,aligner_version,trimmer_version,ivar_version"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     result="$result,!{cleaner_version},!{aligner_version},!{trimmer_version},!{ivar_version}"
2022-03-14 09:23:08 [INFO] ADDING_LINE:     result="$result,!{cleaner_version},!{aligner_version},!{trimmer_version},!{ivar_version}"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     echo $header > !{task.process}/!{sample}.summary.csv
2022-03-14 09:23:08 [INFO] ADDING_LINE:     echo $header > !{task.process}/!{sample}.summary.csv
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     echo $result >> !{task.process}/!{sample}.summary.csv
2022-03-14 09:23:08 [INFO] ADDING_LINE:     echo $result >> !{task.process}/!{sample}.summary.csv
2022-03-14 09:23:08 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:08 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:08 [INFO] ADDING_LINE: }
2022-03-14 09:23:08 [INFO] UPDATING_PROCESS summary
2022-03-14 09:23:08 [INFO] FOUND_PROCESS_NAME: combine_results
2022-03-14 09:23:08 [INFO] PROCESS_LINE: process combine_results {
2022-03-14 09:23:08 [INFO] ADDING_LINE: process combine_results {
2022-03-14 09:23:08 [INFO] PROCESS_LINE:   publishDir "${params.outdir}", mode: 'copy', overwrite: true
2022-03-14 09:23:08 [INFO] PROCESS_LINE:   tag "Combining Results"
2022-03-14 09:23:08 [INFO] ADDING_LINE:   tag "Combining Results"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:   cpus 1
2022-03-14 09:23:08 [INFO] PROCESS_LINE:   container 'quay.io/biocontainers/pandas:1.1.5'
2022-03-14 09:23:08 [INFO] ADDING_LINE:   container 'quay.io/biocontainers/pandas:1.1.5'
2022-03-14 09:23:08 [INFO] PROCESS_LINE:   when:
2022-03-14 09:23:08 [INFO] LINE_INDENT_FIRST_TOKEN:   
2022-03-14 09:23:08 [WARN] NO_PROCESS_LABEL: For process name: combine_results
2022-03-14 09:23:08 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:08 [INFO] CPUS 1 MEM  CONTAINER 'quay.io/biocontainers/pandas:1.1.5'
2022-03-14 09:23:08 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:08 [INFO] ADDING_LINE:   when:
2022-03-14 09:23:08 [INFO] PROCESS_LINE:   params.nextclade || params.pangolin || params.vadr
2022-03-14 09:23:08 [INFO] ADDING_LINE:   params.nextclade || params.pangolin || params.vadr
2022-03-14 09:23:08 [INFO] PROCESS_LINE:   input:
2022-03-14 09:23:08 [INFO] LINE_INDENT_FIRST_TOKEN:   input:
2022-03-14 09:23:08 [WARN] NO_PROCESS_LABEL: For process name: combine_results
2022-03-14 09:23:08 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:08 [INFO] CPUS 1 MEM  CONTAINER 'quay.io/biocontainers/pandas:1.1.5'
2022-03-14 09:23:08 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:08 [INFO] ADDING_LINE:   input:
2022-03-14 09:23:08 [INFO] PROCESS_LINE:   file(nextclade) from nextclade_file.ifEmpty([])
2022-03-14 09:23:08 [INFO] ADDING_LINE:   file(nextclade) from nextclade_file.ifEmpty([])
2022-03-14 09:23:08 [INFO] PROCESS_LINE:   file(pangolin) from pangolin_file.ifEmpty([])
2022-03-14 09:23:08 [INFO] ADDING_LINE:   file(pangolin) from pangolin_file.ifEmpty([])
2022-03-14 09:23:08 [INFO] PROCESS_LINE:   file(vadr) from vadr_file.ifEmpty([])
2022-03-14 09:23:08 [INFO] ADDING_LINE:   file(vadr) from vadr_file.ifEmpty([])
2022-03-14 09:23:08 [INFO] PROCESS_LINE:   file(summary) from summary_file.collect()
2022-03-14 09:23:08 [INFO] ADDING_LINE:   file(summary) from summary_file.collect()
2022-03-14 09:23:08 [INFO] PROCESS_LINE:   file(combine_results) from combine_results_script
2022-03-14 09:23:08 [INFO] ADDING_LINE:   file(combine_results) from combine_results_script
2022-03-14 09:23:08 [INFO] PROCESS_LINE:   output:
2022-03-14 09:23:08 [INFO] ADDING_LINE:   output:
2022-03-14 09:23:08 [INFO] PROCESS_LINE:   file("cecret_results.{csv,txt}")
2022-03-14 09:23:08 [INFO] ADDING_LINE:   file("cecret_results.{csv,txt}")
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:   file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:08 [INFO] ADDING_LINE:   file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:08 [INFO] PROCESS_LINE:   shell:
2022-03-14 09:23:08 [INFO] ADDING_LINE:   shell:
2022-03-14 09:23:08 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:08 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     mkdir -p summary logs/!{task.process}
2022-03-14 09:23:08 [INFO] ADDING_LINE:     mkdir -p summary logs/!{task.process}
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:     log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:08 [INFO] ADDING_LINE:     log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:     err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:08 [INFO] ADDING_LINE:     err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] ADDING_LINE:     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     cat !{summary} | head -n 1 > combined_summary.csv
2022-03-14 09:23:08 [INFO] ADDING_LINE:     cat !{summary} | head -n 1 > combined_summary.csv
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     for summary in !{summary}
2022-03-14 09:23:08 [INFO] ADDING_LINE:     for summary in !{summary}
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     do
2022-03-14 09:23:08 [INFO] ADDING_LINE:     do
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       tail -n +2 $summary >> combined_summary.csv
2022-03-14 09:23:08 [INFO] ADDING_LINE:       tail -n +2 $summary >> combined_summary.csv
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     done
2022-03-14 09:23:08 [INFO] ADDING_LINE:     done
2022-03-14 09:23:08 [INFO] EXPRESSION_LINE:     if [ -s "vadr.vadr.sqa" ] ; then tail -n +2 "vadr.vadr.sqa" | grep -v "#-" | tr -s '[:blank:]' ',' > vadr.csv ; fi
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     if [ -s "vadr.vadr.sqa" ] ; then tail -n +2 "vadr.vadr.sqa" | grep -v "#-" | tr -s '[:blank:]' ',' > vadr.csv ; fi
2022-03-14 09:23:08 [INFO] ADDING_LINE:     if [ -s "vadr.vadr.sqa" ] ; then tail -n +2 "vadr.vadr.sqa" | grep -v "#-" | tr -s '[:blank:]' ',' > vadr.csv ; fi
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     python !{combine_results}
2022-03-14 09:23:08 [INFO] ADDING_LINE:     python !{combine_results}
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     cat cecret_results.csv | tr ',' '\\t' > cecret_results.txt
2022-03-14 09:23:08 [INFO] ADDING_LINE:     cat cecret_results.csv | tr ',' '\\t' > cecret_results.txt
2022-03-14 09:23:08 [INFO] PROCESS_LINE:   '''
2022-03-14 09:23:08 [INFO] ADDING_LINE:   '''
2022-03-14 09:23:08 [INFO] ADDING_LINE: }
2022-03-14 09:23:08 [INFO] UPDATING_PROCESS combine_results
2022-03-14 09:23:08 [INFO] FOUND_PROCESS_NAME: mafft
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     process mafft {
2022-03-14 09:23:08 [INFO] ADDING_LINE:     process mafft {
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       tag "Multiple Sequence Alignment"
2022-03-14 09:23:08 [INFO] ADDING_LINE:       tag "Multiple Sequence Alignment"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       cpus params.maxcpus
2022-03-14 09:23:08 [INFO] INITIAL_LINE:       cpus params.maxcpus
2022-03-14 09:23:08 [INFO] TRANSLATED_LINE:       cpus 8
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       container 'staphb/mafft:latest'
2022-03-14 09:23:08 [INFO] ADDING_LINE:       container 'staphb/mafft:latest'
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       errorStrategy 'retry'
2022-03-14 09:23:08 [INFO] ADDING_LINE:       errorStrategy 'retry'
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       maxRetries 2
2022-03-14 09:23:08 [INFO] ADDING_LINE:       maxRetries 2
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       input:
2022-03-14 09:23:08 [INFO] LINE_INDENT_FIRST_TOKEN:       input:
2022-03-14 09:23:08 [WARN] NO_PROCESS_LABEL: For process name: mafft
2022-03-14 09:23:08 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:08 [INFO] CPUS 8 MEM  CONTAINER 'staphb/mafft:latest'
2022-03-14 09:23:08 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:08 [INFO] ADDING_LINE:       input:
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       file(consensus) from consensus_msa.concat(fastas_msa).concat(multifastas_msa).collect()
2022-03-14 09:23:08 [INFO] ADDING_LINE:       file(consensus) from consensus_msa.concat(fastas_msa).concat(multifastas_msa).collect()
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       file(reference_genome) from reference_genome_msa
2022-03-14 09:23:08 [INFO] ADDING_LINE:       file(reference_genome) from reference_genome_msa
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       output:
2022-03-14 09:23:08 [INFO] ADDING_LINE:       output:
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:       file("${task.process}/mafft_aligned.fasta") into msa_file, msa_file2
2022-03-14 09:23:08 [INFO] ADDING_LINE:       file("${task.process}/mafft_aligned.fasta") into msa_file, msa_file2
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:       file("logs/${task.process}/mafft.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:08 [INFO] ADDING_LINE:       file("logs/${task.process}/mafft.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       shell:
2022-03-14 09:23:08 [INFO] ADDING_LINE:       shell:
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       '''
2022-03-14 09:23:08 [INFO] ADDING_LINE:       '''
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:08 [INFO] ADDING_LINE:         mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:         log_file=logs/!{task.process}/mafft.!{workflow.sessionId}.log
2022-03-14 09:23:08 [INFO] ADDING_LINE:         log_file=logs/!{task.process}/mafft.!{workflow.sessionId}.log
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:         err_file=logs/!{task.process}/mafft.!{workflow.sessionId}.err
2022-03-14 09:23:08 [INFO] ADDING_LINE:         err_file=logs/!{task.process}/mafft.!{workflow.sessionId}.err
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] ADDING_LINE:         date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         echo "mafft version:" >> $log_file
2022-03-14 09:23:08 [INFO] ADDING_LINE:         echo "mafft version:" >> $log_file
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         mafft --version 2>&1 >> $log_file
2022-03-14 09:23:08 [INFO] ADDING_LINE:         mafft --version 2>&1 >> $log_file
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         for fasta in !{consensus}
2022-03-14 09:23:08 [INFO] ADDING_LINE:         for fasta in !{consensus}
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         do
2022-03-14 09:23:08 [INFO] ADDING_LINE:         do
2022-03-14 09:23:08 [INFO] PROCESS_LINE:           cat $fasta >> !{task.process}/ultimate.fasta
2022-03-14 09:23:08 [INFO] ADDING_LINE:           cat $fasta >> !{task.process}/ultimate.fasta
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         done
2022-03-14 09:23:08 [INFO] ADDING_LINE:         done
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         mafft --auto \
2022-03-14 09:23:08 [INFO] ADDING_LINE:         mafft --auto \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:           !{params.mafft_options} \
2022-03-14 09:23:08 [INFO] ADDING_LINE:           !{params.mafft_options} \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:           --thread !{task.cpus} \
2022-03-14 09:23:08 [INFO] ADDING_LINE:           --thread !{task.cpus} \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:           --addfragments !{task.process}/ultimate.fasta \
2022-03-14 09:23:08 [INFO] ADDING_LINE:           --addfragments !{task.process}/ultimate.fasta \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:           !{reference_genome} \
2022-03-14 09:23:08 [INFO] ADDING_LINE:           !{reference_genome} \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:           > !{task.process}/mafft_aligned.fasta \
2022-03-14 09:23:08 [INFO] ADDING_LINE:           > !{task.process}/mafft_aligned.fasta \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:           2>> $err_file
2022-03-14 09:23:08 [INFO] ADDING_LINE:           2>> $err_file
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       '''
2022-03-14 09:23:08 [INFO] ADDING_LINE:       '''
2022-03-14 09:23:08 [INFO] ADDING_LINE:     }
2022-03-14 09:23:08 [INFO] UPDATING_PROCESS mafft
2022-03-14 09:23:08 [INFO] FOUND_PROCESS_NAME: nextalign
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     process nextalign {
2022-03-14 09:23:08 [INFO] ADDING_LINE:     process nextalign {
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       tag "Multiple Sequence Alignment"
2022-03-14 09:23:08 [INFO] ADDING_LINE:       tag "Multiple Sequence Alignment"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       cpus params.maxcpus
2022-03-14 09:23:08 [INFO] INITIAL_LINE:       cpus params.maxcpus
2022-03-14 09:23:08 [INFO] TRANSLATED_LINE:       cpus 8
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       container 'nextstrain/nextalign:latest'
2022-03-14 09:23:08 [INFO] ADDING_LINE:       container 'nextstrain/nextalign:latest'
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       input:
2022-03-14 09:23:08 [INFO] LINE_INDENT_FIRST_TOKEN:       input:
2022-03-14 09:23:08 [WARN] NO_PROCESS_LABEL: For process name: nextalign
2022-03-14 09:23:08 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:08 [INFO] CPUS 8 MEM  CONTAINER 'nextstrain/nextalign:latest'
2022-03-14 09:23:08 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:08 [INFO] ADDING_LINE:       input:
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       file(consensus) from consensus_msa.concat(fastas_msa).concat(multifastas_msa).collect()
2022-03-14 09:23:08 [INFO] ADDING_LINE:       file(consensus) from consensus_msa.concat(fastas_msa).concat(multifastas_msa).collect()
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       path(dataset) from prepped_nextalign
2022-03-14 09:23:08 [INFO] ADDING_LINE:       path(dataset) from prepped_nextalign
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       output:
2022-03-14 09:23:08 [INFO] ADDING_LINE:       output:
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:       file("${task.process}/nextalign.aligned.fasta") into msa_file, msa_file2
2022-03-14 09:23:08 [INFO] ADDING_LINE:       file("${task.process}/nextalign.aligned.fasta") into msa_file, msa_file2
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:       file("${task.process}/{*.fasta,nextalign.*.csv}")
2022-03-14 09:23:08 [INFO] ADDING_LINE:       file("${task.process}/{*.fasta,nextalign.*.csv}")
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:       file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:08 [INFO] ADDING_LINE:       file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       shell:
2022-03-14 09:23:08 [INFO] ADDING_LINE:       shell:
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       '''
2022-03-14 09:23:08 [INFO] ADDING_LINE:       '''
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:08 [INFO] ADDING_LINE:         mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:         log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:08 [INFO] ADDING_LINE:         log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:         err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:08 [INFO] ADDING_LINE:         err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] ADDING_LINE:         date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         echo "nextalign version:" >> $log_file
2022-03-14 09:23:08 [INFO] ADDING_LINE:         echo "nextalign version:" >> $log_file
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         nextalign --version-detailed 2>&1 >> $log_file
2022-03-14 09:23:08 [INFO] ADDING_LINE:         nextalign --version-detailed 2>&1 >> $log_file
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         for fasta in !{consensus}
2022-03-14 09:23:08 [INFO] ADDING_LINE:         for fasta in !{consensus}
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         do
2022-03-14 09:23:08 [INFO] ADDING_LINE:         do
2022-03-14 09:23:08 [INFO] PROCESS_LINE:           cat $fasta >> !{task.process}/ultimate.fasta
2022-03-14 09:23:08 [INFO] ADDING_LINE:           cat $fasta >> !{task.process}/ultimate.fasta
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         done
2022-03-14 09:23:08 [INFO] ADDING_LINE:         done
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         nextalign !{params.nextalign_options} \
2022-03-14 09:23:08 [INFO] ADDING_LINE:         nextalign !{params.nextalign_options} \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:           --sequences !{task.process}/ultimate.fasta \
2022-03-14 09:23:08 [INFO] ADDING_LINE:           --sequences !{task.process}/ultimate.fasta \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:           --reference !{dataset}/reference.fasta \
2022-03-14 09:23:08 [INFO] ADDING_LINE:           --reference !{dataset}/reference.fasta \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:           --genemap !{dataset}/genemap.gff \
2022-03-14 09:23:08 [INFO] ADDING_LINE:           --genemap !{dataset}/genemap.gff \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:           --jobs !{task.cpus} \
2022-03-14 09:23:08 [INFO] ADDING_LINE:           --jobs !{task.cpus} \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:           --output-dir !{task.process} \
2022-03-14 09:23:08 [INFO] ADDING_LINE:           --output-dir !{task.process} \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:           --output-basename nextalign \
2022-03-14 09:23:08 [INFO] ADDING_LINE:           --output-basename nextalign \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:           >> $log_file 2>> $err_file
2022-03-14 09:23:08 [INFO] ADDING_LINE:           >> $log_file 2>> $err_file
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       '''
2022-03-14 09:23:08 [INFO] ADDING_LINE:       '''
2022-03-14 09:23:08 [INFO] ADDING_LINE:     }
2022-03-14 09:23:08 [INFO] UPDATING_PROCESS nextalign
2022-03-14 09:23:08 [INFO] FOUND_PROCESS_NAME: snpdists
2022-03-14 09:23:08 [INFO] PROCESS_LINE:   process snpdists {
2022-03-14 09:23:08 [INFO] ADDING_LINE:   process snpdists {
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     tag "createing snp matrix with snp-dists"
2022-03-14 09:23:08 [INFO] ADDING_LINE:     tag "createing snp matrix with snp-dists"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     cpus 1
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     container 'staphb/snp-dists:latest'
2022-03-14 09:23:08 [INFO] ADDING_LINE:     container 'staphb/snp-dists:latest'
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     when:
2022-03-14 09:23:08 [INFO] LINE_INDENT_FIRST_TOKEN:     
2022-03-14 09:23:08 [WARN] NO_PROCESS_LABEL: For process name: snpdists
2022-03-14 09:23:08 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:08 [INFO] CPUS 1 MEM  CONTAINER 'staphb/snp-dists:latest'
2022-03-14 09:23:08 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:08 [INFO] ADDING_LINE:     when:
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     params.snpdists
2022-03-14 09:23:08 [INFO] ADDING_LINE:     params.snpdists
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     input:
2022-03-14 09:23:08 [INFO] LINE_INDENT_FIRST_TOKEN:     input:
2022-03-14 09:23:08 [WARN] NO_PROCESS_LABEL: For process name: snpdists
2022-03-14 09:23:08 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:08 [INFO] CPUS 1 MEM  CONTAINER 'staphb/snp-dists:latest'
2022-03-14 09:23:08 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:08 [INFO] ADDING_LINE:     input:
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     file(msa) from msa_file
2022-03-14 09:23:08 [INFO] ADDING_LINE:     file(msa) from msa_file
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     output:
2022-03-14 09:23:08 [INFO] ADDING_LINE:     output:
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:     file("snp-dists/snp-dists.txt")
2022-03-14 09:23:08 [INFO] ADDING_LINE:     file("snp-dists/snp-dists.txt")
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:     file("logs/${task.process}/snp-dists.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:08 [INFO] ADDING_LINE:     file("logs/${task.process}/snp-dists.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     shell:
2022-03-14 09:23:08 [INFO] ADDING_LINE:     shell:
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:08 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       mkdir -p snp-dists logs/!{task.process}
2022-03-14 09:23:08 [INFO] ADDING_LINE:       mkdir -p snp-dists logs/!{task.process}
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:       log_file=logs/!{task.process}/snp-dists.!{workflow.sessionId}.log
2022-03-14 09:23:08 [INFO] ADDING_LINE:       log_file=logs/!{task.process}/snp-dists.!{workflow.sessionId}.log
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:       err_file=logs/!{task.process}/snp-dists.!{workflow.sessionId}.err
2022-03-14 09:23:08 [INFO] ADDING_LINE:       err_file=logs/!{task.process}/snp-dists.!{workflow.sessionId}.err
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] ADDING_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       snp-dists -v >> $log_file
2022-03-14 09:23:08 [INFO] ADDING_LINE:       snp-dists -v >> $log_file
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       snp-dists !{params.snpdists_options} !{msa} > snp-dists/snp-dists.txt 2> $err_file
2022-03-14 09:23:08 [INFO] ADDING_LINE:       snp-dists !{params.snpdists_options} !{msa} > snp-dists/snp-dists.txt 2> $err_file
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:08 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:08 [INFO] ADDING_LINE:   }
2022-03-14 09:23:08 [INFO] UPDATING_PROCESS snpdists
2022-03-14 09:23:08 [INFO] FOUND_PROCESS_NAME: iqtree2
2022-03-14 09:23:08 [INFO] PROCESS_LINE:   process iqtree2 {
2022-03-14 09:23:08 [INFO] ADDING_LINE:   process iqtree2 {
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     tag "Creating phylogenetic tree with iqtree"
2022-03-14 09:23:08 [INFO] ADDING_LINE:     tag "Creating phylogenetic tree with iqtree"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     cpus params.maxcpus
2022-03-14 09:23:08 [INFO] INITIAL_LINE:     cpus params.maxcpus
2022-03-14 09:23:08 [INFO] TRANSLATED_LINE:     cpus 8
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     container 'staphb/iqtree2:latest'
2022-03-14 09:23:08 [INFO] ADDING_LINE:     container 'staphb/iqtree2:latest'
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     when:
2022-03-14 09:23:08 [INFO] LINE_INDENT_FIRST_TOKEN:     
2022-03-14 09:23:08 [WARN] NO_PROCESS_LABEL: For process name: iqtree2
2022-03-14 09:23:08 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:08 [INFO] CPUS 8 MEM  CONTAINER 'staphb/iqtree2:latest'
2022-03-14 09:23:08 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:08 [INFO] ADDING_LINE:     when:
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     params.iqtree2
2022-03-14 09:23:08 [INFO] ADDING_LINE:     params.iqtree2
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     input:
2022-03-14 09:23:08 [INFO] LINE_INDENT_FIRST_TOKEN:     input:
2022-03-14 09:23:08 [WARN] NO_PROCESS_LABEL: For process name: iqtree2
2022-03-14 09:23:08 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:08 [INFO] CPUS 8 MEM  CONTAINER 'staphb/iqtree2:latest'
2022-03-14 09:23:08 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:08 [INFO] ADDING_LINE:     input:
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     file(msa) from msa_file2
2022-03-14 09:23:08 [INFO] ADDING_LINE:     file(msa) from msa_file2
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     output:
2022-03-14 09:23:08 [INFO] ADDING_LINE:     output:
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:     file("${task.process}/${task.process}.{iqtree,treefile,mldist,log}")
2022-03-14 09:23:08 [INFO] ADDING_LINE:     file("${task.process}/${task.process}.{iqtree,treefile,mldist,log}")
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:     file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:08 [INFO] ADDING_LINE:     file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     shell:
2022-03-14 09:23:08 [INFO] ADDING_LINE:     shell:
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:08 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:08 [INFO] ADDING_LINE:       mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:       log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:08 [INFO] ADDING_LINE:       log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:       err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:08 [INFO] ADDING_LINE:       err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] ADDING_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       iqtree2 --version >> $log_file
2022-03-14 09:23:08 [INFO] ADDING_LINE:       iqtree2 --version >> $log_file
2022-03-14 09:23:08 [INFO] EXPRESSION_LINE:       if [ -n "!{params.iqtree2_outgroup}" ] && [ "!{params.iqtree2_outgroup}" != "null" ] && [ "!{params.msa}" != "nextclade" ]
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       if [ -n "!{params.iqtree2_outgroup}" ] && [ "!{params.iqtree2_outgroup}" != "null" ] && [ "!{params.msa}" != "nextclade" ]
2022-03-14 09:23:08 [INFO] ADDING_LINE:       if [ -n "!{params.iqtree2_outgroup}" ] && [ "!{params.iqtree2_outgroup}" != "null" ] && [ "!{params.msa}" != "nextclade" ]
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       then
2022-03-14 09:23:08 [INFO] ADDING_LINE:       then
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         outgroup="-o !{params.iqtree2_outgroup}"
2022-03-14 09:23:08 [INFO] ADDING_LINE:         outgroup="-o !{params.iqtree2_outgroup}"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         cat !{msa} | sed 's/!{params.iqtree2_outgroup}.*/!{params.iqtree2_outgroup}/g' > !{msa}.renamed
2022-03-14 09:23:08 [INFO] ADDING_LINE:         cat !{msa} | sed 's/!{params.iqtree2_outgroup}.*/!{params.iqtree2_outgroup}/g' > !{msa}.renamed
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       else
2022-03-14 09:23:08 [INFO] ADDING_LINE:       else
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         outgroup=""
2022-03-14 09:23:08 [INFO] ADDING_LINE:         outgroup=""
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         mv !{msa} !{msa}.renamed
2022-03-14 09:23:08 [INFO] ADDING_LINE:         mv !{msa} !{msa}.renamed
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       fi
2022-03-14 09:23:08 [INFO] ADDING_LINE:       fi
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       # creating a tree
2022-03-14 09:23:08 [INFO] ADDING_LINE:       # creating a tree
2022-03-14 09:23:08 [INFO] PROCESS_LINE: iqtree2 !{params.iqtree2_options} \
2022-03-14 09:23:08 [INFO] ADDING_LINE: iqtree2 !{params.iqtree2_options} \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         -nt AUTO \
2022-03-14 09:23:08 [INFO] ADDING_LINE:         -nt AUTO \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         -ntmax !{task.cpus} \
2022-03-14 09:23:08 [INFO] ADDING_LINE:         -ntmax !{task.cpus} \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         -s !{msa}.renamed \
2022-03-14 09:23:08 [INFO] ADDING_LINE:         -s !{msa}.renamed \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         -pre !{task.process}/iqtree2 \
2022-03-14 09:23:08 [INFO] ADDING_LINE:         -pre !{task.process}/iqtree2 \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         $outgroup \
2022-03-14 09:23:08 [INFO] ADDING_LINE:         $outgroup \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         >> $log_file 2>> $err_file
2022-03-14 09:23:08 [INFO] ADDING_LINE:         >> $log_file 2>> $err_file
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:08 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:08 [INFO] ADDING_LINE:   }
2022-03-14 09:23:08 [INFO] UPDATING_PROCESS iqtree2
2022-03-14 09:23:08 [INFO] FOUND_PROCESS_NAME: rename
2022-03-14 09:23:08 [INFO] PROCESS_LINE:   process rename {
2022-03-14 09:23:08 [INFO] ADDING_LINE:   process rename {
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     tag "Renaming files for ${sample}"
2022-03-14 09:23:08 [INFO] ADDING_LINE:     tag "Renaming files for ${sample}"
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     cpus 1
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     container 'staphb/parallel-perl:latest'
2022-03-14 09:23:08 [INFO] ADDING_LINE:     container 'staphb/parallel-perl:latest'
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     stageInMode 'copy'
2022-03-14 09:23:08 [INFO] ADDING_LINE:     stageInMode 'copy'
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     input:
2022-03-14 09:23:08 [INFO] LINE_INDENT_FIRST_TOKEN:     input:
2022-03-14 09:23:08 [WARN] NO_PROCESS_LABEL: For process name: rename
2022-03-14 09:23:08 [INFO] FOUND_PROCESS_LABEL: 
2022-03-14 09:23:08 [INFO] CPUS 1 MEM  CONTAINER 'staphb/parallel-perl:latest'
2022-03-14 09:23:08 [INFO] ADDING_POD_ANNOTATION: pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] ADDING_LEINENT_ERROR_STRATEGY: errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] ADDING_TIME_COMPONENT: time '1day'
2022-03-14 09:23:08 [INFO] ADDING_LINE:     input:
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     tuple val(sample), file(reads), val(paired_single), file(consensus), file(filtered_reads), file(sample_file) from rename
2022-03-14 09:23:08 [INFO] ADDING_LINE:     tuple val(sample), file(reads), val(paired_single), file(consensus), file(filtered_reads), file(sample_file) from rename
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     output:
2022-03-14 09:23:08 [INFO] ADDING_LINE:     output:
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:     file("submission_files/*{genbank,gisaid}.fa") optional true
2022-03-14 09:23:08 [INFO] ADDING_LINE:     file("submission_files/*{genbank,gisaid}.fa") optional true
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:     file("submission_files/*.fastq.gz")
2022-03-14 09:23:08 [INFO] ADDING_LINE:     file("submission_files/*.fastq.gz")
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{err,log}")
2022-03-14 09:23:08 [INFO] ADDING_LINE:     file("logs/${task.process}/${sample}.${workflow.sessionId}.{err,log}")
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     shell:
2022-03-14 09:23:08 [INFO] ADDING_LINE:     shell:
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:08 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       mkdir -p submission_files logs/!{task.process}
2022-03-14 09:23:08 [INFO] ADDING_LINE:       mkdir -p submission_files logs/!{task.process}
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:08 [INFO] ADDING_LINE:       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:08 [INFO] ADDING_LINE:       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:08 [INFO] PROCESS_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] ADDING_LINE:       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] NOT_PARSING_LINE:       !{workflow.projectDir}/bin/genbank_submission.sh \
2022-03-14 09:23:08 [INFO] ADDING_LINE:       !{workflow.projectDir}/bin/genbank_submission.sh \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         -f !{sample_file} \
2022-03-14 09:23:08 [INFO] ADDING_LINE:         -f !{sample_file} \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         -c . \
2022-03-14 09:23:08 [INFO] ADDING_LINE:         -c . \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         -d . \
2022-03-14 09:23:08 [INFO] ADDING_LINE:         -d . \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         -s !{params.gisaid_threshold} \
2022-03-14 09:23:08 [INFO] ADDING_LINE:         -s !{params.gisaid_threshold} \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         -g !{params.genbank_threshold} \
2022-03-14 09:23:08 [INFO] ADDING_LINE:         -g !{params.genbank_threshold} \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         -o submission_files \
2022-03-14 09:23:08 [INFO] ADDING_LINE:         -o submission_files \
2022-03-14 09:23:08 [INFO] PROCESS_LINE:         2>> $err_file >> $log_file
2022-03-14 09:23:08 [INFO] ADDING_LINE:         2>> $err_file >> $log_file
2022-03-14 09:23:08 [INFO] PROCESS_LINE:     '''
2022-03-14 09:23:08 [INFO] ADDING_LINE:     '''
2022-03-14 09:23:08 [INFO] ADDING_LINE:   }
2022-03-14 09:23:08 [INFO] UPDATING_PROCESS rename
$fastqc
$fastqc$process_lines
 [1] "process fastqc {"                                                                                                                                                 
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                                                                                  
 [3] "  tag \"$sample\""                                                                                                                                                
 [4] "  container 'staphb/fastqc:latest'"                                                                                                                               
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                                    
 [6] "  errorStrategy 'ignore'"                                                                                                                                         
 [7] "  time '1day'"                                                                                                                                                    
 [8] "  when:"                                                                                                                                                          
 [9] "  params.fastqc && sample != null"                                                                                                                                
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                              
[11] "  input:errorStrategy 'ignore'"                                                                                                                                   
[12] "  input:time '1day'"                                                                                                                                              
[13] "  input:"                                                                                                                                                         
[14] "  tuple val(sample), file(raw), val(type) from fastq_reads_fastqc"                                                                                                
[15] "  output:"                                                                                                                                                        
[16] "  file(\"${task.process}/*.{html,zip}\")"                                                                                                                         
[17] "  tuple sample, env(raw_1) into fastqc_1_results"                                                                                                                 
[18] "  tuple sample, env(raw_2) into fastqc_2_results"                                                                                                                 
[19] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                                                       
[20] "  shell:"                                                                                                                                                         
[21] "  '''"                                                                                                                                                            
[22] "    mkdir -p !{task.process} logs/!{task.process}"                                                                                                                
[23] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                                                            
[24] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                                                            
[25] "    # time stamp + capturing tool versions"                                                                                                                       
[26] "    date | tee -a $log_file $err_file > /dev/null"                                                                                                                
[27] "    fastqc --version >> $log_file"                                                                                                                                
[28] "    fastqc !{params.fastqc_options} \\"                                                                                                                           
[29] "      --outdir !{task.process} \\"                                                                                                                                
[30] "      --threads !{task.cpus} \\"                                                                                                                                  
[31] "      !{raw} \\"                                                                                                                                                  
[32] "      2>> $err_file >> $log_file"                                                                                                                                 
[33] "    zipped_fastq=($(ls !{task.process}/*fastqc.zip) \"\")"                                                                                                        
[34] "    raw_1=$(unzip -p ${zipped_fastq[0]} */fastqc_data.txt | grep \"Total Sequences\" | awk '{ print $3 }' )"                                                      
[35] "    raw_2=NA"                                                                                                                                                     
[36] "    if [ -f \"${zipped_fastq[1]}\" ] ; then raw_2=$(unzip -p !{task.process}/*fastqc.zip */fastqc_data.txt | grep \"Total Sequences\" | awk '{ print $3 }' ) ; fi"
[37] "    if [ -z \"$raw_1\" ] ; then raw_1=\"0\" ; fi"                                                                                                                 
[38] "    if [ -z \"$raw_2\" ] ; then raw_2=\"0\" ; fi"                                                                                                                 
[39] "  '''"                                                                                                                                                            
[40] "}"                                                                                                                                                                

$fastqc$line_numbers
 [1] 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183
[20] 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199

$fastqc$cpus_parsed
[1] 1


$seqyclean
$seqyclean$process_lines
 [1] "  process seqyclean {"                                                                                                                   
 [2] "    publishDir \"${params.outdir}\", mode: 'copy'"                                                                                       
 [3] "    tag \"${sample}\""                                                                                                                   
 [4] "    container 'staphb/seqyclean:latest'"                                                                                                 
 [5] "    pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                         
 [6] "    errorStrategy 'ignore'"                                                                                                              
 [7] "    time '1day'"                                                                                                                         
 [8] "    when:"                                                                                                                               
 [9] "    sample != null"                                                                                                                      
[10] "    input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                   
[11] "    input:errorStrategy 'ignore'"                                                                                                        
[12] "    input:time '1day'"                                                                                                                   
[13] "    input:"                                                                                                                              
[14] "    tuple val(sample), file(reads), val(paired_single) from fastq_reads_seqyclean"                                                       
[15] "    output:"                                                                                                                             
[16] "    tuple sample, file(\"${task.process}/${sample}_clean_PE{1,2}.fastq.gz\") optional true into paired_files"                            
[17] "    tuple sample, file(\"${task.process}/${sample}_cln_SE.fastq.gz\") optional true into single_files"                                   
[18] "    tuple sample, file(\"${task.process}/${sample}_clean_PE{1,2}.fastq.gz\"), val(paired_single) optional true into paired_files_kraken2"
[19] "    tuple sample, file(\"${task.process}/${sample}_cln_SE.fastq.gz\"), val(paired_single) optional true into single_files_kraken2"       
[20] "    file(\"${task.process}/${sample}_cl*n_SummaryStatistics.tsv\") into seqyclean_files"                                                 
[21] "    file(\"${task.process}/${sample}_cl*n_SummaryStatistics.txt\")"                                                                      
[22] "    file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                            
[23] "    tuple sample, env(perc_kept) into seqyclean_perc_kept_results"                                                                       
[24] "    tuple sample, env(kept) into seqyclean_pairskept_results"                                                                            
[25] "    tuple sample, env(cleaner_version) into cleaner_version"                                                                             
[26] "    shell:"                                                                                                                              
[27] "    '''"                                                                                                                                 
[28] "      mkdir -p !{task.process} logs/!{task.process}"                                                                                     
[29] "      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                                 
[30] "      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                                 
[31] "      # time stamp + capturing tool versions"                                                                                            
[32] "      date | tee -a $log_file $err_file > /dev/null"                                                                                     
[33] "      echo \"seqyclean version: $(seqyclean -h | grep Version)\" >> $log_file"                                                           
[34] "      cleaner_version=\"seqyclean : $(seqyclean -h | grep Version)\""                                                                    
[35] "      kept=''"                                                                                                                           
[36] "      perc_kept=''"                                                                                                                      
[37] "      if [ \"!{paired_single}\" == \"single\" ]"                                                                                         
[38] "      then"                                                                                                                              
[39] "        seqyclean !{params.seqyclean_options} \\"                                                                                        
[40] "          -c !{params.seqyclean_contaminant_file} \\"                                                                                    
[41] "          -U !{reads} \\"                                                                                                                
[42] "          -o !{task.process}/!{sample}_cln \\"                                                                                           
[43] "          -gz \\"                                                                                                                        
[44] "          2>> $err_file >> $log_file"                                                                                                    
[45] "        kept=$(cut -f 36 !{task.process}/!{sample}_cln_SummaryStatistics.tsv | grep -v \"Kept\" | head -n 1)"                            
[46] "        perc_kept=$(cut -f 37 !{task.process}/!{sample}_cln_SummaryStatistics.tsv | grep -v \"Kept\" | head -n 1)"                       
[47] "      else"                                                                                                                              
[48] "        seqyclean !{params.seqyclean_options} \\"                                                                                        
[49] "          -c !{params.seqyclean_contaminant_file} \\"                                                                                    
[50] "          -1 !{reads[0]} -2 !{reads[1]} \\"                                                                                              
[51] "          -o !{task.process}/!{sample}_clean \\"                                                                                         
[52] "          -gz \\"                                                                                                                        
[53] "          2>> $err_file >> $log_file"                                                                                                    
[54] "        kept=$(cut -f 58 !{task.process}/!{sample}_clean_SummaryStatistics.tsv | grep -v \"Kept\" | head -n 1)"                          
[55] "        perc_kept=$(cut -f 59 !{task.process}/!{sample}_clean_SummaryStatistics.tsv | grep -v \"Kept\" | head -n 1)"                     
[56] "      fi"                                                                                                                                
[57] "      if [ -z \"$kept\" ] ; then kept=\"0\" ; fi"                                                                                        
[58] "      if [ -z \"$perc_kept\" ] ; then perc_kept=\"0\" ; fi"                                                                              
[59] "    '''"                                                                                                                                 
[60] "  }"                                                                                                                                     

$seqyclean$line_numbers
 [1] 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221
[20] 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240
[39] 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257

$seqyclean$cpus_parsed
[1] 1


$fastp
$fastp$process_lines
 [1] "  process fastp {"                                                                                                                       
 [2] "    publishDir \"${params.outdir}\", mode: 'copy'"                                                                                       
 [3] "    tag \"${sample}\""                                                                                                                   
 [4] "    container 'bromberglab/fastp:latest'"                                                                                                
 [5] "    pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                         
 [6] "    errorStrategy 'ignore'"                                                                                                              
 [7] "    time '1day'"                                                                                                                         
 [8] "    when:"                                                                                                                               
 [9] "    sample != null"                                                                                                                      
[10] "    input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                   
[11] "    input:errorStrategy 'ignore'"                                                                                                        
[12] "    input:time '1day'"                                                                                                                   
[13] "    input:"                                                                                                                              
[14] "    tuple val(sample), file(reads), val(paired_single) from fastq_reads_fastp"                                                           
[15] "    output:"                                                                                                                             
[16] "    tuple sample, file(\"${task.process}/${sample}_clean_PE{1,2}.fastq.gz\") optional true into paired_files"                            
[17] "    tuple sample, file(\"${task.process}/${sample}_cln.fastq.gz\") optional true into single_files"                                      
[18] "    tuple sample, file(\"${task.process}/${sample}_clean_PE{1,2}.fastq.gz\"), val(paired_single) optional true into paired_files_kraken2"
[19] "    tuple sample, file(\"${task.process}/${sample}_cln.fastq.gz\"), val(paired_single) optional true into single_files_kraken2"          
[20] "    file(\"${task.process}/${sample}_fastp.{html,json}\")"                                                                               
[21] "    file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                            
[22] "    tuple sample, env(passed_reads) into fastp_results"                                                                                  
[23] "    tuple sample, env(cleaner_version) into cleaner_version"                                                                             
[24] "    shell:"                                                                                                                              
[25] "    '''"                                                                                                                                 
[26] "      mkdir -p !{task.process} logs/!{task.process}"                                                                                     
[27] "      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                                 
[28] "      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                                 
[29] "      # time stamp + capturing tool versions"                                                                                            
[30] "      date | tee -a $log_file $err_file > /dev/null"                                                                                     
[31] "      fastp --version >> $log_file 2>> $err_file"                                                                                        
[32] "      cleaner_version=\"$(fastp --version 2>&1 | head -n 1)\""                                                                           
[33] "      if [ \"!{paired_single}\" == \"single\" ]"                                                                                         
[34] "      then"                                                                                                                              
[35] "        fastp !{params.fastp_options} \\"                                                                                                
[36] "          -i !{reads} \\"                                                                                                                
[37] "          -o !{task.process}/!{sample}_cln.fastq.gz \\"                                                                                  
[38] "          -h !{task.process}/!{sample}_fastp.html \\"                                                                                    
[39] "          -j !{task.process}/!{sample}_fastp.json \\"                                                                                    
[40] "          2>> $err_file >> $log_file"                                                                                                    
[41] "      else"                                                                                                                              
[42] "        fastp !{params.fastp_options} \\"                                                                                                
[43] "          -i !{reads[0]} \\"                                                                                                             
[44] "          -I !{reads[1]} \\"                                                                                                             
[45] "          -o !{task.process}/!{sample}_clean_PE1.fastq.gz \\"                                                                            
[46] "          -O !{task.process}/!{sample}_clean_PE2.fastq.gz \\"                                                                            
[47] "          -h !{task.process}/!{sample}_fastp.html \\"                                                                                    
[48] "          -j !{task.process}/!{sample}_fastp.json \\"                                                                                    
[49] "          2>> $err_file >> $log_file"                                                                                                    
[50] "      fi"                                                                                                                                
[51] "      passed_reads=$(grep \"reads passed filter\" $err_file | tail -n 1 | cut -f 2 -d \":\" | sed 's/ //g' )"                            
[52] "      if [ -z \"$passed_reads\" ] ; then passed_reads=\"0\" ; fi"                                                                        
[53] "    '''"                                                                                                                                 
[54] "  }"                                                                                                                                     

$fastp$line_numbers
 [1] 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284
[20] 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303
[39] 304 305 306 307 308 309 310 311 312 313 314

$fastp$cpus_parsed
[1] 1


$bwa
$bwa$process_lines
 [1] "  process bwa {"                                                                                                            
 [2] "    publishDir \"${params.outdir}\", mode: 'copy', pattern: \"logs/bwa/*.{log,err}\""                                       
 [3] "    tag \"${sample}\""                                                                                                      
 [4] "    container 'staphb/bwa:latest'"                                                                                          
 [5] "    input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                      
 [6] "    input:errorStrategy 'ignore'"                                                                                           
 [7] "    input:time '1day'"                                                                                                      
 [8] "    input:"                                                                                                                 
 [9] "    tuple val(sample), file(reads), file(reference_genome) from paired_files.concat(single_files).combine(reference_genome)"
[10] "    output:"                                                                                                                
[11] "    tuple sample, file(\"aligned/${sample}.sam\") into sams, sams_filter"                                                   
[12] "    file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                               
[13] "    tuple sample, env(bwa_version) into aligner_version"                                                                    
[14] "    shell:"                                                                                                                 
[15] "    '''"                                                                                                                    
[16] "      mkdir -p aligned logs/!{task.process}"                                                                                
[17] "      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                    
[18] "      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                    
[19] "      # time stamp + capturing tool versions"                                                                               
[20] "      date | tee -a $log_file $err_file > /dev/null"                                                                        
[21] "      echo \"bwa $(bwa 2>&1 | grep Version )\" >> $log_file"                                                                
[22] "      bwa_version=\"bwa : \"$(bwa 2>&1 | grep Version)"                                                                     
[23] "      # index the reference fasta file"                                                                                     
[24] "      bwa index !{reference_genome}"                                                                                        
[25] "      # bwa mem command"                                                                                                    
[26] "      bwa mem -t !{task.cpus} !{reference_genome} !{reads} 2>> $err_file > aligned/!{sample}.sam"                           
[27] "    '''"                                                                                                                    
[28] "  }"                                                                                                                        

$bwa$line_numbers
 [1] 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337
[20] 338 339 340 341 342 343 344

$bwa$cpus_parsed
[1] 8


$minimap2
$minimap2$process_lines
 [1] "  process minimap2 {"                                                                                                       
 [2] "    publishDir \"${params.outdir}\", mode: 'copy', pattern: \"logs/minimap2/*.{log,err}\""                                  
 [3] "    tag \"${sample}\""                                                                                                      
 [4] "    container 'staphb/minimap2:latest'"                                                                                     
 [5] "    input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                      
 [6] "    input:errorStrategy 'ignore'"                                                                                           
 [7] "    input:time '1day'"                                                                                                      
 [8] "    input:"                                                                                                                 
 [9] "    tuple val(sample), file(reads), file(reference_genome) from paired_files.concat(single_files).combine(reference_genome)"
[10] "    output:"                                                                                                                
[11] "    tuple sample, file(\"aligned/${sample}.sam\") into sams, sams_filter"                                                   
[12] "    file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                               
[13] "    tuple sample, env(minimap2_version) into aligner_version"                                                               
[14] "    shell:"                                                                                                                 
[15] "    '''"                                                                                                                    
[16] "      mkdir -p aligned logs/!{task.process}"                                                                                
[17] "      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                    
[18] "      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                    
[19] "      # time stamp + capturing tool versions"                                                                               
[20] "      date | tee -a $log_file $err_file > /dev/null"                                                                        
[21] "      minimap2 --version >> $log_file"                                                                                      
[22] "      minimap2_version=$(echo \"minimap2 : \"$(minimap2 --version))"                                                        
[23] "      minimap2 !{params.minimap2_options} \\"                                                                               
[24] "        -ax sr -t !{task.cpus} \\"                                                                                          
[25] "        -o aligned/!{sample}.sam \\"                                                                                        
[26] "        !{reference_genome} !{reads} 2>> $err_file >> $log_file"                                                            
[27] "    '''"                                                                                                                    
[28] "  }"                                                                                                                        

$minimap2$line_numbers
 [1] 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365
[20] 366 367 368 369 370 371 372

$minimap2$cpus_parsed
[1] 8


$sort
$sort$process_lines
 [1] "process sort {"                                                                                                                                       
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                                                                      
 [3] "  tag \"${sample}\""                                                                                                                                  
 [4] "  container 'staphb/samtools:latest'"                                                                                                                 
 [5] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                  
 [6] "  input:errorStrategy 'ignore'"                                                                                                                       
 [7] "  input:time '1day'"                                                                                                                                  
 [8] "  input:"                                                                                                                                             
 [9] "  tuple val(sample), file(sam) from sams"                                                                                                             
[10] "  output:"                                                                                                                                            
[11] "  tuple sample, file(\"aligned/${sample}.sorted.bam\") into pre_trim_bams, pre_trim_bams2"                                                            
[12] "  tuple sample, file(\"aligned/${sample}.sorted.bam\"), file(\"aligned/${sample}.sorted.bam.bai\") into pre_trim_bams_bamsnap, pre_trim_bams_bedtools"
[13] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                                           
[14] "  shell:"                                                                                                                                             
[15] "  '''"                                                                                                                                                
[16] "    mkdir -p aligned logs/!{task.process}"                                                                                                            
[17] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                                                
[18] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                                                
[19] "    # time stamp + capturing tool versions"                                                                                                           
[20] "    date | tee -a $log_file $err_file > /dev/null"                                                                                                    
[21] "    samtools --version >> $log_file"                                                                                                                  
[22] "    samtools sort !{sam} 2>> $err_file | \\"                                                                                                          
[23] "      samtools view -F 4 -o aligned/!{sample}.sorted.bam 2>> $err_file >> $log_file"                                                                  
[24] "    # indexing the bams"                                                                                                                              
[25] "    samtools index aligned/!{sample}.sorted.bam 2>> $err_file >> $log_file"                                                                           
[26] "  '''"                                                                                                                                                
[27] "}"                                                                                                                                                    

$sort$line_numbers
 [1] 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392
[20] 393 394 395 396 397 398

$sort$cpus_parsed
[1] 8


$filter
$filter$process_lines
 [1] "process filter {"                                                                                               
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                                
 [3] "  tag \"${sample}\""                                                                                            
 [4] "  container 'staphb/samtools:latest'"                                                                           
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                  
 [6] "  errorStrategy 'ignore'"                                                                                       
 [7] "  time '1day'"                                                                                                  
 [8] "  when:"                                                                                                        
 [9] "  params.filter"                                                                                                
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                            
[11] "  input:errorStrategy 'ignore'"                                                                                 
[12] "  input:time '1day'"                                                                                            
[13] "  input:"                                                                                                       
[14] "  tuple val(sample), file(sam) from sams_filter"                                                                
[15] "  output:"                                                                                                      
[16] "  tuple sample, file(\"${task.process}/${sample}_filtered_{R1,R2}.fastq.gz\") optional true into filtered_reads"
[17] "  file(\"${task.process}/${sample}_filtered_unpaired.fastq.gz\") optional true"                                 
[18] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                     
[19] "  shell:"                                                                                                       
[20] "  '''"                                                                                                          
[21] "    mkdir -p !{task.process} logs/!{task.process}"                                                              
[22] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                          
[23] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                          
[24] "    # time stamp + capturing tool versions"                                                                     
[25] "    date | tee -a $log_file $err_file > /dev/null"                                                              
[26] "    samtools --version >> $log_file"                                                                            
[27] "    samtools sort -n !{sam} 2>> $err_file | \\"                                                                 
[28] "      samtools fastq -F 4 !{params.filter_options} \\"                                                          
[29] "      -s !{task.process}/!{sample}_filtered_unpaired.fastq.gz \\"                                               
[30] "      -1 !{task.process}/!{sample}_filtered_R1.fastq.gz \\"                                                     
[31] "      -2 !{task.process}/!{sample}_filtered_R2.fastq.gz \\"                                                     
[32] "      2>> $err_file >> $log_file"                                                                               
[33] "  '''"                                                                                                          
[34] "}"                                                                                                              

$filter$line_numbers
 [1] 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418
[20] 419 420 421 422 423 424 425 426 427 428

$filter$cpus_parsed
[1] 1


$ivar_trim
$ivar_trim$process_lines
 [1] "  process ivar_trim {"                                                                                                                            
 [2] "    publishDir \"${params.outdir}\", mode: 'copy'"                                                                                                
 [3] "    tag \"${sample}\""                                                                                                                            
 [4] "    container 'staphb/ivar:latest'"                                                                                                               
 [5] "    input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                            
 [6] "    input:errorStrategy 'ignore'"                                                                                                                 
 [7] "    input:time '1day'"                                                                                                                            
 [8] "    input:"                                                                                                                                       
 [9] "    tuple val(sample), file(bam), file(primer_bed) from pre_trim_bams.combine(primer_bed)"                                                        
[10] "    output:"                                                                                                                                      
[11] "    tuple sample, file(\"${task.process}/${sample}.primertrim.sorted.bam\") into trimmed_bams, trimmed_bams4, trimmed_bams5"                      
[12] "    tuple sample, file(\"${task.process}/${sample}.primertrim.sorted.bam\"), file(\"ivar_trim/${sample}.primertrim.sorted.bam.bai\") into bam_bai"
[13] "    file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                                     
[14] "    tuple sample, env(trimmer_version) into trimmer_version"                                                                                      
[15] "    shell:"                                                                                                                                       
[16] "    '''"                                                                                                                                          
[17] "      mkdir -p !{task.process} logs/!{task.process}"                                                                                              
[18] "      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                                          
[19] "      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                                          
[20] "      # time stamp + capturing tool versions"                                                                                                     
[21] "      date | tee -a $log_file $err_file > /dev/null"                                                                                              
[22] "      ivar version >> $log_file"                                                                                                                  
[23] "      trimmer_version=\"ivar : $(ivar version | grep version)\""                                                                                  
[24] "      # trimming the reads"                                                                                                                       
[25] "      ivar trim !{params.ivar_trim_options} -e -i !{bam} -b !{primer_bed} -p !{task.process}/!{sample}.primertrim 2>> $err_file >> $log_file"     
[26] "      # sorting and indexing the trimmed bams"                                                                                                    
[27] "      samtools sort !{task.process}/!{sample}.primertrim.bam -o !{task.process}/!{sample}.primertrim.sorted.bam 2>> $err_file >> $log_file"       
[28] "      samtools index !{task.process}/!{sample}.primertrim.sorted.bam 2>> $err_file >> $log_file"                                                  
[29] "    '''"                                                                                                                                          
[30] "  }"                                                                                                                                              

$ivar_trim$line_numbers
 [1] 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
[20] 450 451 452 453 454 455 456 457 458

$ivar_trim$cpus_parsed
[1] 1


$samtools_ampliconclip
$samtools_ampliconclip$process_lines
 [1] "  process samtools_ampliconclip {"                                                                                                                      
 [2] "    publishDir \"${params.outdir}\", mode: 'copy'"                                                                                                      
 [3] "    tag \"${sample}\""                                                                                                                                  
 [4] "    container 'staphb/samtools:latest'"                                                                                                                 
 [5] "    input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                  
 [6] "    input:errorStrategy 'ignore'"                                                                                                                       
 [7] "    input:time '1day'"                                                                                                                                  
 [8] "    input:"                                                                                                                                             
 [9] "    tuple val(sample), file(bam), file(primer_bed) from pre_trim_bams.combine(primer_bed)"                                                              
[10] "    output:"                                                                                                                                            
[11] "    tuple sample, file(\"${task.process}/${sample}.primertrim.sorted.bam\") into trimmed_bams, trimmed_bams4, trimmed_bams5"                            
[12] "    tuple sample, file(\"${task.process}/${sample}.primertrim.sorted.bam\"), file(\"${task.process}/${sample}.primertrim.sorted.bam.bai\") into bam_bai"
[13] "    file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                                           
[14] "    tuple sample, env(trimmer_version) into trimmer_version"                                                                                            
[15] "    shell:"                                                                                                                                             
[16] "    '''"                                                                                                                                                
[17] "      mkdir -p !{task.process} logs/!{task.process}"                                                                                                    
[18] "      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                                                
[19] "      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                                                
[20] "      # time stamp + capturing tool versions"                                                                                                           
[21] "      date | tee -a $log_file $err_file > /dev/null"                                                                                                    
[22] "      samtools --version >> $log_file"                                                                                                                  
[23] "      trimmer_version=\"samtools ampliconclip : $(samtools --version | head -n 1)\""                                                                    
[24] "      # trimming the reads"                                                                                                                             
[25] "      samtools ampliconclip !{params.samtools_ampliconclip_options} -b !{primer_bed} !{bam} 2>> $err_file | \\"                                         
[26] "        samtools sort 2>> $err_file |  \\"                                                                                                              
[27] "        samtools view -F 4 -o !{task.process}/!{sample}.primertrim.sorted.bam 2>> $err_file >> $log_file"                                               
[28] "      samtools index !{task.process}/!{sample}.primertrim.sorted.bam 2>> $err_file >> $log_file"                                                        
[29] "    '''"                                                                                                                                                
[30] "  }"                                                                                                                                                    

$samtools_ampliconclip$line_numbers
 [1] 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479
[20] 480 481 482 483 484 485 486 487 488

$samtools_ampliconclip$cpus_parsed
[1] 1


$ivar_variants
$ivar_variants$process_lines
 [1] "process ivar_variants {"                                                                                                                                                                                                     
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                                                                                                                                             
 [3] "  tag \"${sample}\""                                                                                                                                                                                                         
 [4] "  container 'staphb/ivar:latest'"                                                                                                                                                                                            
 [5] "  errorStrategy 'retry'"                                                                                                                                                                                                     
 [6] "  maxRetries 2"                                                                                                                                                                                                              
 [7] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                                                                                               
 [8] "  errorStrategy 'ignore'"                                                                                                                                                                                                    
 [9] "  time '1day'"                                                                                                                                                                                                               
[10] "  when:"                                                                                                                                                                                                                     
[11] "  params.ivar_variants"                                                                                                                                                                                                      
[12] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                                                                                         
[13] "  input:errorStrategy 'ignore'"                                                                                                                                                                                              
[14] "  input:time '1day'"                                                                                                                                                                                                         
[15] "  input:"                                                                                                                                                                                                                    
[16] "  tuple val(sample), file(bam), file(reference_genome), file(gff_file) from trimmed_bams_genome.combine(gff_file)"                                                                                                           
[17] "  output:"                                                                                                                                                                                                                   
[18] "  tuple sample, file(\"${task.process}/${sample}.variants.tsv\")"                                                                                                                                                            
[19] "  tuple sample, file(\"${task.process}/${sample}.ivar_variants.vcf\") into ivar_variant_file"                                                                                                                                
[20] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                                                                                                                  
[21] "  tuple sample, env(variants_num) into ivar_variants_results"                                                                                                                                                                
[22] "  shell:"                                                                                                                                                                                                                    
[23] "  '''"                                                                                                                                                                                                                       
[24] "    mkdir -p !{task.process} logs/!{task.process}"                                                                                                                                                                           
[25] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                                                                                                                       
[26] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                                                                                                                       
[27] "    # time stamp + capturing tool versions"                                                                                                                                                                                  
[28] "    date | tee -a $log_file $err_file > /dev/null"                                                                                                                                                                           
[29] "    samtools --version >> $log_file"                                                                                                                                                                                         
[30] "    ivar version >> $log_file"                                                                                                                                                                                               
[31] "    samtools mpileup -A -d !{params.mpileup_depth} -B -Q 0 --reference !{reference_genome} !{bam} 2>> $err_file | \\"                                                                                                        
[32] "      ivar variants -p !{task.process}/!{sample}.variants !{params.ivar_variants_options} -m !{params.minimum_depth} -r !{reference_genome} -g !{gff_file} 2>> $err_file >> $log_file"                                       
[33] "    variants_num=$(grep \"TRUE\" !{task.process}/!{sample}.variants.tsv | wc -l)"                                                                                                                                            
[34] "    if [ -z \"$variants_num\" ] ; then variants_num=\"0\" ; fi"                                                                                                                                                              
[35] "    echo '##fileformat=VCFv4.2' > !{task.process}/!{sample}.ivar_variants.vcf"                                                                                                                                               
[36] "    echo '##source=iVar' >> !{task.process}/!{sample}.ivar_variants.vcf"                                                                                                                                                     
[37] "    echo '##INFO=<ID=DP,Number=1,Type=Integer,Description=\"Total Depth\">' >> !{task.process}/!{sample}.ivar_variants.vcf"                                                                                                  
[38] "    echo '##FILTER=<ID=PASS,Description=\"Result of p-value <= 0.05\">' >> !{task.process}/!{sample}.ivar_variants.vcf"                                                                                                      
[39] "    echo '##FILTER=<ID=FAIL,Description=\"Result of p-value > 0.05\">' >> !{task.process}/!{sample}.ivar_variants.vcf"                                                                                                       
[40] "    echo '##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">' >> !{task.process}/!{sample}.ivar_variants.vcf"                                                                                                    
[41] "    echo '##FORMAT=<ID=REF_DP,Number=1,Type=Integer,Description=\"Depth of reference base\">' >> !{task.process}/!{sample}.ivar_variants.vcf"                                                                                
[42] "    echo '##FORMAT=<ID=REF_RV,Number=1,Type=Integer,Description=\"Depth of reference base on reverse reads\">' >> !{task.process}/!{sample}.ivar_variants.vcf"                                                               
[43] "    echo '##FORMAT=<ID=REF_QUAL,Number=1,Type=Integer,Description=\"Mean quality of reference base\">' >> !{task.process}/!{sample}.ivar_variants.vcf"                                                                       
[44] "    echo '##FORMAT=<ID=ALT_DP,Number=1,Type=Integer,Description=\"Depth of alternate base\">' >> !{task.process}/!{sample}.ivar_variants.vcf"                                                                                
[45] "    echo '##FORMAT=<ID=ALT_RV,Number=1,Type=Integer,Description=\"Deapth of alternate base on reverse reads\">' >> !{task.process}/!{sample}.ivar_variants.vcf"                                                              
[46] "    echo '##FORMAT=<ID=ALT_QUAL,Number=1,Type=String,Description=\"Mean quality of alternate base\">' >> !{task.process}/!{sample}.ivar_variants.vcf"                                                                        
[47] "    echo '##FORMAT=<ID=ALT_FREQ,Number=1,Type=String,Description=\"Frequency of alternate base\">' >> !{task.process}/!{sample}.ivar_variants.vcf"                                                                           
[48] "    echo -e '#CHROM\\tPOS\\tID\\tREF\\tALT\\tQUAL\\tFILTER\\tINFO\\tFORMAT\\t!{sample}' >> !{task.process}/!{sample}.ivar_variants.vcf"                                                                                      
[49] "    tail -n+2 !{task.process}/!{sample}.variants.tsv | \\"                                                                                                                                                                   
[50] "      awk '{print $1 \"\\t\" $2 \"\\t.\\t\" $3 \"\\t\" $4 \"\\t.\\t.\\tREF_DP=\" $5 \";REF_RV=\" $6 \";REF_QUAL=\" $7 \";ALT_DP=\" $8 \";ALT_RV=\" $9 \";ALT_QUAL=\" $10 \"\\tGT:PL\\t1/1:\" $12 \",\" $12-$8 \",\" $8 }' \\"
[51] "      >> !{task.process}/!{sample}.ivar_variants.vcf"                                                                                                                                                                        
[52] "  '''"                                                                                                                                                                                                                       
[53] "}"                                                                                                                                                                                                                           

$ivar_variants$line_numbers
 [1] 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
[20] 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540
[39] 541 542 543 544 545 546 547 548 549 550 551

$ivar_variants$cpus_parsed
[1] 1

$ivar_variants$memeory_in_gb_parsed
integer(0)


$ivar_consensus
$ivar_consensus$process_lines
 [1] "process ivar_consensus {"                                                                                                                    
 [2] "  publishDir \"${params.outdir}\", mode: 'copy', pattern: \"logs/ivar_consensus/*.{log,err}\""                                               
 [3] "  publishDir \"${params.outdir}\", mode: 'copy', pattern: \"consensus/*.consensus.fa\""                                                      
 [4] "  tag \"${sample}\""                                                                                                                         
 [5] "  container 'staphb/ivar:latest'"                                                                                                            
 [6] "  errorStrategy {'retry'}"                                                                                                                   
 [7] "  maxRetries 2"                                                                                                                              
 [8] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                         
 [9] "  input:errorStrategy 'ignore'"                                                                                                              
[10] "  input:time '1day'"                                                                                                                         
[11] "  input:"                                                                                                                                    
[12] "  tuple val(sample), file(bam), file(reference_genome) from trimmed_bams_ivar_consensus"                                                     
[13] "  output:"                                                                                                                                   
[14] "  tuple sample, file(\"consensus/${sample}.consensus.fa\") into consensus_rename"                                                            
[15] "  file(\"consensus/${sample}.consensus.fa\") into consensus_pangolin, consensus_vadr, consensus_nextclade, consensus_msa"                    
[16] "  file(\"consensus/${sample}.consensus.qual.txt\")"                                                                                          
[17] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                                  
[18] "  tuple sample, env(num_N), env(num_ACTG), env(num_degenerate), env(num_total), env(first_line) into consensus_results"                      
[19] "  tuple sample, env(ivar_version) into ivar_version"                                                                                         
[20] "  shell:"                                                                                                                                    
[21] "  '''"                                                                                                                                       
[22] "    mkdir -p consensus logs/!{task.process}"                                                                                                 
[23] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                                       
[24] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                                       
[25] "    date | tee -a $log_file $err_file > /dev/null"                                                                                           
[26] "    samtools --version >> $log_file"                                                                                                         
[27] "    ivar version >> $log_file"                                                                                                               
[28] "    ivar_version=$(ivar version | grep \"version\")"                                                                                         
[29] "    samtools mpileup -A -d !{params.mpileup_depth} -B -Q 0 --reference !{reference_genome} !{bam} 2>> $err_file | \\"                        
[30] "      ivar consensus !{params.ivar_consensus_options} -m !{params.minimum_depth} -p consensus/!{sample}.consensus 2>> $err_file >> $log_file"
[31] "    if [ -f \"consensus/!{sample}.consensus.fa\" ]"                                                                                          
[32] "    then"                                                                                                                                    
[33] "      num_N=$(grep -v \">\" consensus/!{sample}.consensus.fa | grep -o 'N' | wc -l )"                                                        
[34] "      num_ACTG=$(grep -v \">\" consensus/!{sample}.consensus.fa | grep -o -E \"C|A|T|G\" | wc -l )"                                          
[35] "      num_degenerate=$(grep -v \">\" consensus/!{sample}.consensus.fa | grep -o -E \"B|D|E|F|H|I|J|K|L|M|O|P|Q|R|S|U|V|W|X|Y|Z\" | wc -l )"  
[36] "      first_line=$(grep \">\" consensus/!{sample}.consensus.fa | sed 's/>//g' )"                                                             
[37] "      if [ -z \"$num_N\" ] ; then num_N=\"0\" ; fi"                                                                                          
[38] "      if [ -z \"$num_ACTG\" ] ; then num_ACTG=\"0\" ; fi"                                                                                    
[39] "      if [ -z \"$num_degenerate\" ] ; then num_degenerate=\"0\" ; fi"                                                                        
[40] "      if [ -z \"$first_line\" ] ; then first_line=!{sample} ; fi"                                                                            
[41] "    else"                                                                                                                                    
[42] "      num_N=\"0\""                                                                                                                           
[43] "      num_ACTG=\"0\""                                                                                                                        
[44] "      num_degenerate=\"0\""                                                                                                                  
[45] "      first_line=!{sample}"                                                                                                                  
[46] "    fi"                                                                                                                                      
[47] "    if [ -z \"$num_N\" ] ; then num_N=\"0\" ; fi"                                                                                            
[48] "    if [ -z \"$num_ACTG\" ] ; then num_ACTG=\"0\" ; fi"                                                                                      
[49] "    if [ -z \"$num_degenerate\" ] ; then num_degenerate=\"0\" ; fi"                                                                          
[50] "    num_total=$(( $num_N + $num_degenerate + $num_ACTG ))"                                                                                   
[51] "  '''"                                                                                                                                       
[52] "}"                                                                                                                                           

$ivar_consensus$line_numbers
 [1] 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571
[20] 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590
[39] 591 592 593 594 595 596 597 598 599 600 601 602 603

$ivar_consensus$cpus_parsed
[1] 1

$ivar_consensus$memeory_in_gb_parsed
integer(0)


$fasta_prep
$fasta_prep$process_lines
 [1] "process fasta_prep {"                                                                                                             
 [2] "  publishDir \"${params.outdir}\", mode: 'copy', overwrite: true"                                                                 
 [3] "  tag \"${fasta}\""                                                                                                               
 [4] "  container 'quay.io/biocontainers/pandas:1.1.5'"                                                                                 
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                    
 [6] "  errorStrategy 'ignore'"                                                                                                         
 [7] "  time '1day'"                                                                                                                    
 [8] "  when:"                                                                                                                          
 [9] "  sample != null && sample != 'input.1'"                                                                                          
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                              
[11] "  input:errorStrategy 'ignore'"                                                                                                   
[12] "  input:time '1day'"                                                                                                              
[13] "  input:"                                                                                                                         
[14] "  tuple val(sample), file(fasta) from fastas"                                                                                     
[15] "  output:"                                                                                                                        
[16] "  tuple sample, env(num_N), env(num_ACTG), env(num_degenerate), env(num_total), env(first_line) into fastas_results"              
[17] "  file(\"${task.process}/${fasta}\") optional true into fastas_rename, fastas_pangolin, fastas_vadr, fastas_nextclade, fastas_msa"
[18] "  shell:"                                                                                                                         
[19] "  '''"                                                                                                                            
[20] "    mkdir -p !{task.process} logs/!{task.process}"                                                                                
[21] "    log_file=logs/!{task.process}/!{workflow.sessionId}.log"                                                                      
[22] "    err_file=logs/!{task.process}/!{workflow.sessionId}.err"                                                                      
[23] "    if [ !{fasta} != 'null' ]"                                                                                                    
[24] "    then"                                                                                                                         
[25] "      echo \">!{sample}\" > !{task.process}/!{fasta}"                                                                             
[26] "      grep -v \">\" !{fasta} | fold -w 75 >> !{task.process}/!{fasta}"                                                            
[27] "      num_N=$(grep -v \">\" !{fasta} | grep -o 'N' | wc -l )"                                                                     
[28] "      num_ACTG=$(grep -v \">\" !{fasta} | grep -o -E \"C|A|T|G\" | wc -l )"                                                       
[29] "      num_degenerate=$(grep -v \">\" !{fasta} | grep -o -E \"B|D|E|F|H|I|J|K|L|M|O|P|Q|R|S|U|V|W|X|Y|Z\" | wc -l )"               
[30] "      first_line=$(grep \">\" consensus/!{sample}.consensus.fa | sed 's/>//g' )"                                                  
[31] "      num_total=$(( $num_N + $num_degenerate + $num_ACTG ))"                                                                      
[32] "      if [ -z \"$num_N\" ] ; then num_N=\"0\" ; fi"                                                                               
[33] "      if [ -z \"$num_ACTG\" ] ; then num_ACTG=\"0\" ; fi"                                                                         
[34] "      if [ -z \"$num_degenerate\" ] ; then num_degenerate=\"0\" ; fi"                                                             
[35] "      if [ -z \"$first_line\" ] ; then first_line=!{sample} ; fi"                                                                 
[36] "      if [ -z \"$num_total\" ] ; then num_total=0 ; fi"                                                                           
[37] "    fi"                                                                                                                           
[38] "  '''"                                                                                                                            
[39] "}"                                                                                                                                

$fasta_prep$line_numbers
 [1] 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622
[20] 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637

$fasta_prep$cpus_parsed
[1] 1


$bcftools_variants
$bcftools_variants$process_lines
 [1] "process bcftools_variants {"                                                                                
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                            
 [3] "  tag \"${sample}\""                                                                                        
 [4] "  container 'staphb/bcftools:latest'"                                                                       
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                              
 [6] "  errorStrategy 'ignore'"                                                                                   
 [7] "  time '1day'"                                                                                              
 [8] "  when:"                                                                                                    
 [9] "  params.bcftools_variants"                                                                                 
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                        
[11] "  input:errorStrategy 'ignore'"                                                                             
[12] "  input:time '1day'"                                                                                        
[13] "  input:"                                                                                                   
[14] "  tuple val(sample), file(bam), file(reference_genome) from trimmed_bams_bcftools_variants"                 
[15] "  output:"                                                                                                  
[16] "  tuple sample, file(\"${task.process}/${sample}.vcf\") into bcftools_variants_file"                        
[17] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                 
[18] "  tuple sample, env(variants_num) into bcftools_variants_results"                                           
[19] "  shell:"                                                                                                   
[20] "  '''"                                                                                                      
[21] "    mkdir -p !{task.process} logs/!{task.process}"                                                          
[22] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                      
[23] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                      
[24] "    # time stamp + capturing tool versions"                                                                 
[25] "    date | tee -a $log_file $err_file > /dev/null"                                                          
[26] "    bcftools --version >> $log_file"                                                                        
[27] "    bcftools mpileup -A -d !{params.mpileup_depth} -B -Q 0 -f !{reference_genome} !{bam} 2>> $err_file | \\"
[28] "      bcftools call -mv -Ov -o !{task.process}/!{sample}.vcf 2>> $err_file >> $log_file"                    
[29] "    variants_num=$(grep -v \"#\" bcftools_variants/!{sample}.vcf | wc -l)"                                  
[30] "    if [ -z \"$variants_num\" ] ; then variants_num=\"0\" ; fi"                                             
[31] "  '''"                                                                                                      
[32] "}"                                                                                                          

$bcftools_variants$line_numbers
 [1] 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656
[20] 657 658 659 660 661 662 663 664

$bcftools_variants$cpus_parsed
[1] 1


$bamsnap
$bamsnap$process_lines
 [1] "process bamsnap {"                                                                                               
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                                 
 [3] "  tag \"${sample}\""                                                                                             
 [4] "  errorStrategy 'ignore'"                                                                                        
 [5] "  container 'danielmsk/bamsnap:latest'"                                                                          
 [6] "  time '1h'"                                                                                                     
 [7] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                   
 [8] "  errorStrategy 'ignore'"                                                                                        
 [9] "  time '1day'"                                                                                                   
[10] "  when:"                                                                                                         
[11] "  params.bamsnap"                                                                                                
[12] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                             
[13] "  input:errorStrategy 'ignore'"                                                                                  
[14] "  input:time '1day'"                                                                                             
[15] "  input:"                                                                                                        
[16] "  tuple val(sample), file(bam), file(bai), file(ivar), file(bcftools), file(reference_genome) from bamsnap_files"
[17] "  output:"                                                                                                       
[18] "  file(\"${task.process}/${sample}/{ivar,bcftools}/*.{png,log}\") optional true"                                 
[19] "  file(\"${task.process}/${sample}/*.{png,log}\") optional true"                                                 
[20] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                      
[21] "  shell:"                                                                                                        
[22] "  '''"                                                                                                           
[23] "    mkdir -p logs/!{task.process}"                                                                               
[24] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                           
[25] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                           
[26] "    date | tee -a $log_file $err_file > /dev/null"                                                               
[27] "    bamsnap --version >> $log_file"                                                                              
[28] "    if [[ \"!{ivar}\" != *\"input\"* ]]"                                                                         
[29] "    then"                                                                                                        
[30] "      mkdir -p bamsnap/!{sample}"                                                                                
[31] "      bamsnap \\"                                                                                                
[32] "        -draw coordinates bamplot coverage base \\"                                                              
[33] "        !{params.bamsnap_options} \\"                                                                            
[34] "        -process !{task.cpus} \\"                                                                                
[35] "        -ref !{reference_genome} \\"                                                                             
[36] "        -bam !{bam} \\"                                                                                          
[37] "        -vcf !{ivar} \\"                                                                                         
[38] "        -out !{task.process}/!{sample}/ivar \\"                                                                  
[39] "        -imagetype png \\"                                                                                       
[40] "        -save_image_only 2>> $err_file >> $log_file"                                                             
[41] "    fi"                                                                                                          
[42] "    if [[ \"!{bcftools}\" != *\"input\"* ]]"                                                                     
[43] "    then"                                                                                                        
[44] "      mkdir -p bamsnap/!{sample}"                                                                                
[45] "      bamsnap \\"                                                                                                
[46] "        -draw coordinates bamplot coverage base \\"                                                              
[47] "        !{params.bamsnap_options} \\"                                                                            
[48] "        -process !{task.cpus} \\"                                                                                
[49] "        -ref !{reference_genome} \\"                                                                             
[50] "        -bam !{bam} \\"                                                                                          
[51] "        -vcf !{bcftools} \\"                                                                                     
[52] "        -out !{task.process}/!{sample}/bcftools \\"                                                              
[53] "        -imagetype png \\"                                                                                       
[54] "        -save_image_only 2>> $err_file >> $log_file"                                                             
[55] "    fi"                                                                                                          
[56] "  '''"                                                                                                           
[57] "}"                                                                                                               

$bamsnap$line_numbers
 [1] 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689
[20] 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708
[39] 709 710 711 712 713 714 715 716 717 718 719 720 721 722

$bamsnap$cpus_parsed
[1] 4


$samtools_stats
$samtools_stats$process_lines
 [1] "process samtools_stats {"                                                                                                         
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                                                  
 [3] "  tag \"${sample}\""                                                                                                              
 [4] "  container 'staphb/samtools:latest'"                                                                                             
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                    
 [6] "  errorStrategy 'ignore'"                                                                                                         
 [7] "  time '1day'"                                                                                                                    
 [8] "  when:"                                                                                                                          
 [9] "  params.samtools_stats"                                                                                                          
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                              
[11] "  input:errorStrategy 'ignore'"                                                                                                   
[12] "  input:time '1day'"                                                                                                              
[13] "  input:"                                                                                                                         
[14] "  tuple val(sample), file(aligned), file(trimmed) from pre_post_bams"                                                             
[15] "  output:"                                                                                                                        
[16] "  file(\"${task.process}/aligned/${sample}.stats.txt\")"                                                                          
[17] "  file(\"${task.process}/trimmed/${sample}.stats.trim.txt\") optional true"                                                       
[18] "  tuple sample, env(insert_size_before_trimming) into samtools_stats_before_size_results"                                         
[19] "  tuple sample, env(insert_size_after_trimming) into samtools_stats_after_size_results"                                           
[20] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                       
[21] "  shell:"                                                                                                                         
[22] "  '''"                                                                                                                            
[23] "    mkdir -p !{task.process}/aligned !{task.process}/trimmed logs/!{task.process}"                                                
[24] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                            
[25] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                            
[26] "    date | tee -a $log_file $err_file > /dev/null"                                                                                
[27] "    samtools --version >> $log_file"                                                                                              
[28] "    samtools stats !{params.samtools_stats_options} !{aligned} 2>> $err_file > !{task.process}/aligned/!{sample}.stats.txt"       
[29] "    if [ \"!{trimmed}\" == \"null\" ] || [[ \"!{trimmed}\" == *\"input\"* ]]"                                                     
[30] "    then"                                                                                                                         
[31] "      insert_size_after_trimming=\"NA\""                                                                                          
[32] "    else"                                                                                                                         
[33] "      samtools stats !{params.samtools_stats_options} !{trimmed} 2>> $err_file > !{task.process}/trimmed/!{sample}.stats.trim.txt"
[34] "      insert_size_after_trimming=$(grep \"insert size average\" !{task.process}/trimmed/!{sample}.stats.trim.txt | cut -f 3)"     
[35] "    fi"                                                                                                                           
[36] "    insert_size_before_trimming=$(grep \"insert size average\" !{task.process}/aligned/!{sample}.stats.txt | cut -f 3)"           
[37] "    if [ -z \"$insert_size_before_trimming\" ] ; then insert_size_before_trimming=0 ; fi"                                         
[38] "    if [ -z \"$insert_size_after_trimming\" ] ; then insert_size_after_trimming=0 ; fi"                                           
[39] "  '''"                                                                                                                            
[40] "}"                                                                                                                                

$samtools_stats$line_numbers
 [1] 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745
[20] 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761

$samtools_stats$cpus_parsed
[1] 1


$samtools_coverage
$samtools_coverage$process_lines
 [1] "process samtools_coverage {"                                                                                                                            
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                                                                        
 [3] "  tag \"${sample}\""                                                                                                                                    
 [4] "  container 'staphb/samtools:latest'"                                                                                                                   
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                          
 [6] "  errorStrategy 'ignore'"                                                                                                                               
 [7] "  time '1day'"                                                                                                                                          
 [8] "  when:"                                                                                                                                                
 [9] "  params.samtools_coverage"                                                                                                                             
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                    
[11] "  input:errorStrategy 'ignore'"                                                                                                                         
[12] "  input:time '1day'"                                                                                                                                    
[13] "  input:"                                                                                                                                               
[14] "  tuple val(sample), file(aligned), file(trimmed) from pre_post_bams2"                                                                                  
[15] "  output:"                                                                                                                                              
[16] "  file(\"${task.process}/{aligned,trimmed}/${sample}.cov.{txt,hist}\") optional true"                                                                   
[17] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                                             
[18] "  tuple sample, env(coverage) into samtools_coverage_results"                                                                                           
[19] "  tuple sample, env(depth) into samtools_covdepth_results"                                                                                              
[20] "  shell:"                                                                                                                                               
[21] "  '''"                                                                                                                                                  
[22] "    mkdir -p !{task.process}/aligned !{task.process}/trimmed logs/!{task.process}"                                                                      
[23] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                                                  
[24] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                                                  
[25] "    date | tee -a $log_file $err_file > /dev/null"                                                                                                      
[26] "    samtools --version >> $log_file"                                                                                                                    
[27] "    samtools coverage !{params.samtools_coverage_options} !{aligned} -m -o !{task.process}/aligned/!{sample}.cov.hist 2>> $err_file >> $log_file"       
[28] "    samtools coverage !{params.samtools_coverage_options} !{aligned}    -o !{task.process}/aligned/!{sample}.cov.txt 2>> $err_file >> $log_file"        
[29] "    if [ \"!{trimmed}\" == \"null\" ] || [[ \"!{trimmed}\" == *\"input\"* ]]"                                                                           
[30] "    then"                                                                                                                                               
[31] "      coverage=$(cut -f 6 !{task.process}/aligned/!{sample}.cov.trim.txt | tail -n 1)"                                                                  
[32] "      depth=$(cut -f 7 !{task.process}/aligned/!{sample}.cov.trim.txt | tail -n 1)"                                                                     
[33] "    else"                                                                                                                                               
[34] "      samtools coverage !{params.samtools_coverage_options} !{trimmed} -m -o !{task.process}/trimmed/!{sample}.cov.trim.hist 2>> $err_file >> $log_file"
[35] "      samtools coverage !{params.samtools_coverage_options} !{trimmed}    -o !{task.process}/trimmed/!{sample}.cov.trim.txt 2>> $err_file >> $log_file" 
[36] "      coverage=$(cut -f 6 !{task.process}/trimmed/!{sample}.cov.trim.txt | tail -n 1)"                                                                  
[37] "      depth=$(cut -f 7 !{task.process}/trimmed/!{sample}.cov.trim.txt | tail -n 1)"                                                                     
[38] "    fi"                                                                                                                                                 
[39] "    if [ -z \"$coverage\" ] ; then coverage=\"0\" ; fi"                                                                                                 
[40] "    if [ -z \"$depth\" ] ; then depth=\"0\" ; fi"                                                                                                       
[41] "  '''"                                                                                                                                                  
[42] "}"                                                                                                                                                      

$samtools_coverage$line_numbers
 [1] 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781
[20] 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799

$samtools_coverage$cpus_parsed
[1] 1


$samtools_flagstat
$samtools_flagstat$process_lines
 [1] "process samtools_flagstat {"                                                        
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                    
 [3] "  tag \"${sample}\""                                                                
 [4] "  container 'staphb/samtools:latest'"                                               
 [5] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"
 [6] "  input:errorStrategy 'ignore'"                                                     
 [7] "  input:time '1day'"                                                                
 [8] "  input:"                                                                           
 [9] "  tuple val(sample), file(aligned), file(trimmed) from pre_post_bams3"              
[10] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"      
[11] "  errorStrategy 'ignore'"                                                           
[12] "  time '1day'"                                                                      
[13] "  when:"                                                                            
[14] "  params.samtools_flagstat"                                                         
[15] "  output:"                                                                          
[16] "  file(\"${task.process}/{aligned,trimmed}/${sample}.flagstat.txt\") optional true" 
[17] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"         
[18] "  shell:"                                                                           
[19] "  '''"                                                                              
[20] "    mkdir -p !{task.process}/aligned !{task.process}/trimmed logs/!{task.process}"  
[21] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"              
[22] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"              
[23] "    date | tee -a $log_file $err_file > /dev/null"                                  
[24] "    samtools --version >> $log_file"                                                
[25] "    samtools flagstat !{params.samtools_flagstat_options} \\"                       
[26] "      !{aligned} \\"                                                                
[27] "      2>> $err_file > !{task.process}/aligned/!{sample}.flagstat.txt"               
[28] "    if [ \"!{trimmed}\" == \"null\" ] || [[ \"!{trimmed}\" == *\"input\"* ]]"       
[29] "    then"                                                                           
[30] "      echo \"No trimmed bam\""                                                      
[31] "    else"                                                                           
[32] "      samtools flagstat !{params.samtools_flagstat_options} \\"                     
[33] "        !{trimmed} \\"                                                              
[34] "        2>> $err_file > !{task.process}/trimmed/!{sample}.flagstat.txt"             
[35] "    fi"                                                                             
[36] "  '''"                                                                              
[37] "}"                                                                                  

$samtools_flagstat$line_numbers
 [1] 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819
[20] 820 821 822 823 824 825 826 827 828 829 830 831 832

$samtools_flagstat$cpus_parsed
[1] 1


$samtools_depth
$samtools_depth$process_lines
 [1] "process samtools_depth {"                                                                                                 
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                                          
 [3] "  tag \"${sample}\""                                                                                                      
 [4] "  container 'staphb/samtools:latest'"                                                                                     
 [5] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                      
 [6] "  input:errorStrategy 'ignore'"                                                                                           
 [7] "  input:time '1day'"                                                                                                      
 [8] "  input:"                                                                                                                 
 [9] "  tuple val(sample), file(aligned), file(trimmed) from pre_post_bams4"                                                    
[10] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                            
[11] "  errorStrategy 'ignore'"                                                                                                 
[12] "  time '1day'"                                                                                                            
[13] "  when:"                                                                                                                  
[14] "  params.samtools_depth"                                                                                                  
[15] "  output:"                                                                                                                
[16] "  file(\"${task.process}/{aligned,trimmed}/${sample}.depth.txt\") optional true"                                          
[17] "  tuple sample, env(depth) into samtools_depth_results"                                                                   
[18] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                               
[19] "  shell:"                                                                                                                 
[20] "  '''"                                                                                                                    
[21] "    mkdir -p !{task.process}/aligned !{task.process}/trimmed logs/!{task.process}"                                        
[22] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                    
[23] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                    
[24] "    date | tee -a $log_file $err_file > /dev/null"                                                                        
[25] "    samtools --version >> $log_file"                                                                                      
[26] "    samtools depth !{params.samtools_depth_options} \\"                                                                   
[27] "      !{aligned} \\"                                                                                                      
[28] "      2>> $err_file > !{task.process}/aligned/!{sample}.depth.txt"                                                        
[29] "    if [ \"!{trimmed}\" == \"null\" ] || [[ \"!{trimmed}\" == *\"input\"* ]]"                                             
[30] "    then"                                                                                                                 
[31] "      depth=$(awk '{ if ($3 > !{params.minimum_depth} ) print $0 }' !{task.process}/aligned/!{sample}.depth.txt | wc -l )"
[32] "    else"                                                                                                                 
[33] "      samtools depth !{params.samtools_depth_options} \\"                                                                 
[34] "        !{trimmed} \\"                                                                                                    
[35] "        2>> $err_file > !{task.process}/trimmed/!{sample}.depth.txt"                                                      
[36] "      depth=$(awk '{ if ($3 > !{params.minimum_depth} ) print $0 }' !{task.process}/trimmed/!{sample}.depth.txt | wc -l )"
[37] "    fi"                                                                                                                   
[38] "    if [ -z \"$depth\" ] ; then depth=\"0\" ; fi"                                                                         
[39] "  '''"                                                                                                                    
[40] "}"                                                                                                                        

$samtools_depth$line_numbers
 [1] 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852
[20] 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868

$samtools_depth$cpus_parsed
[1] 1


$kraken2
$kraken2$process_lines
 [1] "process kraken2 {"                                                                                                                                
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                                                                  
 [3] "  tag \"${sample}\""                                                                                                                              
 [4] "  container 'staphb/kraken2:latest'"                                                                                                              
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                    
 [6] "  errorStrategy 'ignore'"                                                                                                                         
 [7] "  time '1day'"                                                                                                                                    
 [8] "  when:"                                                                                                                                          
 [9] "  params.kraken2"                                                                                                                                 
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                              
[11] "  input:errorStrategy 'ignore'"                                                                                                                   
[12] "  input:time '1day'"                                                                                                                              
[13] "  input:"                                                                                                                                         
[14] "  tuple val(sample), file(clean), val(paired_single), path(kraken2_db) from paired_files_kraken2.concat(single_files_kraken2).combine(kraken2_db)"
[15] "  output:"                                                                                                                                        
[16] "  file(\"${task.process}/${sample}_kraken2_report.txt\")"                                                                                         
[17] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                                       
[18] "  tuple sample, env(percentage_cov) into kraken2_sars_results"                                                                                    
[19] "  tuple sample, env(percentage_human) into kraken2_human_results"                                                                                 
[20] "  shell:"                                                                                                                                         
[21] "  '''"                                                                                                                                            
[22] "    mkdir -p !{task.process} logs/!{task.process}"                                                                                                
[23] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                                            
[24] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                                            
[25] "    date | tee -a $log_file $err_file > /dev/null"                                                                                                
[26] "    kraken2 --version >> $log_file"                                                                                                               
[27] "    if [ ! -d !{kraken2_db} ]"                                                                                                                    
[28] "    then"                                                                                                                                         
[29] "      echo \"Kraken2 database could not be found. Please specify with params.kraken2_db\" | tee -a $err_file"                                     
[30] "    fi"                                                                                                                                           
[31] "    if [ \"!{paired_single}\" == \"single\" ]"                                                                                                    
[32] "    then"                                                                                                                                         
[33] "      kraken2 !{params.kraken2_options} \\"                                                                                                       
[34] "        --classified-out cseqs#.fq \\"                                                                                                            
[35] "        --threads !{task.cpus} \\"                                                                                                                
[36] "        --db !{kraken2_db} \\"                                                                                                                    
[37] "        !{clean} \\"                                                                                                                              
[38] "        --report !{task.process}/!{sample}_kraken2_report.txt \\"                                                                                 
[39] "        2>> $err_file >> $log_file"                                                                                                               
[40] "    else"                                                                                                                                         
[41] "      kraken2 !{params.kraken2_options} \\"                                                                                                       
[42] "        --paired \\"                                                                                                                              
[43] "        --classified-out cseqs#.fq \\"                                                                                                            
[44] "        --threads !{task.cpus} \\"                                                                                                                
[45] "        --db !{kraken2_db} \\"                                                                                                                    
[46] "        !{clean} \\"                                                                                                                              
[47] "        --report !{task.process}/!{sample}_kraken2_report.txt \\"                                                                                 
[48] "        2>> $err_file >> $log_file"                                                                                                               
[49] "    fi"                                                                                                                                           
[50] "    percentage_human=$(grep \"Homo sapiens\" !{task.process}/!{sample}_kraken2_report.txt | awk '{print $1}')"                                    
[51] "    percentage_cov=$(grep \"!{params.kraken2_organism}\" !{task.process}/!{sample}_kraken2_report.txt | awk '{print $1}')"                        
[52] "    if [ -z \"$percentage_human\" ] ; then percentage_human=\"0\" ; fi"                                                                           
[53] "    if [ -z \"$percentage_cov\" ] ; then percentage_cov=\"0\" ; fi"                                                                               
[54] "  '''"                                                                                                                                            
[55] "}"                                                                                                                                                

$kraken2$line_numbers
 [1] 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888
[20] 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907
[39] 908 909 910 911 912 913 914 915 916 917 918 919

$kraken2$cpus_parsed
[1] 8


$bedtools_multicov
$bedtools_multicov$process_lines
 [1] "process bedtools_multicov {"                                                                                                                               
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                                                                           
 [3] "  tag \"${sample}\""                                                                                                                                       
 [4] "  container 'staphb/bedtools:latest'"                                                                                                                      
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                             
 [6] "  errorStrategy 'ignore'"                                                                                                                                  
 [7] "  time '1day'"                                                                                                                                             
 [8] "  when:"                                                                                                                                                   
 [9] "  params.bedtools_multicov"                                                                                                                                
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                       
[11] "  input:errorStrategy 'ignore'"                                                                                                                            
[12] "  input:time '1day'"                                                                                                                                       
[13] "  input:"                                                                                                                                                  
[14] "  tuple val(sample), file(bam), file(bai), file(amplicon_bed) from bam_bai.combine(amplicon_bed)"                                                          
[15] "  output:"                                                                                                                                                 
[16] "  file(\"${task.process}/${sample}.multicov.txt\")"                                                                                                        
[17] "  tuple sample, env(num_failed_amplicons) into bedtools_results"                                                                                           
[18] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                                                
[19] "  shell:"                                                                                                                                                  
[20] "  '''"                                                                                                                                                     
[21] "    mkdir -p !{task.process} logs/!{task.process}"                                                                                                         
[22] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                                                     
[23] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                                                     
[24] "    date | tee -a $log_file $err_file > /dev/null"                                                                                                         
[25] "    bedtools --version >> $log_file"                                                                                                                       
[26] "    bedtools multicov !{params.bedtools_multicov_options} \\"                                                                                              
[27] "      -bams !{bam} \\"                                                                                                                                     
[28] "      -bed !{amplicon_bed} \\"                                                                                                                             
[29] "      2>> $err_file >> !{task.process}/!{sample}.multicov.txt"                                                                                             
[30] "    result_column=$(head -n 1 !{task.process}/!{sample}.multicov.txt | awk '{print NF}' )"                                                                 
[31] "    num_failed_amplicons=$(cat !{task.process}/!{sample}.multicov.txt | tr ' ' '\\t' | cut -f $result_column | awk '{ if ( $1 < 20 ) print $0 }' | wc -l )"
[32] "    if [ -z \"$num_failed_amplicons\" ] ; then num_failed_amplicons=\"NA\" ; fi"                                                                           
[33] "  '''"                                                                                                                                                     
[34] "}"                                                                                                                                                         

$bedtools_multicov$line_numbers
 [1] 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939
[20] 940 941 942 943 944 945 946 947 948 949

$bedtools_multicov$cpus_parsed
[1] 1


$samtools_ampliconstats
$samtools_ampliconstats$process_lines
 [1] "process samtools_ampliconstats {"                                                                                                                           
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                                                                            
 [3] "  tag \"${sample}\""                                                                                                                                        
 [4] "  container 'staphb/samtools:latest'"                                                                                                                       
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                              
 [6] "  errorStrategy 'ignore'"                                                                                                                                   
 [7] "  time '1day'"                                                                                                                                              
 [8] "  when:"                                                                                                                                                    
 [9] "  params.samtools_ampliconstats"                                                                                                                            
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                                        
[11] "  input:errorStrategy 'ignore'"                                                                                                                             
[12] "  input:time '1day'"                                                                                                                                        
[13] "  input:"                                                                                                                                                   
[14] "  tuple val(sample), file(bam), file(primer_bed) from trimmed_bams5.combine(primer_bed_ampliconstats)"                                                      
[15] "  output:"                                                                                                                                                  
[16] "  tuple sample, file(\"${task.process}/${sample}_ampliconstats.txt\") into samtools_ampliconstats_files"                                                    
[17] "  tuple sample, env(num_failed_amplicons) into samtools_ampliconstats_results"                                                                              
[18] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                                                                                 
[19] "  shell:"                                                                                                                                                   
[20] "  '''"                                                                                                                                                      
[21] "    mkdir -p !{task.process} logs/!{task.process}"                                                                                                          
[22] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                                                      
[23] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                                                      
[24] "    date | tee -a $log_file $err_file > /dev/null"                                                                                                          
[25] "    samtools --version >> $log_file"                                                                                                                        
[26] "    samtools ampliconstats !{params.samtools_ampliconstats_options} \\"                                                                                     
[27] "      !{primer_bed} \\"                                                                                                                                     
[28] "      !{bam} \\"                                                                                                                                            
[29] "      2>> $err_file > !{task.process}/!{sample}_ampliconstats.txt"                                                                                          
[30] "    num_failed_amplicons=$(grep ^FREADS !{task.process}/!{sample}_ampliconstats.txt | cut -f 2- | tr '\\t' '\\n' | awk '{ if ($1 < 20) print $0 }' | wc -l)"
[31] "    if [ -z \"$num_failed_amplicons\" ] ; then num_failed_amplicons=0 ; fi"                                                                                 
[32] "  '''"                                                                                                                                                      
[33] "}"                                                                                                                                                          

$samtools_ampliconstats$line_numbers
 [1] 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969
[20] 970 971 972 973 974 975 976 977 978

$samtools_ampliconstats$cpus_parsed
[1] 1


$samtools_plot_ampliconstats
$samtools_plot_ampliconstats$process_lines
 [1] "process samtools_plot_ampliconstats {"                                              
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                    
 [3] "  tag \"${sample}\""                                                                
 [4] "  container 'staphb/samtools:latest'"                                               
 [5] "  errorStrategy 'ignore'"                                                           
 [6] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"      
 [7] "  errorStrategy 'ignore'"                                                           
 [8] "  time '1day'"                                                                      
 [9] "  when:"                                                                            
[10] "  params.samtools_plot_ampliconstats"                                               
[11] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"
[12] "  input:errorStrategy 'ignore'"                                                     
[13] "  input:time '1day'"                                                                
[14] "  input:"                                                                           
[15] "  tuple val(sample), file(ampliconstats) from samtools_ampliconstats_files"         
[16] "  output:"                                                                          
[17] "  file(\"${task.process}/${sample}*\")"                                             
[18] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"         
[19] "  shell:"                                                                           
[20] "  '''"                                                                              
[21] "    mkdir -p !{task.process}/!{sample} logs/!{task.process}"                        
[22] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"              
[23] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"              
[24] "    date | tee -a $log_file $err_file > /dev/null"                                  
[25] "    samtools --version >> $log_file"                                                
[26] "    plot-ampliconstats !{params.samtools_plot_ampliconstats_options} \\"            
[27] "      !{task.process}/!{sample} \\"                                                 
[28] "      !{ampliconstats}"                                                             
[29] "  '''"                                                                              
[30] "}"                                                                                  

$samtools_plot_ampliconstats$line_numbers
 [1]  980  981  982  983  984  985  986  987  988  989  990  991  992  993  994
[16]  995  996  997  998  999 1000 1001 1002 1003 1004

$samtools_plot_ampliconstats$cpus_parsed
[1] 1


$pangolin
$pangolin$process_lines
 [1] "process pangolin {"                                                                                  
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                     
 [3] "  tag \"SARS-CoV-2 lineage Determination\""                                                          
 [4] "  container 'staphb/pangolin:latest'"                                                                
 [5] "  stageInMode 'copy'"                                                                                
 [6] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                       
 [7] "  errorStrategy 'ignore'"                                                                            
 [8] "  time '1day'"                                                                                       
 [9] "  when:"                                                                                             
[10] "  params.pangolin"                                                                                   
[11] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                 
[12] "  input:errorStrategy 'ignore'"                                                                      
[13] "  input:time '1day'"                                                                                 
[14] "  input:"                                                                                            
[15] "  file(fasta) from consensus_pangolin.concat(fastas_pangolin).concat(multifastas_pangolin).collect()"
[16] "  output:"                                                                                           
[17] "  file(\"${task.process}/*\")"                                                                       
[18] "  file(\"${task.process}/lineage_report.csv\") into pangolin_file"                                   
[19] "  file(\"logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}\")"                    
[20] "  shell:"                                                                                            
[21] "  '''"                                                                                               
[22] "    mkdir -p !{task.process} logs/!{task.process}"                                                   
[23] "    log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log"                         
[24] "    err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err"                         
[25] "    date | tee -a $log_file $err_file > /dev/null"                                                   
[26] "    pangolin --all-versions >> $log_file"                                                            
[27] "    for fasta in !{fasta}"                                                                           
[28] "    do"                                                                                              
[29] "      cat $fasta >> ultimate_fasta.fasta"                                                            
[30] "    done"                                                                                            
[31] "    pangolin !{params.pangolin_options} \\"                                                          
[32] "      --threads !{task.cpus} \\"                                                                     
[33] "      --outdir !{task.process} \\"                                                                   
[34] "      ultimate_fasta.fasta \\"                                                                       
[35] "      2>> $err_file >> $log_file"                                                                    
[36] "    cp ultimate_fasta.fasta !{task.process}/combined.fasta"                                          
[37] "  '''"                                                                                               
[38] "}"                                                                                                   

$pangolin$line_numbers
 [1] 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020
[16] 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035
[31] 1036 1037 1038

$pangolin$cpus_parsed
[1] 4


$nextclade
$nextclade$process_lines
 [1] "process nextclade {"                                                                                    
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                                        
 [3] "  tag \"Clade Determination\""                                                                          
 [4] "  container 'nextstrain/nextclade:latest'"                                                              
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                          
 [6] "  errorStrategy 'ignore'"                                                                               
 [7] "  time '1day'"                                                                                          
 [8] "  when:"                                                                                                
 [9] "  params.nextclade || params.msa == 'nextalign'"                                                        
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                    
[11] "  input:errorStrategy 'ignore'"                                                                         
[12] "  input:time '1day'"                                                                                    
[13] "  input:"                                                                                               
[14] "  file(fasta) from consensus_nextclade.concat(fastas_nextclade).concat(multifastas_nextclade).collect()"
[15] "  output:"                                                                                              
[16] "  file(\"${task.process}/nextclade.csv\") into nextclade_file"                                          
[17] "  file(\"${task.process}/*\")"                                                                          
[18] "  file(\"${task.process}/nextclade.aligned.fasta\") into nextclade_aligned_fasta"                       
[19] "  path(\"dataset\") into prepped_nextalign"                                                             
[20] "  file(\"logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}\")"                       
[21] "  shell:"                                                                                               
[22] "  '''"                                                                                                  
[23] "    mkdir -p !{task.process} dataset logs/!{task.process}"                                              
[24] "    log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log"                            
[25] "    err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err"                            
[26] "    date | tee -a $log_file $err_file > /dev/null"                                                      
[27] "    nextclade --version >> $log_file"                                                                   
[28] "    nextclade_version=$(nextclade --version)"                                                           
[29] "    nextclade dataset get --name !{params.nextclade_dataset} --output-dir dataset"                      
[30] "    for fasta in !{fasta}"                                                                              
[31] "    do"                                                                                                 
[32] "      cat $fasta >> ultimate_fasta.fasta"                                                               
[33] "    done"                                                                                               
[34] "    nextclade !{params.nextclade_options} \\"                                                           
[35] "      --input-fasta=ultimate_fasta.fasta \\"                                                            
[36] "      --input-dataset dataset \\"                                                                       
[37] "      --output-json=!{task.process}/nextclade.json \\"                                                  
[38] "      --output-csv=!{task.process}/nextclade.csv \\"                                                    
[39] "      --output-tsv=!{task.process}/nextclade.tsv \\"                                                    
[40] "      --output-tree=!{task.process}/nextclade.auspice.json \\"                                          
[41] "      --output-dir=!{task.process} \\"                                                                  
[42] "      --output-basename=nextclade \\"                                                                   
[43] "      2>> $err_file >> $log_file"                                                                       
[44] "    cp ultimate_fasta.fasta !{task.process}/combined.fasta"                                             
[45] "  '''"                                                                                                  
[46] "}"                                                                                                      

$nextclade$line_numbers
 [1] 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055
[16] 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070
[31] 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081

$nextclade$cpus_parsed
[1] 4


$vadr
$vadr$process_lines
 [1] "process vadr {"                                                                          
 [2] "  publishDir \"${params.outdir}\", mode: 'copy'"                                         
 [3] "  tag \"QC metrics\""                                                                    
 [4] "  container 'staphb/vadr:latest'"                                                        
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"           
 [6] "  errorStrategy 'ignore'"                                                                
 [7] "  time '1day'"                                                                           
 [8] "  when:"                                                                                 
 [9] "  params.vadr"                                                                           
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"     
[11] "  input:errorStrategy 'ignore'"                                                          
[12] "  input:time '1day'"                                                                     
[13] "  input:"                                                                                
[14] "  file(fasta) from consensus_vadr.concat(fastas_vadr).concat(multifastas_vadr).collect()"
[15] "  output:"                                                                               
[16] "  file(\"${task.process}/*\") optional true"                                             
[17] "  file(\"${task.process}/vadr.vadr.sqa\") optional true into vadr_file"                  
[18] "  file(\"logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}\")"        
[19] "  shell:"                                                                                
[20] "  '''"                                                                                   
[21] "    mkdir -p logs/!{task.process}"                                                       
[22] "    log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log"             
[23] "    err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err"             
[24] "    date | tee -a $log_file $err_file > /dev/null"                                       
[25] "    echo \"no version\" >> $log_file"                                                    
[26] "    v-annotate.pl -h >> $log_file"                                                       
[27] "    for fasta in !{fasta}"                                                               
[28] "    do"                                                                                  
[29] "      cat $fasta >> ultimate_fasta.fasta"                                                
[30] "    done"                                                                                
[31] "    fasta-trim-terminal-ambigs.pl !{params.vadr_trim_options} \\"                        
[32] "      ultimate_fasta.fasta > trimmed_ultimate_fasta.fasta"                               
[33] "    if [ -s \"trimmed_ultimate_fasta.fasta\" ]"                                          
[34] "    then"                                                                                
[35] "      v-annotate.pl !{params.vadr_options} \\"                                           
[36] "        --cpu !{task.cpus} \\"                                                           
[37] "        --noseqnamemax \\"                                                               
[38] "        --mkey !{params.vadr_reference} \\"                                              
[39] "        --mdir !{params.vadr_mdir} \\"                                                   
[40] "        trimmed_ultimate_fasta.fasta \\"                                                 
[41] "        !{task.process} \\"                                                              
[42] "        2>> $err_file >> $log_file"                                                      
[43] "    fi"                                                                                  
[44] "    cp ultimate_fasta.fasta !{task.process}/combined.fasta"                              
[45] "    cp trimmed_ultimate_fasta.fasta !{task.process}/trimmed.fasta"                       
[46] "  '''"                                                                                   
[47] "}"                                                                                       

$vadr$line_numbers
 [1] 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100
[16] 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115
[31] 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127

$vadr$cpus_parsed
[1] 4


$summary
$summary$process_lines
  [1] "process summary {"                                                                                    
  [2] "  publishDir \"${params.outdir}\", mode: 'copy', overwrite: true"                                     
  [3] "  tag \"${sample}\""                                                                                  
  [4] "  container 'quay.io/biocontainers/pandas:1.1.5'"                                                     
  [5] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                  
  [6] "  input:errorStrategy 'ignore'"                                                                       
  [7] "  input:time '1day'"                                                                                  
  [8] "  input:"                                                                                             
  [9] "  tuple val(sample), val(num_N), val(num_ACTG), val(num_degenerate), val(num_total), val(first_line),"
 [10] "    val(raw_1),"                                                                                      
 [11] "    val(raw_2),"                                                                                      
 [12] "    val(pairskept),"                                                                                  
 [13] "    val(perc_kept),"                                                                                  
 [14] "    val(reads_passed),"                                                                               
 [15] "    val(ivar_variants),"                                                                              
 [16] "    val(bcftools_variants),"                                                                          
 [17] "    val(coverage),"                                                                                   
 [18] "    val(covdepth),"                                                                                   
 [19] "    val(depth),"                                                                                      
 [20] "    val(samtools_stats_before_size_results),"                                                         
 [21] "    val(samtools_stats_after_size_results),"                                                          
 [22] "    val(percentage_human),"                                                                           
 [23] "    val(percentage_cov),"                                                                             
 [24] "    val(bedtools_num_failed_amplicons),"                                                              
 [25] "    val(samtools_num_failed_amplicons),"                                                              
 [26] "    val(aligner_version),"                                                                            
 [27] "    val(trimmer_version),"                                                                            
 [28] "    val(cleaner_version),"                                                                            
 [29] "    val(ivar_version) from results"                                                                   
 [30] "  output:"                                                                                            
 [31] "  file(\"${task.process}/${sample}.summary.csv\") into summary_file, summary"                         
 [32] "  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")"                           
 [33] "  shell:"                                                                                             
 [34] "  '''"                                                                                                
 [35] "    mkdir -p !{task.process} logs/!{task.process}"                                                    
 [36] "    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                
 [37] "    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                
 [38] "    date | tee -a $log_file $err_file > /dev/null"                                                    
 [39] "    sample_id=($(echo !{sample} | cut -f 1 -d \"_\" ))"                                               
 [40] "    header=\"sample_id,sample,fasta_line\""                                                           
 [41] "    result=\"${sample_id},!{sample},!{first_line}\""                                                  
 [42] "    if [ \"!{params.fastqc}\" != \"false\" ]"                                                         
 [43] "    then"                                                                                             
 [44] "      header=\"$header,fastqc_raw_reads_1,fastqc_raw_reads_2\""                                       
 [45] "      result=\"$result,!{raw_1},!{raw_2}\""                                                           
 [46] "    fi"                                                                                               
 [47] "    if [ \"!{params.cleaner}\" == \"seqyclean\" ]"                                                    
 [48] "    then"                                                                                             
 [49] "      header=\"$header,seqyclean_pairs_kept_after_cleaning,seqyclean_percent_kept_after_cleaning\""   
 [50] "      result=\"$result,!{pairskept},!{perc_kept}\""                                                   
 [51] "    fi"                                                                                               
 [52] "    if [ \"!{params.cleaner}\" == \"fastp\" ]"                                                        
 [53] "    then"                                                                                             
 [54] "      header=\"$header,fastp_reads_passed\""                                                          
 [55] "      result=\"$result,!{reads_passed}\""                                                             
 [56] "    fi"                                                                                               
 [57] "    if [ \"!{params.samtools_coverage}\" != \"false\" ]"                                              
 [58] "    then"                                                                                             
 [59] "      header=\"$header,depth_after_trimming,1X_coverage_after_trimming\""                             
 [60] "      result=\"$result,!{covdepth},!{coverage}\""                                                     
 [61] "    fi"                                                                                               
 [62] "    if [ \"!{params.samtools_depth}\" != \"false\" ]"                                                 
 [63] "    then"                                                                                             
 [64] "      header=\"$header,num_pos_!{params.minimum_depth}X\""                                            
 [65] "      result=\"$result,!{depth}\""                                                                    
 [66] "    fi"                                                                                               
 [67] "    if [ \"!{params.samtools_stats}\" != \"false\" ]"                                                 
 [68] "    then"                                                                                             
 [69] "      header=\"$header,insert_size_before_trimming,insert_size_after_trimming\""                      
 [70] "      result=\"$result,!{samtools_stats_before_size_results},!{samtools_stats_after_size_results}\""  
 [71] "    fi"                                                                                               
 [72] "    if [ \"!{params.kraken2}\" != \"false\" ]"                                                        
 [73] "    then"                                                                                             
 [74] "      organism=$(echo \"!{params.kraken2_organism}\" | sed 's/ /_/g')"                                
 [75] "      header=\"$header,%_human_reads,percent_${organism}_reads\""                                     
 [76] "      result=\"$result,!{percentage_human},!{percentage_cov}\""                                       
 [77] "    fi"                                                                                               
 [78] "    if [ \"!{params.ivar_variants}\" != \"false\" ]"                                                  
 [79] "    then"                                                                                             
 [80] "      header=\"$header,ivar_num_variants_identified\""                                                
 [81] "      result=\"$result,!{ivar_variants}\""                                                            
 [82] "    fi"                                                                                               
 [83] "    if [ \"!{params.bcftools_variants}\" != \"false\" ]"                                              
 [84] "    then"                                                                                             
 [85] "      header=\"$header,bcftools_variants_identified\""                                                
 [86] "      result=\"$result,!{bcftools_variants}\""                                                        
 [87] "    fi"                                                                                               
 [88] "    if [ \"!{params.bedtools_multicov}\" != \"false\" ]"                                              
 [89] "    then"                                                                                             
 [90] "      header=\"$header,bedtools_num_failed_amplicons\""                                               
 [91] "      result=\"$result,!{bedtools_num_failed_amplicons}\""                                            
 [92] "    fi"                                                                                               
 [93] "    if [ \"!{params.samtools_ampliconstats}\" != \"false\" ]"                                         
 [94] "    then"                                                                                             
 [95] "      header=\"$header,samtools_num_failed_amplicons\""                                               
 [96] "      result=\"$result,!{samtools_num_failed_amplicons}\""                                            
 [97] "    fi"                                                                                               
 [98] "    header=\"$header,num_N,num_degenerage,num_non-ambiguous,num_total\""                              
 [99] "    result=\"$result,!{num_N},!{num_degenerate},!{num_ACTG},!{num_total}\""                           
[100] "    header=\"$header,cleaner_version,aligner_version,trimmer_version,ivar_version\""                  
[101] "    result=\"$result,!{cleaner_version},!{aligner_version},!{trimmer_version},!{ivar_version}\""      
[102] "    echo $header > !{task.process}/!{sample}.summary.csv"                                             
[103] "    echo $result >> !{task.process}/!{sample}.summary.csv"                                            
[104] "  '''"                                                                                                
[105] "}"                                                                                                    

$summary$line_numbers
  [1] 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165
 [16] 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180
 [31] 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195
 [46] 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210
 [61] 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225
 [76] 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240
 [91] 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253

$summary$cpus_parsed
[1] 1


$combine_results
$combine_results$process_lines
 [1] "process combine_results {"                                                                                                   
 [2] "  publishDir \"${params.outdir}\", mode: 'copy', overwrite: true"                                                            
 [3] "  tag \"Combining Results\""                                                                                                 
 [4] "  container 'quay.io/biocontainers/pandas:1.1.5'"                                                                            
 [5] "  pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                               
 [6] "  errorStrategy 'ignore'"                                                                                                    
 [7] "  time '1day'"                                                                                                               
 [8] "  when:"                                                                                                                     
 [9] "  params.nextclade || params.pangolin || params.vadr"                                                                        
[10] "  input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                         
[11] "  input:errorStrategy 'ignore'"                                                                                              
[12] "  input:time '1day'"                                                                                                         
[13] "  input:"                                                                                                                    
[14] "  file(nextclade) from nextclade_file.ifEmpty([])"                                                                           
[15] "  file(pangolin) from pangolin_file.ifEmpty([])"                                                                             
[16] "  file(vadr) from vadr_file.ifEmpty([])"                                                                                     
[17] "  file(summary) from summary_file.collect()"                                                                                 
[18] "  file(combine_results) from combine_results_script"                                                                         
[19] "  output:"                                                                                                                   
[20] "  file(\"cecret_results.{csv,txt}\")"                                                                                        
[21] "  file(\"logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}\")"                                            
[22] "  shell:"                                                                                                                    
[23] "  '''"                                                                                                                       
[24] "    mkdir -p summary logs/!{task.process}"                                                                                   
[25] "    log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log"                                                 
[26] "    err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err"                                                 
[27] "    date | tee -a $log_file $err_file > /dev/null"                                                                           
[28] "    cat !{summary} | head -n 1 > combined_summary.csv"                                                                       
[29] "    for summary in !{summary}"                                                                                               
[30] "    do"                                                                                                                      
[31] "      tail -n +2 $summary >> combined_summary.csv"                                                                           
[32] "    done"                                                                                                                    
[33] "    if [ -s \"vadr.vadr.sqa\" ] ; then tail -n +2 \"vadr.vadr.sqa\" | grep -v \"#-\" | tr -s '[:blank:]' ',' > vadr.csv ; fi"
[34] "    python !{combine_results}"                                                                                               
[35] "    cat cecret_results.csv | tr ',' '\\\\t' > cecret_results.txt"                                                            
[36] "  '''"                                                                                                                       
[37] "}"                                                                                                                           

$combine_results$line_numbers
 [1] 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274
[16] 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289
[31] 1290 1291

$combine_results$cpus_parsed
[1] 1


$mafft
$mafft$process_lines
 [1] "    process mafft {"                                                                          
 [2] "      publishDir \"${params.outdir}\", mode: 'copy'"                                          
 [3] "      tag \"Multiple Sequence Alignment\""                                                    
 [4] "      container 'staphb/mafft:latest'"                                                        
 [5] "      errorStrategy 'retry'"                                                                  
 [6] "      maxRetries 2"                                                                           
 [7] "      input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"      
 [8] "      input:errorStrategy 'ignore'"                                                           
 [9] "      input:time '1day'"                                                                      
[10] "      input:"                                                                                 
[11] "      file(consensus) from consensus_msa.concat(fastas_msa).concat(multifastas_msa).collect()"
[12] "      file(reference_genome) from reference_genome_msa"                                       
[13] "      output:"                                                                                
[14] "      file(\"${task.process}/mafft_aligned.fasta\") into msa_file, msa_file2"                 
[15] "      file(\"logs/${task.process}/mafft.${workflow.sessionId}.{log,err}\")"                   
[16] "      shell:"                                                                                 
[17] "      '''"                                                                                    
[18] "        mkdir -p !{task.process} logs/!{task.process}"                                        
[19] "        log_file=logs/!{task.process}/mafft.!{workflow.sessionId}.log"                        
[20] "        err_file=logs/!{task.process}/mafft.!{workflow.sessionId}.err"                        
[21] "        date | tee -a $log_file $err_file > /dev/null"                                        
[22] "        echo \"mafft version:\" >> $log_file"                                                 
[23] "        mafft --version 2>&1 >> $log_file"                                                    
[24] "        for fasta in !{consensus}"                                                            
[25] "        do"                                                                                   
[26] "          cat $fasta >> !{task.process}/ultimate.fasta"                                       
[27] "        done"                                                                                 
[28] "        mafft --auto \\"                                                                      
[29] "          !{params.mafft_options} \\"                                                         
[30] "          --thread !{task.cpus} \\"                                                           
[31] "          --addfragments !{task.process}/ultimate.fasta \\"                                   
[32] "          !{reference_genome} \\"                                                             
[33] "          > !{task.process}/mafft_aligned.fasta \\"                                           
[34] "          2>> $err_file"                                                                      
[35] "      '''"                                                                                    
[36] "    }"                                                                                        

$mafft$line_numbers
 [1] 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309
[16] 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324
[31] 1325 1326 1327 1328

$mafft$cpus_parsed
[1] 8


$nextalign
$nextalign$process_lines
 [1] "    process nextalign {"                                                                      
 [2] "      publishDir \"${params.outdir}\", mode: 'copy'"                                          
 [3] "      tag \"Multiple Sequence Alignment\""                                                    
 [4] "      container 'nextstrain/nextalign:latest'"                                                
 [5] "      input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"      
 [6] "      input:errorStrategy 'ignore'"                                                           
 [7] "      input:time '1day'"                                                                      
 [8] "      input:"                                                                                 
 [9] "      file(consensus) from consensus_msa.concat(fastas_msa).concat(multifastas_msa).collect()"
[10] "      path(dataset) from prepped_nextalign"                                                   
[11] "      output:"                                                                                
[12] "      file(\"${task.process}/nextalign.aligned.fasta\") into msa_file, msa_file2"             
[13] "      file(\"${task.process}/{*.fasta,nextalign.*.csv}\")"                                    
[14] "      file(\"logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}\")"         
[15] "      shell:"                                                                                 
[16] "      '''"                                                                                    
[17] "        mkdir -p !{task.process} logs/!{task.process}"                                        
[18] "        log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log"              
[19] "        err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err"              
[20] "        date | tee -a $log_file $err_file > /dev/null"                                        
[21] "        echo \"nextalign version:\" >> $log_file"                                             
[22] "        nextalign --version-detailed 2>&1 >> $log_file"                                       
[23] "        for fasta in !{consensus}"                                                            
[24] "        do"                                                                                   
[25] "          cat $fasta >> !{task.process}/ultimate.fasta"                                       
[26] "        done"                                                                                 
[27] "        nextalign !{params.nextalign_options} \\"                                             
[28] "          --sequences !{task.process}/ultimate.fasta \\"                                      
[29] "          --reference !{dataset}/reference.fasta \\"                                          
[30] "          --genemap !{dataset}/genemap.gff \\"                                                
[31] "          --jobs !{task.cpus} \\"                                                             
[32] "          --output-dir !{task.process} \\"                                                    
[33] "          --output-basename nextalign \\"                                                     
[34] "          >> $log_file 2>> $err_file"                                                         
[35] "      '''"                                                                                    
[36] "    }"                                                                                        

$nextalign$line_numbers
 [1] 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345
[16] 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360
[31] 1361 1362 1363 1364

$nextalign$cpus_parsed
[1] 8


$snpdists
$snpdists$process_lines
 [1] "  process snpdists {"                                                                    
 [2] "    publishDir \"${params.outdir}\", mode: 'copy'"                                       
 [3] "    tag \"createing snp matrix with snp-dists\""                                         
 [4] "    container 'staphb/snp-dists:latest'"                                                 
 [5] "    pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"         
 [6] "    errorStrategy 'ignore'"                                                              
 [7] "    time '1day'"                                                                         
 [8] "    when:"                                                                               
 [9] "    params.snpdists"                                                                     
[10] "    input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"   
[11] "    input:errorStrategy 'ignore'"                                                        
[12] "    input:time '1day'"                                                                   
[13] "    input:"                                                                              
[14] "    file(msa) from msa_file"                                                             
[15] "    output:"                                                                             
[16] "    file(\"snp-dists/snp-dists.txt\")"                                                   
[17] "    file(\"logs/${task.process}/snp-dists.${workflow.sessionId}.{log,err}\")"            
[18] "    shell:"                                                                              
[19] "    '''"                                                                                 
[20] "      mkdir -p snp-dists logs/!{task.process}"                                           
[21] "      log_file=logs/!{task.process}/snp-dists.!{workflow.sessionId}.log"                 
[22] "      err_file=logs/!{task.process}/snp-dists.!{workflow.sessionId}.err"                 
[23] "      date | tee -a $log_file $err_file > /dev/null"                                     
[24] "      snp-dists -v >> $log_file"                                                         
[25] "      snp-dists !{params.snpdists_options} !{msa} > snp-dists/snp-dists.txt 2> $err_file"
[26] "    '''"                                                                                 
[27] "  }"                                                                                     

$snpdists$line_numbers
 [1] 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384
[16] 1385 1386 1387 1388 1389 1390 1391

$snpdists$cpus_parsed
[1] 1


$iqtree2
$iqtree2$process_lines
 [1] "  process iqtree2 {"                                                                                                                       
 [2] "    publishDir \"${params.outdir}\", mode: 'copy'"                                                                                         
 [3] "    tag \"Creating phylogenetic tree with iqtree\""                                                                                        
 [4] "    container 'staphb/iqtree2:latest'"                                                                                                     
 [5] "    pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                           
 [6] "    errorStrategy 'ignore'"                                                                                                                
 [7] "    time '1day'"                                                                                                                           
 [8] "    when:"                                                                                                                                 
 [9] "    params.iqtree2"                                                                                                                        
[10] "    input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                                     
[11] "    input:errorStrategy 'ignore'"                                                                                                          
[12] "    input:time '1day'"                                                                                                                     
[13] "    input:"                                                                                                                                
[14] "    file(msa) from msa_file2"                                                                                                              
[15] "    output:"                                                                                                                               
[16] "    file(\"${task.process}/${task.process}.{iqtree,treefile,mldist,log}\")"                                                                
[17] "    file(\"logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}\")"                                                        
[18] "    shell:"                                                                                                                                
[19] "    '''"                                                                                                                                   
[20] "      mkdir -p !{task.process} logs/!{task.process}"                                                                                       
[21] "      log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log"                                                             
[22] "      err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err"                                                             
[23] "      date | tee -a $log_file $err_file > /dev/null"                                                                                       
[24] "      iqtree2 --version >> $log_file"                                                                                                      
[25] "      if [ -n \"!{params.iqtree2_outgroup}\" ] && [ \"!{params.iqtree2_outgroup}\" != \"null\" ] && [ \"!{params.msa}\" != \"nextclade\" ]"
[26] "      then"                                                                                                                                
[27] "        outgroup=\"-o !{params.iqtree2_outgroup}\""                                                                                        
[28] "        cat !{msa} | sed 's/!{params.iqtree2_outgroup}.*/!{params.iqtree2_outgroup}/g' > !{msa}.renamed"                                   
[29] "      else"                                                                                                                                
[30] "        outgroup=\"\""                                                                                                                     
[31] "        mv !{msa} !{msa}.renamed"                                                                                                          
[32] "      fi"                                                                                                                                  
[33] "      # creating a tree"                                                                                                                   
[34] "iqtree2 !{params.iqtree2_options} \\"                                                                                                      
[35] "        -nt AUTO \\"                                                                                                                       
[36] "        -ntmax !{task.cpus} \\"                                                                                                            
[37] "        -s !{msa}.renamed \\"                                                                                                              
[38] "        -pre !{task.process}/iqtree2 \\"                                                                                                   
[39] "        $outgroup \\"                                                                                                                      
[40] "        >> $log_file 2>> $err_file"                                                                                                        
[41] "    '''"                                                                                                                                   
[42] "  }"                                                                                                                                       

$iqtree2$line_numbers
 [1] 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408
[16] 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1423 1424
[31] 1425 1426 1427 1428 1429 1430 1431

$iqtree2$cpus_parsed
[1] 8


$rename
$rename$process_lines
 [1] "  process rename {"                                                                                                          
 [2] "    publishDir \"${params.outdir}\", mode: 'copy'"                                                                           
 [3] "    tag \"Renaming files for ${sample}\""                                                                                    
 [4] "    container 'staphb/parallel-perl:latest'"                                                                                 
 [5] "    stageInMode 'copy'"                                                                                                      
 [6] "    input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'"                                       
 [7] "    input:errorStrategy 'ignore'"                                                                                            
 [8] "    input:time '1day'"                                                                                                       
 [9] "    input:"                                                                                                                  
[10] "    tuple val(sample), file(reads), val(paired_single), file(consensus), file(filtered_reads), file(sample_file) from rename"
[11] "    output:"                                                                                                                 
[12] "    file(\"submission_files/*{genbank,gisaid}.fa\") optional true"                                                           
[13] "    file(\"submission_files/*.fastq.gz\")"                                                                                   
[14] "    file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{err,log}\")"                                                
[15] "    shell:"                                                                                                                  
[16] "    '''"                                                                                                                     
[17] "      mkdir -p submission_files logs/!{task.process}"                                                                        
[18] "      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log"                                                     
[19] "      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err"                                                     
[20] "      date | tee -a $log_file $err_file > /dev/null"                                                                         
[21] "      !{workflow.projectDir}/bin/genbank_submission.sh \\"                                                                   
[22] "        -f !{sample_file} \\"                                                                                                
[23] "        -c . \\"                                                                                                             
[24] "        -d . \\"                                                                                                             
[25] "        -s !{params.gisaid_threshold} \\"                                                                                    
[26] "        -g !{params.genbank_threshold} \\"                                                                                   
[27] "        -o submission_files \\"                                                                                              
[28] "        2>> $err_file >> $log_file"                                                                                          
[29] "    '''"                                                                                                                     
[30] "  }"                                                                                                                         

$rename$line_numbers
 [1] 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462
[16] 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475

$rename$cpus_parsed
[1] 1


2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   process rename {
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     tag "Renaming files for ${sample}"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     container 'staphb/parallel-perl:latest'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     stageInMode 'copy'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:time '1day'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     tuple val(sample), file(reads), val(paired_single), file(consensus), file(filtered_reads), file(sample_file) from rename
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     output:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     file("submission_files/*{genbank,gisaid}.fa") optional true
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     file("submission_files/*.fastq.gz")
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     file("logs/${task.process}/${sample}.${workflow.sessionId}.{err,log}")
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     shell:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     '''
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       mkdir -p submission_files logs/!{task.process}
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       !{workflow.projectDir}/bin/genbank_submission.sh \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         -f !{sample_file} \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         -c . \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         -d . \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         -s !{params.gisaid_threshold} \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         -g !{params.genbank_threshold} \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         -o submission_files \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         2>> $err_file >> $log_file
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     '''
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   }
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   process iqtree2 {
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     tag "Creating phylogenetic tree with iqtree"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     container 'staphb/iqtree2:latest'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     time '1day'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     when:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     params.iqtree2
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:time '1day'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     file(msa) from msa_file2
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     output:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     file("${task.process}/${task.process}.{iqtree,treefile,mldist,log}")
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     shell:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     '''
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       iqtree2 --version >> $log_file
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       if [ -n "!{params.iqtree2_outgroup}" ] && [ "!{params.iqtree2_outgroup}" != "null" ] && [ "!{params.msa}" != "nextclade" ]
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       then
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         outgroup="-o !{params.iqtree2_outgroup}"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         cat !{msa} | sed 's/!{params.iqtree2_outgroup}.*/!{params.iqtree2_outgroup}/g' > !{msa}.renamed
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       else
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         outgroup=""
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         mv !{msa} !{msa}.renamed
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       fi
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       # creating a tree
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL iqtree2 !{params.iqtree2_options} \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         -nt AUTO \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         -ntmax !{task.cpus} \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         -s !{msa}.renamed \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         -pre !{task.process}/iqtree2 \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         $outgroup \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         >> $log_file 2>> $err_file
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     '''
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   }
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   process snpdists {
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     tag "createing snp matrix with snp-dists"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     container 'staphb/snp-dists:latest'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     time '1day'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     when:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     params.snpdists
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:time '1day'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     input:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     file(msa) from msa_file
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     output:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     file("snp-dists/snp-dists.txt")
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     file("logs/${task.process}/snp-dists.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     shell:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     '''
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       mkdir -p snp-dists logs/!{task.process}
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       log_file=logs/!{task.process}/snp-dists.!{workflow.sessionId}.log
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       err_file=logs/!{task.process}/snp-dists.!{workflow.sessionId}.err
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       snp-dists -v >> $log_file
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       snp-dists !{params.snpdists_options} !{msa} > snp-dists/snp-dists.txt 2> $err_file
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     '''
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   }
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     process nextalign {
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       tag "Multiple Sequence Alignment"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       container 'nextstrain/nextalign:latest'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       input:errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       input:time '1day'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       input:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       file(consensus) from consensus_msa.concat(fastas_msa).concat(multifastas_msa).collect()
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       path(dataset) from prepped_nextalign
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       output:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       file("${task.process}/nextalign.aligned.fasta") into msa_file, msa_file2
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       file("${task.process}/{*.fasta,nextalign.*.csv}")
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       shell:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       '''
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         echo "nextalign version:" >> $log_file
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         nextalign --version-detailed 2>&1 >> $log_file
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         for fasta in !{consensus}
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         do
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL           cat $fasta >> !{task.process}/ultimate.fasta
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         done
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         nextalign !{params.nextalign_options} \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL           --sequences !{task.process}/ultimate.fasta \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL           --reference !{dataset}/reference.fasta \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL           --genemap !{dataset}/genemap.gff \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL           --jobs !{task.cpus} \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL           --output-dir !{task.process} \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL           --output-basename nextalign \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL           >> $log_file 2>> $err_file
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       '''
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     }
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     process mafft {
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       tag "Multiple Sequence Alignment"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       container 'staphb/mafft:latest'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       errorStrategy 'retry'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       maxRetries 2
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       input:errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       input:time '1day'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       input:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       file(consensus) from consensus_msa.concat(fastas_msa).concat(multifastas_msa).collect()
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       file(reference_genome) from reference_genome_msa
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       output:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       file("${task.process}/mafft_aligned.fasta") into msa_file, msa_file2
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       file("logs/${task.process}/mafft.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       shell:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       '''
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         log_file=logs/!{task.process}/mafft.!{workflow.sessionId}.log
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         err_file=logs/!{task.process}/mafft.!{workflow.sessionId}.err
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         echo "mafft version:" >> $log_file
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         mafft --version 2>&1 >> $log_file
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         for fasta in !{consensus}
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         do
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL           cat $fasta >> !{task.process}/ultimate.fasta
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         done
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         mafft --auto \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL           !{params.mafft_options} \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL           --thread !{task.cpus} \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL           --addfragments !{task.process}/ultimate.fasta \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL           !{reference_genome} \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL           > !{task.process}/mafft_aligned.fasta \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL           2>> $err_file
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       '''
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     }
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL process combine_results {
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   publishDir "${params.outdir}", mode: 'copy', overwrite: true
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   tag "Combining Results"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   container 'quay.io/biocontainers/pandas:1.1.5'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   time '1day'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   when:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   params.nextclade || params.pangolin || params.vadr
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:time '1day'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file(nextclade) from nextclade_file.ifEmpty([])
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file(pangolin) from pangolin_file.ifEmpty([])
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file(vadr) from vadr_file.ifEmpty([])
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file(summary) from summary_file.collect()
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file(combine_results) from combine_results_script
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   output:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file("cecret_results.{csv,txt}")
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   shell:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   '''
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     mkdir -p summary logs/!{task.process}
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     cat !{summary} | head -n 1 > combined_summary.csv
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     for summary in !{summary}
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     do
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       tail -n +2 $summary >> combined_summary.csv
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     done
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ -s "vadr.vadr.sqa" ] ; then tail -n +2 "vadr.vadr.sqa" | grep -v "#-" | tr -s '[:blank:]' ',' > vadr.csv ; fi
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     python !{combine_results}
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     cat cecret_results.csv | tr ',' '\\t' > cecret_results.txt
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   '''
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL }
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL process summary {
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   publishDir "${params.outdir}", mode: 'copy', overwrite: true
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   tag "${sample}"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   container 'quay.io/biocontainers/pandas:1.1.5'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:time '1day'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   tuple val(sample), val(num_N), val(num_ACTG), val(num_degenerate), val(num_total), val(first_line),
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(raw_1),
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(raw_2),
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(pairskept),
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(perc_kept),
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(reads_passed),
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(ivar_variants),
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(bcftools_variants),
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(coverage),
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(covdepth),
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(depth),
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(samtools_stats_before_size_results),
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(samtools_stats_after_size_results),
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(percentage_human),
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(percentage_cov),
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(bedtools_num_failed_amplicons),
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(samtools_num_failed_amplicons),
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(aligner_version),
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(trimmer_version),
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(cleaner_version),
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     val(ivar_version) from results
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   output:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file("${task.process}/${sample}.summary.csv") into summary_file, summary
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   shell:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   '''
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     sample_id=($(echo !{sample} | cut -f 1 -d "_" ))
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     header="sample_id,sample,fasta_line"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     result="${sample_id},!{sample},!{first_line}"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ "!{params.fastqc}" != "false" ]
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       header="$header,fastqc_raw_reads_1,fastqc_raw_reads_2"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       result="$result,!{raw_1},!{raw_2}"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ "!{params.cleaner}" == "seqyclean" ]
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       header="$header,seqyclean_pairs_kept_after_cleaning,seqyclean_percent_kept_after_cleaning"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       result="$result,!{pairskept},!{perc_kept}"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ "!{params.cleaner}" == "fastp" ]
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       header="$header,fastp_reads_passed"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       result="$result,!{reads_passed}"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ "!{params.samtools_coverage}" != "false" ]
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       header="$header,depth_after_trimming,1X_coverage_after_trimming"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       result="$result,!{covdepth},!{coverage}"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ "!{params.samtools_depth}" != "false" ]
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       header="$header,num_pos_!{params.minimum_depth}X"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       result="$result,!{depth}"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ "!{params.samtools_stats}" != "false" ]
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       header="$header,insert_size_before_trimming,insert_size_after_trimming"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       result="$result,!{samtools_stats_before_size_results},!{samtools_stats_after_size_results}"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ "!{params.kraken2}" != "false" ]
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       organism=$(echo "!{params.kraken2_organism}" | sed 's/ /_/g')
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       header="$header,%_human_reads,percent_${organism}_reads"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       result="$result,!{percentage_human},!{percentage_cov}"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ "!{params.ivar_variants}" != "false" ]
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       header="$header,ivar_num_variants_identified"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       result="$result,!{ivar_variants}"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ "!{params.bcftools_variants}" != "false" ]
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       header="$header,bcftools_variants_identified"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       result="$result,!{bcftools_variants}"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ "!{params.bedtools_multicov}" != "false" ]
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       header="$header,bedtools_num_failed_amplicons"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       result="$result,!{bedtools_num_failed_amplicons}"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ "!{params.samtools_ampliconstats}" != "false" ]
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       header="$header,samtools_num_failed_amplicons"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       result="$result,!{samtools_num_failed_amplicons}"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     header="$header,num_N,num_degenerage,num_non-ambiguous,num_total"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     result="$result,!{num_N},!{num_degenerate},!{num_ACTG},!{num_total}"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     header="$header,cleaner_version,aligner_version,trimmer_version,ivar_version"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     result="$result,!{cleaner_version},!{aligner_version},!{trimmer_version},!{ivar_version}"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     echo $header > !{task.process}/!{sample}.summary.csv
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     echo $result >> !{task.process}/!{sample}.summary.csv
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   '''
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL }
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL process vadr {
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   tag "QC metrics"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   container 'staphb/vadr:latest'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   time '1day'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   when:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   params.vadr
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:time '1day'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file(fasta) from consensus_vadr.concat(fastas_vadr).concat(multifastas_vadr).collect()
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   output:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file("${task.process}/*") optional true
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file("${task.process}/vadr.vadr.sqa") optional true into vadr_file
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   shell:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   '''
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     mkdir -p logs/!{task.process}
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     echo "no version" >> $log_file
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     v-annotate.pl -h >> $log_file
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     for fasta in !{fasta}
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     do
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       cat $fasta >> ultimate_fasta.fasta
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     done
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fasta-trim-terminal-ambigs.pl !{params.vadr_trim_options} \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       ultimate_fasta.fasta > trimmed_ultimate_fasta.fasta
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     if [ -s "trimmed_ultimate_fasta.fasta" ]
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     then
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       v-annotate.pl !{params.vadr_options} \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         --cpu !{task.cpus} \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         --noseqnamemax \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         --mkey !{params.vadr_reference} \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         --mdir !{params.vadr_mdir} \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         trimmed_ultimate_fasta.fasta \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         !{task.process} \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL         2>> $err_file >> $log_file
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     fi
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     cp ultimate_fasta.fasta !{task.process}/combined.fasta
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     cp trimmed_ultimate_fasta.fasta !{task.process}/trimmed.fasta
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   '''
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL }
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL process nextclade {
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   tag "Clade Determination"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   container 'nextstrain/nextclade:latest'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   time '1day'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   when:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   params.nextclade || params.msa == 'nextalign'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:time '1day'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file(fasta) from consensus_nextclade.concat(fastas_nextclade).concat(multifastas_nextclade).collect()
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   output:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file("${task.process}/nextclade.csv") into nextclade_file
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file("${task.process}/*")
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file("${task.process}/nextclade.aligned.fasta") into nextclade_aligned_fasta
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   path("dataset") into prepped_nextalign
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   shell:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   '''
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     mkdir -p !{task.process} dataset logs/!{task.process}
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     nextclade --version >> $log_file
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     nextclade_version=$(nextclade --version)
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     nextclade dataset get --name !{params.nextclade_dataset} --output-dir dataset
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     for fasta in !{fasta}
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     do
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       cat $fasta >> ultimate_fasta.fasta
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     done
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     nextclade !{params.nextclade_options} \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       --input-fasta=ultimate_fasta.fasta \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       --input-dataset dataset \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       --output-json=!{task.process}/nextclade.json \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       --output-csv=!{task.process}/nextclade.csv \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       --output-tsv=!{task.process}/nextclade.tsv \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       --output-tree=!{task.process}/nextclade.auspice.json \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       --output-dir=!{task.process} \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       --output-basename=nextclade \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       2>> $err_file >> $log_file
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     cp ultimate_fasta.fasta !{task.process}/combined.fasta
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   '''
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL }
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL process pangolin {
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   tag "SARS-CoV-2 lineage Determination"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   container 'staphb/pangolin:latest'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   stageInMode 'copy'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   time '1day'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   when:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   params.pangolin
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:time '1day'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file(fasta) from consensus_pangolin.concat(fastas_pangolin).concat(multifastas_pangolin).collect()
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   output:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file("${task.process}/*")
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file("${task.process}/lineage_report.csv") into pangolin_file
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file("logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   shell:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   '''
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     mkdir -p !{task.process} logs/!{task.process}
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     pangolin --all-versions >> $log_file
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     for fasta in !{fasta}
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     do
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       cat $fasta >> ultimate_fasta.fasta
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     done
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     pangolin !{params.pangolin_options} \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       --threads !{task.cpus} \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       --outdir !{task.process} \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       ultimate_fasta.fasta \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       2>> $err_file >> $log_file
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     cp ultimate_fasta.fasta !{task.process}/combined.fasta
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   '''
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL }
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL process samtools_plot_ampliconstats {
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   tag "${sample}"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   container 'staphb/samtools:latest'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   time '1day'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   when:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   params.samtools_plot_ampliconstats
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:time '1day'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   tuple val(sample), file(ampliconstats) from samtools_ampliconstats_files
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   output:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file("${task.process}/${sample}*")
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   file("logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}")
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   shell:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   '''
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     mkdir -p !{task.process}/!{sample} logs/!{task.process}
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     date | tee -a $log_file $err_file > /dev/null
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     samtools --version >> $log_file
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL     plot-ampliconstats !{params.samtools_plot_ampliconstats_options} \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       !{task.process}/!{sample} \
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL       !{ampliconstats}
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   '''
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL }
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL process samtools_ampliconstats {
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   publishDir "${params.outdir}", mode: 'copy'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   tag "${sample}"
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   container 'staphb/samtools:latest'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   time '1day'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   when:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   params.samtools_ampliconstats
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:pod annotation: 'scheduler.illumina.com/presetSize' value: 'standard-small'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:errorStrategy 'ignore'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:time '1day'
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   input:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   tuple val(sample), file(bam), file(primer_bed) from trimmed_bams5.combine(primer_bed_ampliconstats)
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   output:
2022-03-14 09:23:08 [INFO] LOOKING_AT_LINE_FOR_CHANNEL   tuple sample, file("${task.process}/${sample}_ampliconstats.txt") into samtools_ampliconstats_files
2022-03-14 09:23:08 [INFO] FOUND_DUMMY_CHANNEL_EXPRESSION:   tuple sample, file("${task.process}/${sample}_ampliconstats.txt") into samtools_ampliconstats_files
2022-03-14 09:23:08 [INFO] ADDING DUMMY PROCESS
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 0 UPPER_LINE_BOUND 165
2022-03-14 09:23:08 [INFO] ADDED 204 lines from process: fastqc
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 199 UPPER_LINE_BOUND 203
2022-03-14 09:23:08 [INFO] ADDED 63 lines from process: seqyclean
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 257 UPPER_LINE_BOUND 266
2022-03-14 09:23:08 [INFO] ADDED 62 lines from process: fastp
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 314 UPPER_LINE_BOUND 319
2022-03-14 09:23:08 [INFO] ADDED 32 lines from process: bwa
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 344 UPPER_LINE_BOUND 347
2022-03-14 09:23:08 [INFO] ADDED 30 lines from process: minimap2
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 372 UPPER_LINE_BOUND 374
2022-03-14 09:23:08 [INFO] ADDED 28 lines from process: sort
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 398 UPPER_LINE_BOUND 400
2022-03-14 09:23:08 [INFO] ADDED 35 lines from process: filter
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 428 UPPER_LINE_BOUND 431
2022-03-14 09:23:08 [INFO] ADDED 32 lines from process: ivar_trim
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 458 UPPER_LINE_BOUND 461
2022-03-14 09:23:08 [INFO] ADDED 32 lines from process: samtools_ampliconclip
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 488 UPPER_LINE_BOUND 503
2022-03-14 09:23:08 [INFO] ADDED 67 lines from process: ivar_variants
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 551 UPPER_LINE_BOUND 553
2022-03-14 09:23:08 [INFO] ADDED 53 lines from process: ivar_consensus
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 603 UPPER_LINE_BOUND 604
2022-03-14 09:23:08 [INFO] ADDED 39 lines from process: fasta_prep
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 637 UPPER_LINE_BOUND 638
2022-03-14 09:23:08 [INFO] ADDED 32 lines from process: bcftools_variants
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 664 UPPER_LINE_BOUND 671
2022-03-14 09:23:08 [INFO] ADDED 63 lines from process: bamsnap
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 722 UPPER_LINE_BOUND 727
2022-03-14 09:23:08 [INFO] ADDED 44 lines from process: samtools_stats
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 761 UPPER_LINE_BOUND 763
2022-03-14 09:23:08 [INFO] ADDED 43 lines from process: samtools_coverage
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 799 UPPER_LINE_BOUND 801
2022-03-14 09:23:08 [INFO] ADDED 38 lines from process: samtools_flagstat
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 832 UPPER_LINE_BOUND 834
2022-03-14 09:23:08 [INFO] ADDED 41 lines from process: samtools_depth
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 868 UPPER_LINE_BOUND 870
2022-03-14 09:23:08 [INFO] ADDED 56 lines from process: kraken2
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 919 UPPER_LINE_BOUND 921
2022-03-14 09:23:08 [INFO] ADDED 35 lines from process: bedtools_multicov
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 949 UPPER_LINE_BOUND 951
2022-03-14 09:23:08 [INFO] ADDED 34 lines from process: samtools_ampliconstats
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 978 UPPER_LINE_BOUND 980
2022-03-14 09:23:08 [INFO] ADDED 31 lines from process: samtools_plot_ampliconstats
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 1004 UPPER_LINE_BOUND 1006
2022-03-14 09:23:08 [INFO] ADDED 39 lines from process: pangolin
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 1038 UPPER_LINE_BOUND 1041
2022-03-14 09:23:08 [INFO] ADDED 48 lines from process: nextclade
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 1081 UPPER_LINE_BOUND 1086
2022-03-14 09:23:08 [INFO] ADDED 51 lines from process: vadr
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 1127 UPPER_LINE_BOUND 1151
2022-03-14 09:23:08 [INFO] ADDED 128 lines from process: summary
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 1253 UPPER_LINE_BOUND 1260
2022-03-14 09:23:08 [INFO] ADDED 43 lines from process: combine_results
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 1291 UPPER_LINE_BOUND 1295
2022-03-14 09:23:08 [INFO] ADDED 39 lines from process: mafft
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 1328 UPPER_LINE_BOUND 1331
2022-03-14 09:23:08 [INFO] ADDED 38 lines from process: nextalign
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 1364 UPPER_LINE_BOUND 1370
2022-03-14 09:23:08 [INFO] ADDED 32 lines from process: snpdists
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 1391 UPPER_LINE_BOUND 1394
2022-03-14 09:23:08 [INFO] ADDED 44 lines from process: iqtree2
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 1431 UPPER_LINE_BOUND 1448
2022-03-14 09:23:08 [INFO] ADDED 46 lines from process: rename
2022-03-14 09:23:08 [INFO] LOWER_LINE_BOUND 1475 UPPER_LINE_BOUND 1476
2022-03-14 09:23:08 [INFO] ADDED 17 lines from process: copy_workfiles
2022-03-14 09:23:08 [INFO] Writing updated processes to /Users/keng/codes/Cecret/Cecret.ica.dev.nf
2022-03-14 09:23:09 [INFO] ENTERING_PARAMS_ENCLOSURE: params {
2022-03-14 09:23:09 [INFO] OTHER_LINE: params {
2022-03-14 09:23:09 [INFO] LINE_OF_INTEREST: params { PARAMS_ENCLOSURE: TRUE
2022-03-14 09:23:09 [INFO] initial_nested_param: NA 	 nested_param_key: NA
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:        repoDir='/seqprg'
2022-03-14 09:23:09 [INFO] EXITED_PARAMS_ENCLOSURE: }
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:   executor = 'slurm'
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:   clusterOptions = '--hold --no-kill'
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:   queue = '128GB,256GB,256GBv1'
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:     container = 'goalconsortium/trim_galore:1.0.9'
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:     container = 'goalconsortium/abra2:1.0.9'
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:     container = 'goalconsortium/profiling_qc:1.0.9'
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:      container = 'goalconsortium/dna_alignment:1.0.9'
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:     container = 'goalconsortium/variantcalling:1.0.9'
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:      container = 'goalconsortium/structuralvariant:1.0.9'
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:     container = 'goalconsortium/starfusion:1.0.9'
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:     container = 'goalconsortium/rna_alignment:1.0.9'
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:     container = 'goalconsortium/rna_gene_abundance:1.0.9'
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS: }
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:   enabled = true
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:   runOptions='--no-home --cleanenv'
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:   cacheDir="$PWD"
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:   enabled = true
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:   file = 'pipeline_trace.txt'
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:   field = 'task_id,native_id,process,name,status,exit,submit,start,complete,duration,realtime'
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:   enabled = false
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:   file = 'timeline.html'
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:   enabled = false
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:   file = 'report.html'
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:   homePage = 'https://github.com/bcantarel/school'
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:   description = 'School is a collection of genomics analysis workflows that are used for detecting single nucleotide variants (SNVs), insertions/deletions (indels), copy number variants (CNVs) and translocations from RNA and DNA sequencing.  These workflows have been validated in a CLIA laboratory at UTSW'
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:   mainScript = 'dna.nf'
2022-03-14 09:23:09 [INFO] NOT_CHANGING_STATUS:   nextflowVersion = '>=0.31.0'
2022-03-14 09:23:09 [INFO] DONE_PARSING


2022-03-14 09:23:09 [INFO] ADDING_NF_SCRIPT_LINE: params.input = './fastq'
2022-03-14 09:23:09 [INFO] ADDING_NF_SCRIPT_LINE: params.output = './analysis'
2022-03-14 09:23:09 [INFO] ADDING_NF_SCRIPT_LINE: params.snpeff_vers = 'GRCh38.86';
2022-03-14 09:23:09 [INFO] ADDING_NF_SCRIPT_LINE: params.genome="/project/shared/bicf_workflow_ref/human/grch38_cloud/dnaref"
2022-03-14 09:23:09 [INFO] ADDING_NF_SCRIPT_LINE: params.virus_genome="/project/shared/bicf_workflow_ref/human_virus_genome/clinlab_idt_genomes"
2022-03-14 09:23:09 [INFO] ADDING_NF_SCRIPT_LINE: params.markdups='fgbio_umi'
2022-03-14 09:23:09 [INFO] ADDING_NF_SCRIPT_LINE: params.version = 'v4'
2022-03-14 09:23:09 [INFO] ADDING_NF_SCRIPT_LINE: params.seqrunid = 'runtest'
2022-03-14 09:23:09 [INFO] ADDING_NF_SCRIPT_LINE: ncmconf = file("$params.genome/ncm.conf")
2022-03-14 09:23:09 [INFO] ADDING_NF_SCRIPT_LINE: reffa=file("$params.genome/genome.fa")
2022-03-14 09:23:09 [INFO] ADDING_NF_SCRIPT_LINE: dbsnp="$params.genome/dbSnp.vcf.gz"
2022-03-14 09:23:09 [INFO] ADDING_NF_SCRIPT_LINE: indel="$params.genome/GoldIndels.vcf.gz"
2022-03-14 09:23:09 [INFO] ADDING_NF_SCRIPT_LINE: capturebed = file("$params.capture")
2022-03-14 09:23:09 [INFO] ADDING_NF_SCRIPT_LINE: capturedir = file("$params.capturedir")
2022-03-14 09:23:09 [INFO] ADDING_NF_SCRIPT_LINE:    repoDir=params.repoDir
2022-03-14 09:23:09 [INFO] ADDING_NF_SCRIPT_LINE:    ponopt="-q $params.pon"
2022-03-14 09:23:09 [INFO] ADDING_NF_SCRIPT_LINE:    params.tumorid = 'Tumor'
2022-03-14 09:23:09 [INFO] ADDING_NF_SCRIPT_LINE:    somatic[params.caseid] = false
2022-03-14 09:23:09 [INFO] ADDING_NF_SCRIPT_LINE:       somatic[params.caseid] = true
2022-03-14 09:23:09 [INFO] ADDING_NF_SCRIPT_LINE:   params.design="$params.input/design.txt"
2022-03-14 09:23:09 [INFO] ADDING_NF_SCRIPT_LINE:   params.fastqs="$params.input/*.fastq.gz"
2022-03-14 09:23:09 [INFO] Parameters to check: 
2022-03-14 09:23:09 [INFO] Parameters to add: 
2022-03-14 09:23:09 [INFO] SETTING y to foi_result[['params_found']]
2022-03-14 09:23:09 [INFO] ADDING UPDATED PARAMS to /Users/keng/codes/school/dna.ica.nf
2022-03-14 09:23:10 [INFO] parameters found: 
2022-03-14 09:23:10 [INFO] LOOKING into 
Error in paramsToXML[[param_name]] : 
  attempt to select less than one element in get1index
Calls: classifyParameters
Execution halted
